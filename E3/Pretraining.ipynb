{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pretraining on one dataset and then train on another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prepare PAMAP2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH:  /home/dmitrii/GitHub/SDAPraktikum/E3/PAMAP2_Dataset/pamap2.h5\n",
      "x_train shape =  (128247, 52)\n",
      "y_train shape = (128247,)\n",
      "x_test shape = (22659, 52)\n",
      "y_test shape = (22659,)\n",
      "x_train shape(downsampled) =  (42749, 52)\n",
      "y_train shape(downsampled) = (42749,)\n",
      "x_test shape(downsampled) = (7553, 52)\n",
      "y_test shape(downsampled) = (7553,)\n",
      "[ 1  2  3  4  5  6  7 11 12 13 14 18]\n",
      "[ 1  2  3  4  5  6  7 11 12 13 14 18]\n",
      "segmenting signal...\n",
      "signal segmented.\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[[ 0.001     ,  0.1       ,  0.030375  , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.1       ,  0.030375  , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.101     ,  0.030375  , ...,  0.001     ,\n           0.        ,  0.        ],\n         ...,\n         [ 0.001     ,  0.102     ,  0.0305    , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.102     ,  0.0305    , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.102     ,  0.0305    , ...,  0.001     ,\n           0.        ,  0.        ]],\n \n        [[ 0.001     ,  0.102     ,  0.0304375 , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.102     ,  0.0304375 , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.102     ,  0.0304375 , ...,  0.001     ,\n           0.        ,  0.        ],\n         ...,\n         [ 0.001     ,  0.103     ,  0.0305    , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.103     ,  0.0305    , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.104     ,  0.0305    , ...,  0.001     ,\n           0.        ,  0.        ]],\n \n        [[ 0.001     ,  0.102     ,  0.0305    , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.102     ,  0.0305    , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.102     ,  0.0305    , ...,  0.001     ,\n           0.        ,  0.        ],\n         ...,\n         [ 0.001     ,  0.105     ,  0.0305625 , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.106     ,  0.0305625 , ...,  0.001     ,\n           0.        ,  0.        ],\n         [ 0.001     ,  0.106     ,  0.0305625 , ...,  0.001     ,\n           0.        ,  0.        ]],\n \n        ...,\n \n        [[ 0.024     ,  0.153     ,  0.025125  , ...,  0.00050735,\n          -0.00060634,  0.00052589],\n         [ 0.024     ,  0.153     ,  0.025125  , ...,  0.00049953,\n          -0.00061755,  0.00054103],\n         [ 0.024     ,  0.153     ,  0.025125  , ...,  0.00040207,\n          -0.00064276,  0.00050967],\n         ...,\n         [ 0.024     ,  0.156     ,  0.025125  , ...,  0.00044798,\n          -0.00048998,  0.00062958],\n         [ 0.024     ,  0.156     ,  0.025125  , ...,  0.00046398,\n          -0.00064208,  0.00053236],\n         [ 0.024     ,  0.157     ,  0.025125  , ...,  0.00053828,\n          -0.00058986,  0.00056612]],\n \n        [[ 0.024     ,  0.153     ,  0.025125  , ...,  0.0004087 ,\n          -0.00056059,  0.00055887],\n         [ 0.024     ,  0.153     ,  0.025125  , ...,  0.00041794,\n          -0.00059147,  0.00051272],\n         [ 0.024     ,  0.154     ,  0.025125  , ...,  0.00040863,\n          -0.00057881,  0.00051072],\n         ...,\n         [ 0.024     ,  0.16      ,  0.025125  , ...,  0.00042317,\n          -0.00068581,  0.00047049],\n         [ 0.024     ,  0.16      ,  0.025125  , ...,  0.00051829,\n          -0.00072267,  0.0004394 ],\n         [ 0.024     ,  0.16      ,  0.025125  , ...,  0.00052783,\n          -0.00062406,  0.00053145]],\n \n        [[ 0.024     ,  0.157     ,  0.025125  , ...,  0.00053828,\n          -0.00058986,  0.00056612],\n         [ 0.024     ,  0.157     ,  0.025125  , ...,  0.00050774,\n          -0.00056039,  0.00059596],\n         [ 0.024     ,  0.158     ,  0.025125  , ...,  0.00041073,\n          -0.00070837,  0.00047278],\n         ...,\n         [ 0.024     ,  0.161     ,  0.0251875 , ...,  0.00041117,\n          -0.00057883,  0.00056236],\n         [ 0.024     ,  0.161     ,  0.0251875 , ...,  0.00040814,\n          -0.00054579,  0.000569  ],\n         [ 0.024     ,  0.161     ,  0.025125  , ...,  0.00044533,\n          -0.00038871,  0.00065102]]]),\n array([ 1.,  1.,  1., ..., 18., 18., 18.]),\n array([[[ 1.00000e-03,  1.03000e-01,  3.32500e-02, ...,  1.03534e-04,\n          -9.08114e-04, -2.12260e-04],\n         [ 1.00000e-03,  1.03000e-01,  3.32500e-02, ...,  8.98076e-05,\n          -9.02214e-04, -2.17754e-04],\n         [ 1.00000e-03,  1.03000e-01,  3.32500e-02, ...,  7.65267e-05,\n          -8.95669e-04, -2.20620e-04],\n         ...,\n         [ 1.00000e-03,  1.02000e-01,  3.32500e-02, ...,  8.92419e-04,\n           2.57181e-04,  1.06879e-04],\n         [ 1.00000e-03,  1.02000e-01,  3.32500e-02, ...,  9.36846e-04,\n           2.04511e-04,  1.82783e-04],\n         [ 1.00000e-03,  1.02000e-01,  3.32500e-02, ...,  9.15749e-04,\n           3.13463e-04,  2.50749e-04]],\n \n        [[ 1.00000e-03,  1.03000e-01,  3.32500e-02, ...,  4.85205e-05,\n           7.09063e-04,  3.09091e-04],\n         [ 1.00000e-03,  1.03000e-01,  3.32500e-02, ...,  8.41282e-05,\n           6.55264e-04,  3.52324e-04],\n         [ 1.00000e-03,  1.03000e-01,  3.32500e-02, ...,  7.23934e-05,\n           6.10668e-04,  3.53321e-04],\n         ...,\n         [ 1.00000e-03,  1.02000e-01,  3.32500e-02, ...,  8.39300e-04,\n           1.62334e-04,  3.63733e-04],\n         [ 1.00000e-03,  1.02000e-01,  3.32500e-02, ...,  8.02805e-04,\n           1.60831e-04,  4.18969e-04],\n         [ 1.00000e-03,  1.02000e-01,  3.32500e-02, ...,  7.78272e-04,\n           9.35298e-05,  4.39410e-04]],\n \n        [[ 1.00000e-03,  1.02000e-01,  3.32500e-02, ...,  9.15749e-04,\n           3.13463e-04,  2.50749e-04],\n         [ 1.00000e-03,  1.02000e-01,  3.32500e-02, ...,  8.89780e-04,\n           3.23625e-04,  3.17993e-04],\n         [ 1.00000e-03,  1.02000e-01,  3.32500e-02, ...,  8.55072e-04,\n           3.47445e-04,  3.80990e-04],\n         ...,\n         [ 1.00000e-03,  1.03000e-01,  3.32500e-02, ...,  3.21497e-04,\n           2.79670e-04,  7.67436e-04],\n         [ 1.00000e-03,  1.03000e-01,  3.32500e-02, ...,  2.76914e-04,\n           2.73516e-04,  7.92475e-04],\n         [ 1.00000e-03,  1.03000e-01,  3.32500e-02, ...,  3.16375e-04,\n           2.12738e-04,  7.51861e-04]],\n \n        ...,\n \n        [[ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  4.32296e-04,\n          -6.39444e-04,  5.20863e-04],\n         [ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  5.92321e-04,\n          -7.67470e-04,  1.99674e-04],\n         [ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  4.45465e-04,\n          -5.70321e-04,  5.96048e-04],\n         ...,\n         [ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  5.50368e-04,\n          -3.96387e-04,  6.41473e-04],\n         [ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  5.49377e-04,\n          -3.92533e-04,  6.46833e-04],\n         [ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  5.38514e-04,\n          -3.92767e-04,  6.52458e-04]],\n \n        [[ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  5.61563e-04,\n          -6.64288e-04,  4.23815e-04],\n         [ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  7.48795e-04,\n          -6.05850e-04,  2.68654e-04],\n         [ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  5.45898e-04,\n          -5.84367e-04,  5.18723e-04],\n         ...,\n         [ 5.00000e-03,  1.73000e-01,  2.80000e-02, ...,  5.83251e-04,\n          -3.09538e-04,  7.01865e-04],\n         [ 5.00000e-03,  1.73000e-01,  2.80000e-02, ...,  5.85208e-04,\n          -3.14005e-04,  7.01057e-04],\n         [ 5.00000e-03,  1.73000e-01,  2.80000e-02, ...,  5.87475e-04,\n          -3.16355e-04,  6.99267e-04]],\n \n        [[ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  5.38514e-04,\n          -3.92767e-04,  6.52458e-04],\n         [ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  5.74442e-04,\n          -3.20648e-04,  6.81843e-04],\n         [ 5.00000e-03,  1.74000e-01,  2.80000e-02, ...,  5.89182e-04,\n          -2.94675e-04,  6.92372e-04],\n         ...,\n         [ 2.40000e-02,  1.32000e-01,  2.80000e-02, ...,  1.19955e-04,\n          -7.57519e-04,  1.01360e-04],\n         [ 2.40000e-02,  1.32000e-01,  2.80000e-02, ...,  1.17755e-04,\n          -7.57894e-04,  1.06911e-04],\n         [ 2.40000e-02,  1.32000e-01,  2.79375e-02, ...,  1.18948e-04,\n          -7.57137e-04,  1.06869e-04]]]),\n array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n         1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,\n         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3., 14., 14., 14., 14.,\n        14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14.,\n        14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14.,\n        14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14.,\n        14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14.,\n        14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14.,\n        14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14.,\n        14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 13.,\n        13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13.,\n        13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13.,\n        13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13.,\n        13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13.,\n        13., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n        11., 11., 11., 11., 12., 12., 12., 12., 12., 12., 12., 12., 12.,\n        12., 12., 12., 12., 12., 12., 11., 11., 11., 11., 11., 11., 11.,\n        11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 12., 12.,\n        12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12.,  4.,  4.,\n         4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n         4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n         4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n         4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n         4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  7.,  7.,\n         7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,\n         7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,\n         7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,\n         7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,\n         7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,\n         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n         5.,  5.,  5.,  5.]))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cnn1d_modules import Model, Dataset\n",
    "from statistics import Statistics\n",
    "dataset_obj = Dataset(\"pa2\")\n",
    "dataset_obj.read_dataset()\n",
    "dataset_obj.downsample_dataset()\n",
    "dataset_obj.segment_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train model numerous times to get mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "WARNING:tensorflow:From /home/dmitrii/anaconda3/envs/work/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "WARNING:tensorflow:From /home/dmitrii/anaconda3/envs/work/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /home/dmitrii/anaconda3/envs/work/lib/python3.8/site-packages/tensorflow/python/util/tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 22:34:55.523017: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-10 22:34:55.523464: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-10 22:34:55.526579: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-07-10 22:34:55.537267: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2022-07-10 22:34:55.564893: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1796665000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Training Loss:  2.4931993007659914  Training Accuracy:  0.22549845\n",
      "Epoch:  1  Training Loss:  2.1713886185125872  Training Accuracy:  0.3299635\n",
      "Epoch:  2  Training Loss:  1.9693447839130054  Training Accuracy:  0.36871666\n",
      "Epoch:  3  Training Loss:  1.798331819339232  Training Accuracy:  0.393148\n",
      "Epoch:  4  Training Loss:  1.681404430216009  Training Accuracy:  0.45773658\n",
      "Epoch:  5  Training Loss:  1.5506980660286818  Training Accuracy:  0.50659925\n",
      "Epoch:  6  Training Loss:  1.4251950139349157  Training Accuracy:  0.5549003\n",
      "Epoch:  7  Training Loss:  1.2920508723367343  Training Accuracy:  0.60263973\n",
      "Epoch:  8  Training Loss:  1.1895693646235899  Training Accuracy:  0.63437235\n",
      "Epoch:  9  Training Loss:  1.0954911741343412  Training Accuracy:  0.65515304\n",
      "Epoch:  10  Training Loss:  1.0233710278164256  Training Accuracy:  0.68491995\n",
      "Epoch:  11  Training Loss:  0.9419859485192732  Training Accuracy:  0.7110362\n",
      "Epoch:  12  Training Loss:  0.8825237130576914  Training Accuracy:  0.7079472\n",
      "Epoch:  13  Training Loss:  0.8092630259015343  Training Accuracy:  0.71665263\n",
      "Epoch:  14  Training Loss:  0.7480754006992687  Training Accuracy:  0.739399\n",
      "Epoch:  15  Training Loss:  0.7006520179185001  Training Accuracy:  0.73546755\n",
      "Epoch:  16  Training Loss:  0.6514089698141271  Training Accuracy:  0.7396799\n",
      "Epoch:  17  Training Loss:  0.6419697524471717  Training Accuracy:  0.7565291\n",
      "Epoch:  18  Training Loss:  0.59151509499008  Training Accuracy:  0.77028924\n",
      "Epoch:  19  Training Loss:  0.5798508737574924  Training Accuracy:  0.7627071\n",
      "Epoch:  20  Training Loss:  0.5397710139101202  Training Accuracy:  0.79387814\n",
      "Epoch:  21  Training Loss:  0.5098683311180635  Training Accuracy:  0.78573436\n",
      "Epoch:  22  Training Loss:  0.4898552370342341  Training Accuracy:  0.79415894\n",
      "Epoch:  23  Training Loss:  0.4924346483566544  Training Accuracy:  0.7994945\n",
      "Epoch:  24  Training Loss:  0.4638674100691622  Training Accuracy:  0.8087616\n",
      "Epoch:  25  Training Loss:  0.4598974617367441  Training Accuracy:  0.8152204\n",
      "Epoch:  26  Training Loss:  0.4408497001637112  Training Accuracy:  0.82083684\n",
      "Epoch:  27  Training Loss:  0.44318917000835595  Training Accuracy:  0.8213985\n",
      "Epoch:  28  Training Loss:  0.41483365845951164  Training Accuracy:  0.8326313\n",
      "Epoch:  29  Training Loss:  0.4115788832306862  Training Accuracy:  0.83628196\n",
      "Epoch:  30  Training Loss:  0.38554327406666494  Training Accuracy:  0.8368436\n",
      "Epoch:  31  Training Loss:  0.3866194773126732  Training Accuracy:  0.84723395\n",
      "Epoch:  32  Training Loss:  0.379089378463951  Training Accuracy:  0.8413367\n",
      "Epoch:  33  Training Loss:  0.3665049776265567  Training Accuracy:  0.84105587\n",
      "Epoch:  34  Training Loss:  0.3673035971820354  Training Accuracy:  0.82645327\n",
      "Epoch:  35  Training Loss:  0.386593019860712  Training Accuracy:  0.83768606\n",
      "Epoch:  36  Training Loss:  0.46562639227644964  Training Accuracy:  0.8289806\n",
      "Epoch:  37  Training Loss:  0.5131412909789519  Training Accuracy:  0.8323505\n",
      "Epoch:  38  Training Loss:  0.536023390868848  Training Accuracy:  0.8435833\n",
      "Epoch:  39  Training Loss:  0.6611047480255365  Training Accuracy:  0.8418983\n",
      "Epoch:  40  Training Loss:  0.6282450947910547  Training Accuracy:  0.82364506\n",
      "Epoch:  41  Training Loss:  0.8461732869375158  Training Accuracy:  0.8427408\n",
      "Epoch:  42  Training Loss:  1.1176405312662774  Training Accuracy:  0.80005616\n",
      "Epoch:  43  Training Loss:  1.6278857304629955  Training Accuracy:  0.7615838\n",
      "Epoch:  44  Training Loss:  1.600118406303227  Training Accuracy:  0.7978096\n",
      "Epoch:  45  Training Loss:  1.8838383128527891  Training Accuracy:  0.7708509\n",
      "Epoch:  46  Training Loss:  2.4297189807349984  Training Accuracy:  0.7554058\n",
      "Epoch:  47  Training Loss:  3.1359457637098704  Training Accuracy:  0.73659086\n",
      "Epoch:  48  Training Loss:  4.434390374797989  Training Accuracy:  0.71665263\n",
      "Epoch:  49  Training Loss:  5.513417808846994  Training Accuracy:  0.72423476\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.77070063\n",
      "validation accuracy: 0.77070063\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.520192499594255  Training Accuracy:  0.21623139\n",
      "Epoch:  1  Training Loss:  2.1568252151662652  Training Accuracy:  0.34400448\n",
      "Epoch:  2  Training Loss:  1.9179570040919565  Training Accuracy:  0.37405223\n",
      "Epoch:  3  Training Loss:  1.7537139025601474  Training Accuracy:  0.41224375\n",
      "Epoch:  4  Training Loss:  1.6193989986723119  Training Accuracy:  0.46728447\n",
      "Epoch:  5  Training Loss:  1.4737449472600763  Training Accuracy:  0.5293457\n",
      "Epoch:  6  Training Loss:  1.3459233045578003  Training Accuracy:  0.5798933\n",
      "Epoch:  7  Training Loss:  1.2304315767504952  Training Accuracy:  0.6262286\n",
      "Epoch:  8  Training Loss:  1.1339252076365731  Training Accuracy:  0.6585229\n",
      "Epoch:  9  Training Loss:  1.029921503500505  Training Accuracy:  0.6714406\n",
      "Epoch:  10  Training Loss:  0.9554432942108675  Training Accuracy:  0.69559115\n",
      "Epoch:  11  Training Loss:  0.8708390000191601  Training Accuracy:  0.7031733\n",
      "Epoch:  12  Training Loss:  0.8140939731489528  Training Accuracy:  0.7155293\n",
      "Epoch:  13  Training Loss:  0.7617518406022679  Training Accuracy:  0.72451556\n",
      "Epoch:  14  Training Loss:  0.7051131080497395  Training Accuracy:  0.7315361\n",
      "Epoch:  15  Training Loss:  0.6607414244250818  Training Accuracy:  0.7455771\n",
      "Epoch:  16  Training Loss:  0.6094445036216216  Training Accuracy:  0.75063187\n",
      "Epoch:  17  Training Loss:  0.5745571453462948  Training Accuracy:  0.76214546\n",
      "Epoch:  18  Training Loss:  0.5513019202107733  Training Accuracy:  0.76354957\n",
      "Epoch:  19  Training Loss:  0.5149948667396199  Training Accuracy:  0.78320694\n",
      "Epoch:  20  Training Loss:  0.4847335213964636  Training Accuracy:  0.79668635\n",
      "Epoch:  21  Training Loss:  0.4931452743031762  Training Accuracy:  0.81100816\n",
      "Epoch:  22  Training Loss:  0.4757846233519641  Training Accuracy:  0.8292614\n",
      "Epoch:  23  Training Loss:  0.4782736883922057  Training Accuracy:  0.82111764\n",
      "Epoch:  24  Training Loss:  0.47626076123931194  Training Accuracy:  0.83178884\n",
      "Epoch:  25  Training Loss:  0.4620197992433201  Training Accuracy:  0.83628196\n",
      "Epoch:  26  Training Loss:  0.45806544172492897  Training Accuracy:  0.83768606\n",
      "Epoch:  27  Training Loss:  0.42565921077674085  Training Accuracy:  0.8416175\n",
      "Epoch:  28  Training Loss:  0.38223131210966543  Training Accuracy:  0.85060376\n",
      "Epoch:  29  Training Loss:  0.3685035724531521  Training Accuracy:  0.82561076\n",
      "Epoch:  30  Training Loss:  0.3380387004126202  Training Accuracy:  0.8104465\n",
      "Epoch:  31  Training Loss:  0.33479960533705627  Training Accuracy:  0.8073575\n",
      "Epoch:  32  Training Loss:  0.3413876859979196  Training Accuracy:  0.80791914\n",
      "Epoch:  33  Training Loss:  0.3459398737346584  Training Accuracy:  0.8042685\n",
      "Epoch:  34  Training Loss:  0.3733300447294658  Training Accuracy:  0.7851727\n",
      "Epoch:  35  Training Loss:  0.3200442003255541  Training Accuracy:  0.7781522\n",
      "Epoch:  36  Training Loss:  0.4074429754506458  Training Accuracy:  0.80988485\n",
      "Epoch:  37  Training Loss:  0.41290496699512  Training Accuracy:  0.77141255\n",
      "Epoch:  38  Training Loss:  0.4815108516846191  Training Accuracy:  0.8199944\n",
      "Epoch:  39  Training Loss:  0.46506561603058466  Training Accuracy:  0.78713846\n",
      "Epoch:  40  Training Loss:  0.5327668439046565  Training Accuracy:  0.7834878\n",
      "Epoch:  41  Training Loss:  0.583715844408355  Training Accuracy:  0.8042685\n",
      "Epoch:  42  Training Loss:  0.883736396513202  Training Accuracy:  0.7916316\n",
      "Epoch:  43  Training Loss:  0.9718379364433614  Training Accuracy:  0.75877565\n",
      "Epoch:  44  Training Loss:  1.2534130737185478  Training Accuracy:  0.7935973\n",
      "Epoch:  45  Training Loss:  1.4059481507675213  Training Accuracy:  0.7304128\n",
      "Epoch:  46  Training Loss:  1.8237626446495678  Training Accuracy:  0.7725358\n",
      "Epoch:  47  Training Loss:  2.397440977530046  Training Accuracy:  0.7528784\n",
      "Epoch:  48  Training Loss:  2.5563991958106107  Training Accuracy:  0.77000844\n",
      "Epoch:  49  Training Loss:  3.4988974002613262  Training Accuracy:  0.7525976\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.7324841\n",
      "validation accuracy: 0.7324841\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.524980833313682  Training Accuracy:  0.20359449\n",
      "Epoch:  1  Training Loss:  2.194056808948517  Training Accuracy:  0.294861\n",
      "Epoch:  2  Training Loss:  1.9972546414895491  Training Accuracy:  0.3664701\n",
      "Epoch:  3  Training Loss:  1.8209295988082885  Training Accuracy:  0.4184218\n",
      "Epoch:  4  Training Loss:  1.661000560088591  Training Accuracy:  0.49199662\n",
      "Epoch:  5  Training Loss:  1.5165404850786381  Training Accuracy:  0.53018814\n",
      "Epoch:  6  Training Loss:  1.393444685773416  Training Accuracy:  0.5501264\n",
      "Epoch:  7  Training Loss:  1.2906151115894318  Training Accuracy:  0.5970233\n",
      "Epoch:  8  Training Loss:  1.199890202012929  Training Accuracy:  0.6141533\n",
      "Epoch:  9  Training Loss:  1.1197880322282965  Training Accuracy:  0.6276327\n",
      "Epoch:  10  Training Loss:  1.0650807386094874  Training Accuracy:  0.64504355\n",
      "Epoch:  11  Training Loss:  0.9959441499276595  Training Accuracy:  0.6652626\n",
      "Epoch:  12  Training Loss:  0.9348920998248187  Training Accuracy:  0.6717214\n",
      "Epoch:  13  Training Loss:  0.8913256959481672  Training Accuracy:  0.6700365\n",
      "Epoch:  14  Training Loss:  0.8264283589341423  Training Accuracy:  0.69418705\n",
      "Epoch:  15  Training Loss:  0.7753236472606659  Training Accuracy:  0.71019375\n",
      "Epoch:  16  Training Loss:  0.7375717642632398  Training Accuracy:  0.716091\n",
      "Epoch:  17  Training Loss:  0.7240217222408815  Training Accuracy:  0.72142655\n",
      "Epoch:  18  Training Loss:  0.6778977656906301  Training Accuracy:  0.73406345\n",
      "Epoch:  19  Training Loss:  0.6599283543500033  Training Accuracy:  0.7438922\n",
      "Epoch:  20  Training Loss:  0.6230344640937718  Training Accuracy:  0.76888514\n",
      "Epoch:  21  Training Loss:  0.6172119989991188  Training Accuracy:  0.7868576\n",
      "Epoch:  22  Training Loss:  0.5906511484221979  Training Accuracy:  0.7837686\n",
      "Epoch:  23  Training Loss:  0.5515527523376725  Training Accuracy:  0.78461105\n",
      "Epoch:  24  Training Loss:  0.5192952437834306  Training Accuracy:  0.79415894\n",
      "Epoch:  25  Training Loss:  0.4925334230065346  Training Accuracy:  0.79837126\n",
      "Epoch:  26  Training Loss:  0.47106091258200733  Training Accuracy:  0.7834878\n",
      "Epoch:  27  Training Loss:  0.43243573836304927  Training Accuracy:  0.7933165\n",
      "Epoch:  28  Training Loss:  0.42793104296380824  Training Accuracy:  0.79415894\n",
      "Epoch:  29  Training Loss:  0.39895171936262736  Training Accuracy:  0.8006178\n",
      "Epoch:  30  Training Loss:  0.3879344906996597  Training Accuracy:  0.77506316\n",
      "Epoch:  31  Training Loss:  0.3769599483771758  Training Accuracy:  0.76383036\n",
      "Epoch:  32  Training Loss:  0.3619451893324202  Training Accuracy:  0.76888514\n",
      "Epoch:  33  Training Loss:  0.37922602275555783  Training Accuracy:  0.7742207\n",
      "Epoch:  34  Training Loss:  0.36970025009729646  Training Accuracy:  0.7596181\n",
      "Epoch:  35  Training Loss:  0.3768884048543193  Training Accuracy:  0.74641955\n",
      "Epoch:  36  Training Loss:  0.370469483462247  Training Accuracy:  0.7778714\n",
      "Epoch:  37  Training Loss:  0.39776183464987713  Training Accuracy:  0.7837686\n",
      "Epoch:  38  Training Loss:  0.3785761863670566  Training Accuracy:  0.77028924\n",
      "Epoch:  39  Training Loss:  0.40513052151284434  Training Accuracy:  0.7711317\n",
      "Epoch:  40  Training Loss:  0.4108365808698264  Training Accuracy:  0.8104465\n",
      "Epoch:  41  Training Loss:  0.4452904093671929  Training Accuracy:  0.8059534\n",
      "Epoch:  42  Training Loss:  0.5008326038379561  Training Accuracy:  0.82392585\n",
      "Epoch:  43  Training Loss:  0.635883775819093  Training Accuracy:  0.81128895\n",
      "Epoch:  44  Training Loss:  0.6913043731992895  Training Accuracy:  0.7975288\n",
      "Epoch:  45  Training Loss:  0.8820900827307593  Training Accuracy:  0.80651504\n",
      "Epoch:  46  Training Loss:  0.9514092549089004  Training Accuracy:  0.7806796\n",
      "Epoch:  47  Training Loss:  1.4042508195408365  Training Accuracy:  0.77337825\n",
      "Epoch:  48  Training Loss:  1.5476447430523959  Training Accuracy:  0.7775906\n",
      "Epoch:  49  Training Loss:  1.9504153935069388  Training Accuracy:  0.73799497\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.6910828\n",
      "validation accuracy: 0.6910828\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.559270371090282  Training Accuracy:  0.22662173\n",
      "Epoch:  1  Training Loss:  2.155079727823084  Training Accuracy:  0.32884023\n",
      "Epoch:  2  Training Loss:  1.9398318366570906  Training Accuracy:  0.38135356\n",
      "Epoch:  3  Training Loss:  1.7892000117085196  Training Accuracy:  0.4310587\n",
      "Epoch:  4  Training Loss:  1.6459023773670196  Training Accuracy:  0.48834598\n",
      "Epoch:  5  Training Loss:  1.5095517906275662  Training Accuracy:  0.53580457\n",
      "Epoch:  6  Training Loss:  1.3643768841570074  Training Accuracy:  0.58242065\n",
      "Epoch:  7  Training Loss:  1.2571160953153264  Training Accuracy:  0.6293176\n",
      "Epoch:  8  Training Loss:  1.1489550371061672  Training Accuracy:  0.64981747\n",
      "Epoch:  9  Training Loss:  1.0642368771813133  Training Accuracy:  0.6663858\n",
      "Epoch:  10  Training Loss:  0.9921701469204642  Training Accuracy:  0.68463916\n",
      "Epoch:  11  Training Loss:  0.9220088124275208  Training Accuracy:  0.6981185\n",
      "Epoch:  12  Training Loss:  0.8547770895741202  Training Accuracy:  0.7065431\n",
      "Epoch:  13  Training Loss:  0.7978821469978853  Training Accuracy:  0.7287279\n",
      "Epoch:  14  Training Loss:  0.7604899563572624  Training Accuracy:  0.739399\n",
      "Epoch:  15  Training Loss:  0.718572847680612  Training Accuracy:  0.7514743\n",
      "Epoch:  16  Training Loss:  0.6843658494678411  Training Accuracy:  0.76326877\n",
      "Epoch:  17  Training Loss:  0.6404846914789893  Training Accuracy:  0.78601515\n",
      "Epoch:  18  Training Loss:  0.6199957154013894  Training Accuracy:  0.7961247\n",
      "Epoch:  19  Training Loss:  0.6061695425347848  Training Accuracy:  0.803426\n",
      "Epoch:  20  Training Loss:  0.5869299871000376  Training Accuracy:  0.8160629\n",
      "Epoch:  21  Training Loss:  0.5560397557236931  Training Accuracy:  0.8261724\n",
      "Epoch:  22  Training Loss:  0.5187660806558348  Training Accuracy:  0.8301039\n",
      "Epoch:  23  Training Loss:  0.4881772358309139  Training Accuracy:  0.8309464\n",
      "Epoch:  24  Training Loss:  0.43916969936002387  Training Accuracy:  0.81915194\n",
      "Epoch:  25  Training Loss:  0.4318638234653256  Training Accuracy:  0.82561076\n",
      "Epoch:  26  Training Loss:  0.3988813690841198  Training Accuracy:  0.8216793\n",
      "Epoch:  27  Training Loss:  0.3804401460019025  Training Accuracy:  0.8298231\n",
      "Epoch:  28  Training Loss:  0.3639293200590394  Training Accuracy:  0.8202752\n",
      "Epoch:  29  Training Loss:  0.3496169063855301  Training Accuracy:  0.82392585\n",
      "Epoch:  30  Training Loss:  0.34333546303889967  Training Accuracy:  0.8309464\n",
      "Epoch:  31  Training Loss:  0.3485304136167873  Training Accuracy:  0.8258916\n",
      "Epoch:  32  Training Loss:  0.3237755092707547  Training Accuracy:  0.8160629\n",
      "Epoch:  33  Training Loss:  0.31922183626077394  Training Accuracy:  0.8132547\n",
      "Epoch:  34  Training Loss:  0.3389039588584141  Training Accuracy:  0.8228026\n",
      "Epoch:  35  Training Loss:  0.3316662642427466  Training Accuracy:  0.81409717\n",
      "Epoch:  36  Training Loss:  0.3650621465661309  Training Accuracy:  0.817467\n",
      "Epoch:  37  Training Loss:  0.33402286751026455  Training Accuracy:  0.81100816\n",
      "Epoch:  38  Training Loss:  0.44584671584042634  Training Accuracy:  0.79668635\n",
      "Epoch:  39  Training Loss:  0.4070340844717893  Training Accuracy:  0.8008986\n",
      "Epoch:  40  Training Loss:  0.5348556908016855  Training Accuracy:  0.8155013\n",
      "Epoch:  41  Training Loss:  0.6307186268524013  Training Accuracy:  0.7980904\n",
      "Epoch:  42  Training Loss:  0.6275615274906159  Training Accuracy:  0.8281382\n",
      "Epoch:  43  Training Loss:  0.9903953737155957  Training Accuracy:  0.8354395\n",
      "Epoch:  44  Training Loss:  0.9342670956118541  Training Accuracy:  0.8025835\n",
      "Epoch:  45  Training Loss:  1.4091627385805954  Training Accuracy:  0.8025835\n",
      "Epoch:  46  Training Loss:  1.5883868527683345  Training Accuracy:  0.7570907\n",
      "Epoch:  47  Training Loss:  1.9825460333377123  Training Accuracy:  0.7615838\n",
      "Epoch:  48  Training Loss:  2.7223969680341806  Training Accuracy:  0.7469812\n",
      "Epoch:  49  Training Loss:  3.2559636076742953  Training Accuracy:  0.7233923\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.6878981\n",
      "validation accuracy: 0.6878981\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.5631814393130217  Training Accuracy:  0.224656\n",
      "Epoch:  1  Training Loss:  2.144109722700986  Training Accuracy:  0.3173266\n",
      "Epoch:  2  Training Loss:  1.9536806664683601  Training Accuracy:  0.3594496\n",
      "Epoch:  3  Training Loss:  1.8064308892596852  Training Accuracy:  0.3889357\n",
      "Epoch:  4  Training Loss:  1.6828951618888162  Training Accuracy:  0.4689694\n",
      "Epoch:  5  Training Loss:  1.5342361263253472  Training Accuracy:  0.53327715\n",
      "Epoch:  6  Training Loss:  1.3973126286810094  Training Accuracy:  0.57118785\n",
      "Epoch:  7  Training Loss:  1.2866216862743551  Training Accuracy:  0.59618086\n",
      "Epoch:  8  Training Loss:  1.2064100769433108  Training Accuracy:  0.63100255\n",
      "Epoch:  9  Training Loss:  1.1048548370599747  Training Accuracy:  0.63549566\n",
      "Epoch:  10  Training Loss:  1.0317863263867117  Training Accuracy:  0.65768045\n",
      "Epoch:  11  Training Loss:  0.9708573666485873  Training Accuracy:  0.6717214\n",
      "Epoch:  12  Training Loss:  0.9007183424451134  Training Accuracy:  0.69109803\n",
      "Epoch:  13  Training Loss:  0.8388293697075411  Training Accuracy:  0.7124403\n",
      "Epoch:  14  Training Loss:  0.7885508707978509  Training Accuracy:  0.72563887\n",
      "Epoch:  15  Training Loss:  0.7337612729180943  Training Accuracy:  0.73237854\n",
      "Epoch:  16  Training Loss:  0.6917964033105156  Training Accuracy:  0.7570907\n",
      "Epoch:  17  Training Loss:  0.6603800844062458  Training Accuracy:  0.76046056\n",
      "Epoch:  18  Training Loss:  0.6226399321447719  Training Accuracy:  0.7657961\n",
      "Epoch:  19  Training Loss:  0.6016404360532761  Training Accuracy:  0.78433025\n",
      "Epoch:  20  Training Loss:  0.5719277647408572  Training Accuracy:  0.786296\n",
      "Epoch:  21  Training Loss:  0.5431710011579773  Training Accuracy:  0.8042685\n",
      "Epoch:  22  Training Loss:  0.5190308825536207  Training Accuracy:  0.81437796\n",
      "Epoch:  23  Training Loss:  0.500089891525832  Training Accuracy:  0.8213985\n",
      "Epoch:  24  Training Loss:  0.48974998606876896  Training Accuracy:  0.81943274\n",
      "Epoch:  25  Training Loss:  0.47684652561491186  Training Accuracy:  0.8289806\n",
      "Epoch:  26  Training Loss:  0.4630197431553494  Training Accuracy:  0.84442574\n",
      "Epoch:  27  Training Loss:  0.4715506817806851  Training Accuracy:  0.84442574\n",
      "Epoch:  28  Training Loss:  0.45529142807830464  Training Accuracy:  0.8416175\n",
      "Epoch:  29  Training Loss:  0.4119249914857474  Training Accuracy:  0.8438641\n",
      "Epoch:  30  Training Loss:  0.37469063584100115  Training Accuracy:  0.8101657\n",
      "Epoch:  31  Training Loss:  0.403879626840353  Training Accuracy:  0.8233642\n",
      "Epoch:  32  Training Loss:  0.36072816076603803  Training Accuracy:  0.8402134\n",
      "Epoch:  33  Training Loss:  0.3737608714537187  Training Accuracy:  0.8171862\n",
      "Epoch:  34  Training Loss:  0.3805133243514733  Training Accuracy:  0.81943274\n",
      "Epoch:  35  Training Loss:  0.40012475326657293  Training Accuracy:  0.8357203\n",
      "Epoch:  36  Training Loss:  0.42369099435481156  Training Accuracy:  0.8416175\n",
      "Epoch:  37  Training Loss:  0.44301739639856597  Training Accuracy:  0.8298231\n",
      "Epoch:  38  Training Loss:  0.5204411086711016  Training Accuracy:  0.83824766\n",
      "Epoch:  39  Training Loss:  0.6349222039973194  Training Accuracy:  0.81774783\n",
      "Epoch:  40  Training Loss:  0.6361985475502231  Training Accuracy:  0.8301039\n",
      "Epoch:  41  Training Loss:  0.8641902062703263  Training Accuracy:  0.8025835\n",
      "Epoch:  42  Training Loss:  0.9659424433654005  Training Accuracy:  0.81100816\n",
      "Epoch:  43  Training Loss:  1.1700802369720555  Training Accuracy:  0.7961247\n",
      "Epoch:  44  Training Loss:  1.5732119251381267  Training Accuracy:  0.78910416\n",
      "Epoch:  45  Training Loss:  1.8897568033500152  Training Accuracy:  0.7882617\n",
      "Epoch:  46  Training Loss:  2.4188449859280476  Training Accuracy:  0.7570907\n",
      "Epoch:  47  Training Loss:  2.9607926068658177  Training Accuracy:  0.7663578\n",
      "Epoch:  48  Training Loss:  3.9730143949050793  Training Accuracy:  0.744173\n",
      "Epoch:  49  Training Loss:  4.929660421542146  Training Accuracy:  0.7399607\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.7929936\n",
      "validation accuracy: 0.7929936\n"
     ]
    }
   ],
   "source": [
    "model = Model(dataset_obj)\n",
    "stats = Statistics()\n",
    "num_experiments = 5\n",
    "\n",
    "for i in range(num_experiments):\n",
    "    model.build_model(load_weights=False)\n",
    "    model.run_model(training_epochs=50, learning_rate=0.0005)\n",
    "    test_accuracy, val_accuracy, y_pred, y_true = model.test()\n",
    "    stats.add(test_accuracy, val_accuracy, y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy. Mean (std) = 0.735 (0.042)\n",
      "Val accuracy. Mean (std) = 0.735 (0.042)\n",
      "f1 score weighted. Mean (std) = 0.701 (0.045)\n",
      "f1 score mean. Mean (std) = 0.695 (0.036)\n"
     ]
    }
   ],
   "source": [
    "stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pretrain the model on Opportunity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH:  /home/dmitrii/GitHub/SDAPraktikum/E3/OpportunityUCIDataset/opportunity.h5\n",
      "x_train shape =  (700165, 77)\n",
      "y_train shape = (700165,)\n",
      "x_test shape = (120516, 77)\n",
      "y_test shape = (120516,)\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "segmenting signal...\n",
      "signal segmented.\n",
      "train_x shape = (63650, 23, 77)\n",
      "train_y shape = (63650,)\n",
      "test_x shape = (10955, 23, 77)\n",
      "test_y shape = (10955,)\n",
      "opp\n",
      "X shape = (?, 1, 23, 77)\n",
      "Y shape = (?, 18)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 77, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 17, 128)\n",
      "h_pool1 shape = (?, 1, 6, 128)\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 4, 128)\n",
      "h_pool2 shape = (?, 1, 1, 128)\n",
      "shape's shape: [None, 1, 1, 128]\n",
      "c_flat shape = (?, 128)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (63650, 18)\n",
      "test_y shape(1-hot) = (10955, 18)\n",
      "train_x_reshaped =  (63650, 1, 23, 77)\n",
      "test_x_reshaped =  (10955, 1, 23, 77)\n",
      "train_x shape = (63650, 23, 77)\n",
      "train_y shape = (63650,)\n",
      "test_x shape = (10955, 23, 77)\n",
      "test_y shape = (10955,)\n",
      "Epoch:  0  Training Loss:  1.0267435149309738  Training Accuracy:  0.71924585\n",
      "Epoch:  1  Training Loss:  0.6662705483680293  Training Accuracy:  0.75337\n",
      "Epoch:  2  Training Loss:  0.5541527740844806  Training Accuracy:  0.7821838\n",
      "Epoch:  3  Training Loss:  0.49404162775900334  Training Accuracy:  0.808044\n",
      "Epoch:  4  Training Loss:  0.451495156036121  Training Accuracy:  0.82226235\n",
      "Epoch:  5  Training Loss:  0.4045749302123132  Training Accuracy:  0.8346112\n",
      "Epoch:  6  Training Loss:  0.378427674007086  Training Accuracy:  0.84942657\n",
      "Epoch:  7  Training Loss:  0.34422004803155126  Training Accuracy:  0.8558837\n",
      "Epoch:  8  Training Loss:  0.32451874238338324  Training Accuracy:  0.8637235\n",
      "Epoch:  9  Training Loss:  0.3026053944218062  Training Accuracy:  0.87476826\n",
      "Epoch:  10  Training Loss:  0.2852558381032792  Training Accuracy:  0.8744855\n",
      "Epoch:  11  Training Loss:  0.2730923033896984  Training Accuracy:  0.8802671\n",
      "Epoch:  12  Training Loss:  0.26201713054222886  Training Accuracy:  0.8876826\n",
      "Epoch:  13  Training Loss:  0.2479383114804236  Training Accuracy:  0.8907148\n",
      "Epoch:  14  Training Loss:  0.23697656434568162  Training Accuracy:  0.8955067\n",
      "Epoch:  15  Training Loss:  0.22984765491598583  Training Accuracy:  0.89907306\n",
      "Epoch:  16  Training Loss:  0.21198430933440038  Training Accuracy:  0.9011312\n",
      "Epoch:  17  Training Loss:  0.2037630371454886  Training Accuracy:  0.904729\n",
      "Epoch:  18  Training Loss:  0.20153192430546973  Training Accuracy:  0.8986646\n",
      "Epoch:  19  Training Loss:  0.19506373227199264  Training Accuracy:  0.9078712\n",
      "Epoch:  20  Training Loss:  0.18370890380575744  Training Accuracy:  0.91478395\n",
      "Epoch:  21  Training Loss:  0.1779057469663255  Training Accuracy:  0.9122231\n",
      "Epoch:  22  Training Loss:  0.17022395031941143  Training Accuracy:  0.91662216\n",
      "Epoch:  23  Training Loss:  0.16970830569353912  Training Accuracy:  0.9171092\n",
      "Epoch:  24  Training Loss:  0.15856901952015393  Training Accuracy:  0.9203299\n",
      "Epoch:  25  Training Loss:  0.15543195835513557  Training Accuracy:  0.92510605\n",
      "Epoch:  26  Training Loss:  0.15232449074443472  Training Accuracy:  0.92556167\n",
      "Epoch:  27  Training Loss:  0.15273964963232556  Training Accuracy:  0.9302592\n",
      "Epoch:  28  Training Loss:  0.14469500718928063  Training Accuracy:  0.92108405\n",
      "Epoch:  29  Training Loss:  0.13618151942015808  Training Accuracy:  0.92674\n",
      "Epoch:  30  Training Loss:  0.15041789578648407  Training Accuracy:  0.92573446\n",
      "Epoch:  31  Training Loss:  0.1355170352253312  Training Accuracy:  0.9367007\n",
      "Epoch:  32  Training Loss:  0.13008756203672592  Training Accuracy:  0.9345326\n",
      "Epoch:  33  Training Loss:  0.12951743607335062  Training Accuracy:  0.9368421\n",
      "Epoch:  34  Training Loss:  0.1281793378829504  Training Accuracy:  0.93487823\n",
      "Epoch:  35  Training Loss:  0.12497337510901516  Training Accuracy:  0.93374705\n",
      "Epoch:  36  Training Loss:  0.12015122007455453  Training Accuracy:  0.94256085\n",
      "Epoch:  37  Training Loss:  0.1185069931403214  Training Accuracy:  0.93949723\n",
      "Epoch:  38  Training Loss:  0.12085344659841737  Training Accuracy:  0.9441477\n",
      "Epoch:  39  Training Loss:  0.1151542984422588  Training Accuracy:  0.9459387\n",
      "Epoch:  40  Training Loss:  0.10900301228508816  Training Accuracy:  0.94232523\n",
      "Epoch:  41  Training Loss:  0.11361251860198443  Training Accuracy:  0.9505892\n",
      "Epoch:  42  Training Loss:  0.1048302573577667  Training Accuracy:  0.9413511\n",
      "Epoch:  43  Training Loss:  0.11639527624344939  Training Accuracy:  0.94169676\n",
      "Epoch:  44  Training Loss:  0.12013868854587118  Training Accuracy:  0.9480126\n",
      "Epoch:  45  Training Loss:  0.10872500199689887  Training Accuracy:  0.9476826\n",
      "Epoch:  46  Training Loss:  0.10088171351662222  Training Accuracy:  0.9455774\n",
      "Epoch:  47  Training Loss:  0.1006298202737734  Training Accuracy:  0.94739985\n",
      "Epoch:  48  Training Loss:  0.097144567131967  Training Accuracy:  0.95318145\n",
      "Epoch:  49  Training Loss:  0.09950981179831224  Training Accuracy:  0.955978\n"
     ]
    }
   ],
   "source": [
    "dataset_obj2 = Dataset(\"opp\")\n",
    "dataset_obj2.read_dataset()\n",
    "dataset_obj2.downsample_dataset()\n",
    "dataset_obj2.segment_dataset()\n",
    "model2 = Model(dataset_obj2)\n",
    "model2.build_model(load_weights=False)\n",
    "model2.run_model(training_epochs=50, learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from opp\n",
      "Testing Accuracy: 0.8878138\n",
      "validation accuracy: 0.8878138\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.8878138,\n 0.8878138,\n array([0, 0, 0, ..., 0, 0, 0]),\n array([0, 0, 0, ..., 0, 0, 0]))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train the model again but with pretrained hidden layer\n",
    "The network consists of input layer, hidden layer and output layer.\n",
    "Since only hidden layer is common for all datasets, we replace only this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.374279529398138  Training Accuracy:  0.14125246\n",
      "Epoch:  1  Training Loss:  2.280574224211953  Training Accuracy:  0.24122438\n",
      "Epoch:  2  Training Loss:  2.1423000769181684  Training Accuracy:  0.33333334\n",
      "Epoch:  3  Training Loss:  1.9517558157444  Training Accuracy:  0.36899748\n",
      "Epoch:  4  Training Loss:  1.813495524092154  Training Accuracy:  0.39511374\n",
      "Epoch:  5  Training Loss:  1.7036527330225164  Training Accuracy:  0.41786015\n",
      "Epoch:  6  Training Loss:  1.6261991213668476  Training Accuracy:  0.45436674\n",
      "Epoch:  7  Training Loss:  1.5567798013036902  Training Accuracy:  0.49059254\n",
      "Epoch:  8  Training Loss:  1.4934284204786474  Training Accuracy:  0.49536648\n",
      "Epoch:  9  Training Loss:  1.435614015026526  Training Accuracy:  0.5026678\n",
      "Epoch:  10  Training Loss:  1.3825978615067223  Training Accuracy:  0.502387\n",
      "Epoch:  11  Training Loss:  1.3453901361335407  Training Accuracy:  0.51923615\n",
      "Epoch:  12  Training Loss:  1.2963662548498673  Training Accuracy:  0.5290649\n",
      "Epoch:  13  Training Loss:  1.2628896019675515  Training Accuracy:  0.5447908\n",
      "Epoch:  14  Training Loss:  1.2205272403630343  Training Accuracy:  0.5532154\n",
      "Epoch:  15  Training Loss:  1.179694259708578  Training Accuracy:  0.56641394\n",
      "Epoch:  16  Training Loss:  1.1270676312121477  Training Accuracy:  0.59505755\n",
      "Epoch:  17  Training Loss:  1.0935155527158218  Training Accuracy:  0.609941\n",
      "Epoch:  18  Training Loss:  1.0542044433680449  Training Accuracy:  0.62285876\n",
      "Epoch:  19  Training Loss:  1.0159345529296182  Training Accuracy:  0.627071\n",
      "Epoch:  20  Training Loss:  0.9691243960098787  Training Accuracy:  0.64251614\n",
      "Epoch:  21  Training Loss:  0.9385803019458597  Training Accuracy:  0.64223534\n",
      "Epoch:  22  Training Loss:  0.9334970512173393  Training Accuracy:  0.6464476\n",
      "Epoch:  23  Training Loss:  0.8922381168062037  Training Accuracy:  0.65009826\n",
      "Epoch:  24  Training Loss:  0.8680224816907536  Training Accuracy:  0.6447627\n",
      "Epoch:  25  Training Loss:  0.8458569656718861  Training Accuracy:  0.63605726\n",
      "Epoch:  26  Training Loss:  0.8165581234476783  Training Accuracy:  0.6413929\n",
      "Epoch:  27  Training Loss:  0.8142985785549337  Training Accuracy:  0.6321258\n",
      "Epoch:  28  Training Loss:  0.8059340113943273  Training Accuracy:  0.62987924\n",
      "Epoch:  29  Training Loss:  0.7933614348823373  Training Accuracy:  0.62426287\n",
      "Epoch:  30  Training Loss:  0.7831555450504476  Training Accuracy:  0.62173545\n",
      "Epoch:  31  Training Loss:  0.7840129191225226  Training Accuracy:  0.6253861\n",
      "Epoch:  32  Training Loss:  0.7767021119594574  Training Accuracy:  0.6383039\n",
      "Epoch:  33  Training Loss:  0.7626417955214327  Training Accuracy:  0.66582423\n",
      "Epoch:  34  Training Loss:  0.7408688835122369  Training Accuracy:  0.6823926\n",
      "Epoch:  35  Training Loss:  0.7273186114701358  Training Accuracy:  0.70401573\n",
      "Epoch:  36  Training Loss:  0.7092768574302847  Training Accuracy:  0.7247964\n",
      "Epoch:  37  Training Loss:  0.6672035234895619  Training Accuracy:  0.7514743\n",
      "Epoch:  38  Training Loss:  0.6538555240089243  Training Accuracy:  0.7489469\n",
      "Epoch:  39  Training Loss:  0.6186351364309137  Training Accuracy:  0.7694468\n",
      "Epoch:  40  Training Loss:  0.6011234586889094  Training Accuracy:  0.78713846\n",
      "Epoch:  41  Training Loss:  0.5652610022913326  Training Accuracy:  0.7902275\n",
      "Epoch:  42  Training Loss:  0.5373637607151812  Training Accuracy:  0.79415894\n",
      "Epoch:  43  Training Loss:  0.502614734118635  Training Accuracy:  0.8020219\n",
      "Epoch:  44  Training Loss:  0.4794566126032309  Training Accuracy:  0.8070767\n",
      "Epoch:  45  Training Loss:  0.4725501803511923  Training Accuracy:  0.8155013\n",
      "Epoch:  46  Training Loss:  0.4302194046703252  Training Accuracy:  0.8272957\n",
      "Epoch:  47  Training Loss:  0.4319618615237149  Training Accuracy:  0.82841897\n",
      "Epoch:  48  Training Loss:  0.40331140587275677  Training Accuracy:  0.845549\n",
      "Epoch:  49  Training Loss:  0.4003138241442767  Training Accuracy:  0.84246\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.88535035\n",
      "validation accuracy: 0.88535035\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.3685677940195258  Training Accuracy:  0.16540298\n",
      "Epoch:  1  Training Loss:  2.206754938038913  Training Accuracy:  0.24178602\n",
      "Epoch:  2  Training Loss:  2.0445242819460954  Training Accuracy:  0.31086773\n",
      "Epoch:  3  Training Loss:  1.9292507009072737  Training Accuracy:  0.3524291\n",
      "Epoch:  4  Training Loss:  1.8180500225587324  Training Accuracy:  0.40129176\n",
      "Epoch:  5  Training Loss:  1.721202390031381  Training Accuracy:  0.4327436\n",
      "Epoch:  6  Training Loss:  1.6311893389983612  Training Accuracy:  0.48385286\n",
      "Epoch:  7  Training Loss:  1.5241406947374343  Training Accuracy:  0.53468126\n",
      "Epoch:  8  Training Loss:  1.4436252014203506  Training Accuracy:  0.54114014\n",
      "Epoch:  9  Training Loss:  1.3788829299536618  Training Accuracy:  0.5464757\n",
      "Epoch:  10  Training Loss:  1.3145292929627679  Training Accuracy:  0.55546194\n",
      "Epoch:  11  Training Loss:  1.2729302498427304  Training Accuracy:  0.5700646\n",
      "Epoch:  12  Training Loss:  1.2369784796779806  Training Accuracy:  0.58213985\n",
      "Epoch:  13  Training Loss:  1.1872524437579242  Training Accuracy:  0.5801741\n",
      "Epoch:  14  Training Loss:  1.171038512208245  Training Accuracy:  0.58101654\n",
      "Epoch:  15  Training Loss:  1.1506642945788124  Training Accuracy:  0.58494806\n",
      "Epoch:  16  Training Loss:  1.1152301696213809  Training Accuracy:  0.5860713\n",
      "Epoch:  17  Training Loss:  1.0948776681314816  Training Accuracy:  0.5911261\n",
      "Epoch:  18  Training Loss:  1.0665972211144188  Training Accuracy:  0.58522886\n",
      "Epoch:  19  Training Loss:  1.0441462113098665  Training Accuracy:  0.5925302\n",
      "Epoch:  20  Training Loss:  1.0495990522883154  Training Accuracy:  0.5857905\n",
      "Epoch:  21  Training Loss:  1.0220438686284152  Training Accuracy:  0.5939343\n",
      "Epoch:  22  Training Loss:  1.0043895491144874  Training Accuracy:  0.6017972\n",
      "Epoch:  23  Training Loss:  0.9892604204741391  Training Accuracy:  0.59196854\n",
      "Epoch:  24  Training Loss:  0.9644898349588568  Training Accuracy:  0.6141533\n",
      "Epoch:  25  Training Loss:  0.9366454555229707  Training Accuracy:  0.6290368\n",
      "Epoch:  26  Training Loss:  0.9096862248399041  Training Accuracy:  0.64392024\n",
      "Epoch:  27  Training Loss:  0.8883197681470351  Training Accuracy:  0.65009826\n",
      "Epoch:  28  Training Loss:  0.8610336406664415  Training Accuracy:  0.68155015\n",
      "Epoch:  29  Training Loss:  0.836748936095021  Training Accuracy:  0.6871665\n",
      "Epoch:  30  Training Loss:  0.8145183056592942  Training Accuracy:  0.69474864\n",
      "Epoch:  31  Training Loss:  0.7872381945902651  Training Accuracy:  0.7141252\n",
      "Epoch:  32  Training Loss:  0.7634359999136491  Training Accuracy:  0.72395396\n",
      "Epoch:  33  Training Loss:  0.7323948549953374  Training Accuracy:  0.73659086\n",
      "Epoch:  34  Training Loss:  0.724773093583909  Training Accuracy:  0.7556866\n",
      "Epoch:  35  Training Loss:  0.6960290207104249  Training Accuracy:  0.75933725\n",
      "Epoch:  36  Training Loss:  0.6699731939218261  Training Accuracy:  0.772255\n",
      "Epoch:  37  Training Loss:  0.6339831238443201  Training Accuracy:  0.78152204\n",
      "Epoch:  38  Training Loss:  0.6157600244337862  Training Accuracy:  0.7950014\n",
      "Epoch:  39  Training Loss:  0.5867173944007267  Training Accuracy:  0.7930357\n",
      "Epoch:  40  Training Loss:  0.5581019386649132  Training Accuracy:  0.7961247\n",
      "Epoch:  41  Training Loss:  0.5419802663001148  Training Accuracy:  0.8008986\n",
      "Epoch:  42  Training Loss:  0.5157049692489885  Training Accuracy:  0.80819994\n",
      "Epoch:  43  Training Loss:  0.5079053975641727  Training Accuracy:  0.81578207\n",
      "Epoch:  44  Training Loss:  0.48269672231240707  Training Accuracy:  0.8213985\n",
      "Epoch:  45  Training Loss:  0.46713960495862095  Training Accuracy:  0.8233642\n",
      "Epoch:  46  Training Loss:  0.4715947601605545  Training Accuracy:  0.8301039\n",
      "Epoch:  47  Training Loss:  0.44412111734802073  Training Accuracy:  0.8292614\n",
      "Epoch:  48  Training Loss:  0.43270856751637027  Training Accuracy:  0.8278573\n",
      "Epoch:  49  Training Loss:  0.41982190581885254  Training Accuracy:  0.8371244\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.78503186\n",
      "validation accuracy: 0.78503186\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.352654324878346  Training Accuracy:  0.22437517\n",
      "Epoch:  1  Training Loss:  2.172668889435855  Training Accuracy:  0.27997753\n",
      "Epoch:  2  Training Loss:  2.0085399855266917  Training Accuracy:  0.33642235\n",
      "Epoch:  3  Training Loss:  1.871603759039532  Training Accuracy:  0.3903398\n",
      "Epoch:  4  Training Loss:  1.7490005341443149  Training Accuracy:  0.44734624\n",
      "Epoch:  5  Training Loss:  1.6305018869313326  Training Accuracy:  0.49059254\n",
      "Epoch:  6  Training Loss:  1.5171012523499403  Training Accuracy:  0.52990735\n",
      "Epoch:  7  Training Loss:  1.4285999249328267  Training Accuracy:  0.5383319\n",
      "Epoch:  8  Training Loss:  1.3440186289223757  Training Accuracy:  0.5630441\n",
      "Epoch:  9  Training Loss:  1.275872682983225  Training Accuracy:  0.5815782\n",
      "Epoch:  10  Training Loss:  1.2059110443700443  Training Accuracy:  0.5981466\n",
      "Epoch:  11  Training Loss:  1.16444961076433  Training Accuracy:  0.60572875\n",
      "Epoch:  12  Training Loss:  1.1098566995425658  Training Accuracy:  0.61162597\n",
      "Epoch:  13  Training Loss:  1.0650435054844076  Training Accuracy:  0.6206122\n",
      "Epoch:  14  Training Loss:  1.0246386473829097  Training Accuracy:  0.6265094\n",
      "Epoch:  15  Training Loss:  0.9873493920673023  Training Accuracy:  0.64055043\n",
      "Epoch:  16  Training Loss:  0.9524743180383336  Training Accuracy:  0.634934\n",
      "Epoch:  17  Training Loss:  0.9175733403726057  Training Accuracy:  0.64841336\n",
      "Epoch:  18  Training Loss:  0.914124652066014  Training Accuracy:  0.6663858\n",
      "Epoch:  19  Training Loss:  0.9005693013017828  Training Accuracy:  0.6714406\n",
      "Epoch:  20  Training Loss:  0.8612507717175917  Training Accuracy:  0.6764954\n",
      "Epoch:  21  Training Loss:  0.846964228424159  Training Accuracy:  0.67846113\n",
      "Epoch:  22  Training Loss:  0.8008449871431698  Training Accuracy:  0.68604326\n",
      "Epoch:  23  Training Loss:  0.7886828842488203  Training Accuracy:  0.7009267\n",
      "Epoch:  24  Training Loss:  0.7522898934104226  Training Accuracy:  0.68800896\n",
      "Epoch:  25  Training Loss:  0.7268115133047104  Training Accuracy:  0.6995226\n",
      "Epoch:  26  Training Loss:  0.701451361450282  Training Accuracy:  0.7110362\n",
      "Epoch:  27  Training Loss:  0.686361917311495  Training Accuracy:  0.71300197\n",
      "Epoch:  28  Training Loss:  0.6725903418931094  Training Accuracy:  0.73069364\n",
      "Epoch:  29  Training Loss:  0.6436346199024807  Training Accuracy:  0.7427689\n",
      "Epoch:  30  Training Loss:  0.6154980910095301  Training Accuracy:  0.74473464\n",
      "Epoch:  31  Training Loss:  0.624191822653467  Training Accuracy:  0.7458579\n",
      "Epoch:  32  Training Loss:  0.5935640096664428  Training Accuracy:  0.7556866\n",
      "Epoch:  33  Training Loss:  0.584520977193659  Training Accuracy:  0.76046056\n",
      "Epoch:  34  Training Loss:  0.5460208103738048  Training Accuracy:  0.7739399\n",
      "Epoch:  35  Training Loss:  0.5458088326860558  Training Accuracy:  0.7801179\n",
      "Epoch:  36  Training Loss:  0.5252775046635758  Training Accuracy:  0.7823645\n",
      "Epoch:  37  Training Loss:  0.5031617713245479  Training Accuracy:  0.8042685\n",
      "Epoch:  38  Training Loss:  0.4820711956105449  Training Accuracy:  0.8090424\n",
      "Epoch:  39  Training Loss:  0.48839551799676634  Training Accuracy:  0.82504916\n",
      "Epoch:  40  Training Loss:  0.4423993640663949  Training Accuracy:  0.8483572\n",
      "Epoch:  41  Training Loss:  0.47444155209443784  Training Accuracy:  0.8433024\n",
      "Epoch:  42  Training Loss:  0.4389764736999165  Training Accuracy:  0.85734344\n",
      "Epoch:  43  Training Loss:  0.46134946935556154  Training Accuracy:  0.84582984\n",
      "Epoch:  44  Training Loss:  0.47824823795394467  Training Accuracy:  0.85060376\n",
      "Epoch:  45  Training Loss:  0.4778311525556174  Training Accuracy:  0.8427408\n",
      "Epoch:  46  Training Loss:  0.5535209966654128  Training Accuracy:  0.84919965\n",
      "Epoch:  47  Training Loss:  0.5523000211878256  Training Accuracy:  0.8326313\n",
      "Epoch:  48  Training Loss:  0.6783666571432894  Training Accuracy:  0.8244875\n",
      "Epoch:  49  Training Loss:  0.7298852809450843  Training Accuracy:  0.81943274\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.78821653\n",
      "validation accuracy: 0.78821653\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.333591430837458  Training Accuracy:  0.22999157\n",
      "Epoch:  1  Training Loss:  2.1898512027480384  Training Accuracy:  0.3103061\n",
      "Epoch:  2  Training Loss:  2.015351091189818  Training Accuracy:  0.35720304\n",
      "Epoch:  3  Training Loss:  1.8824534887617284  Training Accuracy:  0.39146307\n",
      "Epoch:  4  Training Loss:  1.7614633039994674  Training Accuracy:  0.43358606\n",
      "Epoch:  5  Training Loss:  1.6499244719743729  Training Accuracy:  0.47655153\n",
      "Epoch:  6  Training Loss:  1.5560035304589706  Training Accuracy:  0.5183937\n",
      "Epoch:  7  Training Loss:  1.4329338084567678  Training Accuracy:  0.55658525\n",
      "Epoch:  8  Training Loss:  1.3216979127038608  Training Accuracy:  0.58382475\n",
      "Epoch:  9  Training Loss:  1.2079225735230879  Training Accuracy:  0.6158382\n",
      "Epoch:  10  Training Loss:  1.1220547567714345  Training Accuracy:  0.627071\n",
      "Epoch:  11  Training Loss:  1.0501677147366784  Training Accuracy:  0.64841336\n",
      "Epoch:  12  Training Loss:  0.9973186452280391  Training Accuracy:  0.65936536\n",
      "Epoch:  13  Training Loss:  0.9678011604330756  Training Accuracy:  0.67340636\n",
      "Epoch:  14  Training Loss:  0.9174823449416594  Training Accuracy:  0.68744737\n",
      "Epoch:  15  Training Loss:  0.9000941376794468  Training Accuracy:  0.70008427\n",
      "Epoch:  16  Training Loss:  0.8500676808032123  Training Accuracy:  0.72086495\n",
      "Epoch:  17  Training Loss:  0.8315276354551315  Training Accuracy:  0.72395396\n",
      "Epoch:  18  Training Loss:  0.7918128398331729  Training Accuracy:  0.74922776\n",
      "Epoch:  19  Training Loss:  0.7512595079161904  Training Accuracy:  0.74361134\n",
      "Epoch:  20  Training Loss:  0.7080412760376931  Training Accuracy:  0.7444538\n",
      "Epoch:  21  Training Loss:  0.6821199258620089  Training Accuracy:  0.76691943\n",
      "Epoch:  22  Training Loss:  0.6612259761853652  Training Accuracy:  0.76242626\n",
      "Epoch:  23  Training Loss:  0.6254230232401328  Training Accuracy:  0.7742207\n",
      "Epoch:  24  Training Loss:  0.5958885829557072  Training Accuracy:  0.76888514\n",
      "Epoch:  25  Training Loss:  0.599625235457312  Training Accuracy:  0.7711317\n",
      "Epoch:  26  Training Loss:  0.5637964080680501  Training Accuracy:  0.77197415\n",
      "Epoch:  27  Training Loss:  0.545274450562217  Training Accuracy:  0.7736591\n",
      "Epoch:  28  Training Loss:  0.5259360312060877  Training Accuracy:  0.78292614\n",
      "Epoch:  29  Training Loss:  0.5080263422971422  Training Accuracy:  0.78404945\n",
      "Epoch:  30  Training Loss:  0.4808904657987031  Training Accuracy:  0.778433\n",
      "Epoch:  31  Training Loss:  0.46725658293474803  Training Accuracy:  0.77955633\n",
      "Epoch:  32  Training Loss:  0.4623628680001606  Training Accuracy:  0.7879809\n",
      "Epoch:  33  Training Loss:  0.44590126397934826  Training Accuracy:  0.7964055\n",
      "Epoch:  34  Training Loss:  0.42991075373508714  Training Accuracy:  0.79696715\n",
      "Epoch:  35  Training Loss:  0.4274951883337714  Training Accuracy:  0.8045493\n",
      "Epoch:  36  Training Loss:  0.42283630167896097  Training Accuracy:  0.81128895\n",
      "Epoch:  37  Training Loss:  0.3954021094197577  Training Accuracy:  0.81915194\n",
      "Epoch:  38  Training Loss:  0.3919690414924513  Training Accuracy:  0.817467\n",
      "Epoch:  39  Training Loss:  0.40002427568489857  Training Accuracy:  0.8180286\n",
      "Epoch:  40  Training Loss:  0.3780955935066396  Training Accuracy:  0.8242067\n",
      "Epoch:  41  Training Loss:  0.38179656842892823  Training Accuracy:  0.8360011\n",
      "Epoch:  42  Training Loss:  0.3872365839779377  Training Accuracy:  0.8289806\n",
      "Epoch:  43  Training Loss:  0.3793826285411011  Training Accuracy:  0.8185903\n",
      "Epoch:  44  Training Loss:  0.36594715172594244  Training Accuracy:  0.8360011\n",
      "Epoch:  45  Training Loss:  0.38491504456509246  Training Accuracy:  0.8441449\n",
      "Epoch:  46  Training Loss:  0.3955578633330085  Training Accuracy:  0.8435833\n",
      "Epoch:  47  Training Loss:  0.4318411752581596  Training Accuracy:  0.8399326\n",
      "Epoch:  48  Training Loss:  0.4575849271633408  Training Accuracy:  0.8306655\n",
      "Epoch:  49  Training Loss:  0.451337650350549  Training Accuracy:  0.82701486\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.7977707\n",
      "validation accuracy: 0.7977707\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.357728303562511  Training Accuracy:  0.20556024\n",
      "Epoch:  1  Training Loss:  2.1926628416234797  Training Accuracy:  0.28615558\n",
      "Epoch:  2  Training Loss:  2.0064339036291297  Training Accuracy:  0.3580455\n",
      "Epoch:  3  Training Loss:  1.8617058764804493  Training Accuracy:  0.42600393\n",
      "Epoch:  4  Training Loss:  1.7273158176378771  Training Accuracy:  0.45885986\n",
      "Epoch:  5  Training Loss:  1.6148031069473787  Training Accuracy:  0.4959281\n",
      "Epoch:  6  Training Loss:  1.4932519993998787  Training Accuracy:  0.516428\n",
      "Epoch:  7  Training Loss:  1.3921708405017852  Training Accuracy:  0.55209213\n",
      "Epoch:  8  Training Loss:  1.2913951307535172  Training Accuracy:  0.55827016\n",
      "Epoch:  9  Training Loss:  1.2035478762604974  Training Accuracy:  0.5967425\n",
      "Epoch:  10  Training Loss:  1.1228208926591006  Training Accuracy:  0.620893\n",
      "Epoch:  11  Training Loss:  1.057717557928779  Training Accuracy:  0.648975\n",
      "Epoch:  12  Training Loss:  1.0059314229271628  Training Accuracy:  0.66217357\n",
      "Epoch:  13  Training Loss:  0.9530535250902176  Training Accuracy:  0.6871665\n",
      "Epoch:  14  Training Loss:  0.912680045041171  Training Accuracy:  0.69896096\n",
      "Epoch:  15  Training Loss:  0.8932029520923441  Training Accuracy:  0.71131706\n",
      "Epoch:  16  Training Loss:  0.8649720332839272  Training Accuracy:  0.72283065\n",
      "Epoch:  17  Training Loss:  0.8341810368678787  Training Accuracy:  0.7233923\n",
      "Epoch:  18  Training Loss:  0.8167584363709797  Training Accuracy:  0.71665263\n",
      "Epoch:  19  Training Loss:  0.7823101110079071  Training Accuracy:  0.7281662\n",
      "Epoch:  20  Training Loss:  0.7635466292500496  Training Accuracy:  0.72591966\n",
      "Epoch:  21  Training Loss:  0.7469424723224206  Training Accuracy:  0.73209774\n",
      "Epoch:  22  Training Loss:  0.7249468061057004  Training Accuracy:  0.7188992\n",
      "Epoch:  23  Training Loss:  0.695169060067697  Training Accuracy:  0.73237854\n",
      "Epoch:  24  Training Loss:  0.6814831239255992  Training Accuracy:  0.7287279\n",
      "Epoch:  25  Training Loss:  0.658905238319527  Training Accuracy:  0.7233923\n",
      "Epoch:  26  Training Loss:  0.6570639342069626  Training Accuracy:  0.74361134\n",
      "Epoch:  27  Training Loss:  0.6458147754723376  Training Accuracy:  0.7312553\n",
      "Epoch:  28  Training Loss:  0.6421545699238778  Training Accuracy:  0.7396799\n",
      "Epoch:  29  Training Loss:  0.614433965222402  Training Accuracy:  0.74473464\n",
      "Epoch:  30  Training Loss:  0.6234873365272176  Training Accuracy:  0.74670035\n",
      "Epoch:  31  Training Loss:  0.6072991581125693  Training Accuracy:  0.7736591\n",
      "Epoch:  32  Training Loss:  0.5789652970704166  Training Accuracy:  0.7820837\n",
      "Epoch:  33  Training Loss:  0.5338733341883529  Training Accuracy:  0.80174106\n",
      "Epoch:  34  Training Loss:  0.5063334101980382  Training Accuracy:  0.8107273\n",
      "Epoch:  35  Training Loss:  0.5061194161122495  Training Accuracy:  0.817467\n",
      "Epoch:  36  Training Loss:  0.48328142843463207  Training Accuracy:  0.81128895\n",
      "Epoch:  37  Training Loss:  0.47693139246918936  Training Accuracy:  0.8152204\n",
      "Epoch:  38  Training Loss:  0.44456672140143133  Training Accuracy:  0.8216793\n",
      "Epoch:  39  Training Loss:  0.4349310789595951  Training Accuracy:  0.8213985\n",
      "Epoch:  40  Training Loss:  0.4187296583571217  Training Accuracy:  0.8298231\n",
      "Epoch:  41  Training Loss:  0.4065534880892797  Training Accuracy:  0.82673407\n",
      "Epoch:  42  Training Loss:  0.39459707791155035  Training Accuracy:  0.82561076\n",
      "Epoch:  43  Training Loss:  0.3866744304922494  Training Accuracy:  0.84779555\n",
      "Epoch:  44  Training Loss:  0.3532005513933572  Training Accuracy:  0.856501\n",
      "Epoch:  45  Training Loss:  0.36600076535885984  Training Accuracy:  0.8553777\n",
      "Epoch:  46  Training Loss:  0.3474611734802073  Training Accuracy:  0.86043245\n",
      "Epoch:  47  Training Loss:  0.33920618735931135  Training Accuracy:  0.86464477\n",
      "Epoch:  48  Training Loss:  0.3274310050024228  Training Accuracy:  0.8668913\n",
      "Epoch:  49  Training Loss:  0.3137712157585404  Training Accuracy:  0.8677338\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.91082805\n",
      "validation accuracy: 0.91082805\n"
     ]
    }
   ],
   "source": [
    "stats2 = Statistics()\n",
    "for i in range(num_experiments):\n",
    "    model.W_conv2_weight = model2.W_conv2_weight\n",
    "    model.b_conv2_weight = model2.b_conv2_weight\n",
    "    model.build_model(load_weights=True)\n",
    "    model.run_model(training_epochs=50, learning_rate=0.0005)\n",
    "    test_accuracy, val_accuracy, y_pred, y_true = model.test()\n",
    "    stats2.add(test_accuracy, val_accuracy, y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy. Mean (std) = 0.833 (0.054)\n",
      "Val accuracy. Mean (std) = 0.833 (0.054)\n",
      "f1 score weighted. Mean (std) = 0.823 (0.064)\n",
      "f1 score mean. Mean (std) = 0.809 (0.060)\n"
     ]
    }
   ],
   "source": [
    "stats2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusions\n",
    "All experiment results are shown in the presentation ***PSDA_ÜB3.pdf***.\n",
    "1. Pre-training facilitates faster convergence for (num_epochs=50, learning_rate=0.0005)\n",
    "2. No visible improvements for pre-training with many epochs (num_epochs=100, learning_rate=0.0001)\n",
    "3. Possible reasons: the tested network is too small, the number epochs is large enough to find the global minimum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}