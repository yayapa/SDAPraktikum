{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Self-training as pretraining\n",
    "The transformation are used as pretext tasks on unlabeled data to learn features.\n",
    "The learnt weights are used for initialization of weights.\n",
    "To see different transformation, look into Transformations notebook.\n",
    "Two types of self-training are tested:\n",
    "1. binary classification, whether the transformation of time series was applied\n",
    "2. multi-task classification, which transformation was applied"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Binary classification\n",
    "Prepare datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dmitrii/anaconda3/envs/work/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from cnn1d_modules import Model, Dataset\n",
    "from transformation import identity, flip, permute, time_warp\n",
    "from statistics import Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH:  /home/dmitrii/GitHub/SDAPraktikum/E3/PAMAP2_Dataset/pamap2.h5\n",
      "x_train shape =  (128247, 52)\n",
      "y_train shape = (128247,)\n",
      "x_test shape = (22659, 52)\n",
      "y_test shape = (22659,)\n",
      "x_train shape(downsampled) =  (42749, 52)\n",
      "y_train shape(downsampled) = (42749,)\n",
      "x_test shape(downsampled) = (7553, 52)\n",
      "y_test shape(downsampled) = (7553,)\n",
      "[ 1  2  3  4  5  6  7 11 12 13 14 18]\n",
      "[ 1  2  3  4  5  6  7 11 12 13 14 18]\n",
      "segmenting signal...\n",
      "signal segmented.\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "PATH:  /home/dmitrii/GitHub/SDAPraktikum/E3/OpportunityUCIDataset/opportunity.h5\n",
      "x_train shape =  (700165, 77)\n",
      "y_train shape = (700165,)\n",
      "x_test shape = (120516, 77)\n",
      "y_test shape = (120516,)\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "segmenting signal...\n",
      "signal segmented.\n",
      "train_x shape = (63650, 23, 77)\n",
      "train_y shape = (63650,)\n",
      "test_x shape = (10955, 23, 77)\n",
      "test_y shape = (10955,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[[-9.830e-01, -1.990e-01,  1.190e-01, ...,  2.000e-02,\n           4.200e-02,  1.750e-01],\n         [-9.860e-01, -2.200e-01,  1.140e-01, ...,  1.700e-02,\n           3.100e-02,  1.750e-01],\n         [-9.870e-01, -2.270e-01,  1.120e-01, ..., -2.700e-02,\n           1.500e-02,  1.750e-01],\n         ...,\n         [-9.720e-01, -1.420e-01,  6.900e-02, ..., -4.500e-02,\n           5.800e-02,  1.750e-01],\n         [-9.680e-01, -1.420e-01,  6.400e-02, ..., -1.600e-02,\n           4.400e-02,  1.750e-01],\n         [-9.650e-01, -1.450e-01,  8.700e-02, ...,  8.700e-02,\n           2.400e-02,  1.750e-01]],\n \n        [[-9.990e-01, -1.420e-01,  1.190e-01, ..., -4.000e-03,\n           9.000e-03,  1.750e-01],\n         [-9.710e-01, -1.370e-01,  9.000e-02, ..., -1.300e-02,\n           2.000e-02,  1.750e-01],\n         [-9.680e-01, -1.530e-01,  6.900e-02, ..., -7.000e-03,\n           1.500e-02,  1.750e-01],\n         ...,\n         [-9.640e-01, -1.050e-01,  1.700e-02, ..., -5.400e-02,\n          -3.459e+00,  1.760e-01],\n         [-9.770e-01, -1.250e-01,  3.000e-03, ...,  9.790e-01,\n          -5.223e+00,  1.740e-01],\n         [-9.880e-01, -1.520e-01,  4.700e-02, ..., -1.306e+00,\n          -2.782e+00,  1.720e-01]],\n \n        [[-9.650e-01, -1.450e-01,  8.700e-02, ...,  8.700e-02,\n           2.400e-02,  1.750e-01],\n         [-9.700e-01, -1.390e-01,  9.000e-02, ...,  3.800e-02,\n           4.200e-02,  1.750e-01],\n         [-9.870e-01, -1.300e-01,  8.000e-02, ...,  2.360e-01,\n           6.200e-02,  1.760e-01],\n         ...,\n         [-9.540e-01, -2.360e-01,  1.170e-01, ..., -5.100e-02,\n          -3.000e-03,  1.700e-01],\n         [-9.400e-01, -2.430e-01,  9.600e-02, ..., -1.400e-02,\n          -2.700e-02,  1.700e-01],\n         [-9.290e-01, -2.580e-01,  8.200e-02, ...,  1.300e-02,\n          -2.600e-02,  1.700e-01]],\n \n        ...,\n \n        [[-9.840e-01, -1.240e-01,  7.800e-02, ..., -1.900e-02,\n          -2.000e-02, -7.700e-02],\n         [-9.790e-01, -1.340e-01,  7.500e-02, ...,  3.700e-02,\n           9.000e-03, -7.700e-02],\n         [-9.860e-01, -1.310e-01,  7.700e-02, ...,  5.000e-03,\n          -1.000e-03, -7.700e-02],\n         ...,\n         [-9.880e-01, -1.250e-01,  8.300e-02, ..., -8.000e-03,\n           2.100e-02, -7.700e-02],\n         [-9.920e-01, -1.220e-01,  7.700e-02, ..., -1.400e-02,\n           1.200e-02, -7.700e-02],\n         [-9.960e-01, -1.290e-01,  7.500e-02, ..., -1.600e-02,\n          -1.500e-02, -7.700e-02]],\n \n        [[-9.810e-01, -1.190e-01,  8.700e-02, ..., -1.000e-03,\n           1.200e-02, -7.700e-02],\n         [-9.810e-01, -1.180e-01,  8.800e-02, ...,  0.000e+00,\n           1.200e-02, -7.700e-02],\n         [-9.850e-01, -1.160e-01,  8.700e-02, ...,  3.200e-02,\n           2.500e-02, -7.700e-02],\n         ...,\n         [-9.970e-01, -1.310e-01,  7.400e-02, ...,  1.200e-02,\n           3.400e-02, -7.700e-02],\n         [-9.940e-01, -1.150e-01,  7.300e-02, ..., -2.200e-02,\n           3.100e-02, -7.700e-02],\n         [-9.940e-01, -1.360e-01,  7.700e-02, ..., -1.500e-02,\n           6.000e-03, -7.700e-02]],\n \n        [[-9.960e-01, -1.290e-01,  7.500e-02, ..., -1.600e-02,\n          -1.500e-02, -7.700e-02],\n         [-9.930e-01, -1.250e-01,  7.500e-02, ...,  3.000e-03,\n          -7.000e-03, -7.700e-02],\n         [-9.910e-01, -1.270e-01,  7.400e-02, ...,  3.000e-03,\n           1.100e-02, -7.700e-02],\n         ...,\n         [-9.890e-01, -1.280e-01,  8.800e-02, ...,  1.000e-03,\n          -2.600e-02, -7.700e-02],\n         [-9.840e-01, -1.420e-01,  8.600e-02, ..., -1.500e-02,\n           3.500e-02, -7.700e-02],\n         [-9.850e-01, -1.660e-01,  8.600e-02, ...,  0.000e+00,\n           2.000e-03, -7.700e-02]]]),\n array([1., 1., 1., ..., 1., 1., 1.]),\n array([[[-9.620e-01, -1.660e-01,  9.600e-02, ...,  0.000e+00,\n           3.000e-03,  1.390e-01],\n         [-9.610e-01, -1.550e-01,  7.900e-02, ...,  6.000e-03,\n           3.900e-02,  1.400e-01],\n         [-9.810e-01, -1.510e-01,  6.900e-02, ...,  5.000e-03,\n           3.700e-02,  1.400e-01],\n         ...,\n         [-9.900e-01, -1.730e-01,  3.600e-02, ...,  1.700e-02,\n          -3.500e-02,  1.390e-01],\n         [-9.630e-01, -1.540e-01,  2.700e-02, ..., -7.000e-03,\n           4.300e-02,  1.390e-01],\n         [-9.710e-01, -1.500e-01,  2.700e-02, ..., -2.300e-02,\n           1.300e-02,  1.400e-01]],\n \n        [[-9.900e-01, -1.530e-01,  5.700e-02, ...,  9.000e-03,\n           1.600e-02,  1.400e-01],\n         [-9.850e-01, -1.750e-01,  6.900e-02, ..., -2.000e-02,\n           2.600e-02,  1.390e-01],\n         [-9.890e-01, -1.960e-01,  1.000e-02, ..., -4.400e-02,\n           5.000e-03,  1.380e-01],\n         ...,\n         [-1.003e+00, -1.680e-01,  1.600e-02, ...,  2.500e-02,\n           3.700e-02,  1.410e-01],\n         [-9.940e-01, -1.800e-01,  6.000e-03, ..., -9.000e-03,\n           1.600e-02,  1.410e-01],\n         [-9.890e-01, -1.800e-01,  7.000e-03, ...,  1.000e-03,\n           3.000e-03,  1.400e-01]],\n \n        [[-9.710e-01, -1.500e-01,  2.700e-02, ..., -2.300e-02,\n           1.300e-02,  1.400e-01],\n         [-9.760e-01, -1.510e-01,  4.000e-02, ..., -2.000e-03,\n          -8.000e-03,  1.400e-01],\n         [-9.920e-01, -1.450e-01,  3.000e-02, ...,  1.200e-02,\n           3.000e-02,  1.390e-01],\n         ...,\n         [-9.900e-01, -1.610e-01,  1.500e-02, ...,  7.000e-03,\n           0.000e+00,  1.400e-01],\n         [-9.850e-01, -1.560e-01,  6.000e-03, ...,  1.500e-02,\n          -3.500e-02,  1.400e-01],\n         [-9.810e-01, -1.610e-01,  1.000e-03, ..., -1.600e-02,\n           5.000e-03,  1.400e-01]],\n \n        ...,\n \n        [[-9.690e-01, -4.600e-02,  2.530e-01, ..., -2.900e-02,\n          -1.500e-02,  1.200e-02],\n         [-9.660e-01, -4.300e-02,  2.530e-01, ...,  5.200e-02,\n           2.200e-02,  1.200e-02],\n         [-9.710e-01, -4.500e-02,  2.500e-01, ...,  1.700e-02,\n           0.000e+00,  1.200e-02],\n         ...,\n         [-9.720e-01, -3.600e-02,  2.480e-01, ...,  9.000e-03,\n           2.300e-02,  1.200e-02],\n         [-9.690e-01, -4.300e-02,  2.620e-01, ...,  1.100e-02,\n           3.500e-02,  1.200e-02],\n         [-9.660e-01, -3.600e-02,  2.500e-01, ..., -1.500e-02,\n          -2.000e-03,  1.200e-02]],\n \n        [[-9.670e-01, -3.900e-02,  2.490e-01, ..., -1.800e-02,\n           1.100e-02,  1.200e-02],\n         [-9.690e-01, -4.100e-02,  2.530e-01, ..., -1.200e-02,\n          -2.800e-02,  1.200e-02],\n         [-9.700e-01, -4.000e-02,  2.540e-01, ..., -1.200e-02,\n          -1.200e-02,  1.200e-02],\n         ...,\n         [-9.710e-01, -5.000e-02,  2.510e-01, ...,  2.800e-02,\n          -1.700e-02,  1.200e-02],\n         [-9.690e-01, -5.000e-02,  2.500e-01, ..., -8.000e-03,\n          -6.000e-02,  1.200e-02],\n         [-9.670e-01, -4.900e-02,  2.470e-01, ...,  2.800e-02,\n          -1.400e-02,  1.200e-02]],\n \n        [[ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00],\n         [ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00],\n         [ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00],\n         ...,\n         [ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00],\n         [ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00],\n         [ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00]]]),\n array([1., 1., 1., ..., 1., 1., 0.]))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_obj = Dataset(\"pa2\")\n",
    "dataset_obj.read_dataset()\n",
    "dataset_obj.downsample_dataset()\n",
    "dataset_obj.segment_dataset()\n",
    "\n",
    "dataset_obj2 = Dataset(\"opp\")\n",
    "dataset_obj2.read_dataset()\n",
    "dataset_obj2.downsample_dataset()\n",
    "dataset_obj2.segment_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train on pretext task: flip transformation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opp\n",
      "X shape = (?, 1, 23, 77)\n",
      "Y shape = (?, 2)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 77, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 17, 128)\n",
      "h_pool1 shape = (?, 1, 6, 128)\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 4, 128)\n",
      "h_pool2 shape = (?, 1, 1, 128)\n",
      "shape's shape: [None, 1, 1, 128]\n",
      "c_flat shape = (?, 128)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (63650, 18)\n",
      "test_y shape(1-hot) = (10955, 18)\n",
      "train_x_reshaped =  (63650, 1, 23, 77)\n",
      "test_x_reshaped =  (10955, 1, 23, 77)\n",
      "train_x shape = (63650, 23, 77)\n",
      "train_y shape = (63650,)\n",
      "test_x shape = (10955, 23, 77)\n",
      "test_y shape = (10955,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/GitHub/SDAPraktikum/E3/transformation.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  splitted = np.array(np.split(sample_i, np.append(segments, sample.shape[1])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Training Loss:  0.7602719527854765  Training Accuracy:  0.6125845\n",
      "Epoch:  1  Training Loss:  0.6128162098842368  Training Accuracy:  0.65142184\n",
      "Epoch:  2  Training Loss:  0.5795984004944623  Training Accuracy:  0.69690496\n",
      "Epoch:  3  Training Loss:  0.5687582880198596  Training Accuracy:  0.6968892\n",
      "Epoch:  4  Training Loss:  0.5644364662513407  Training Accuracy:  0.700817\n",
      "Epoch:  5  Training Loss:  0.5512849999145722  Training Accuracy:  0.69692063\n",
      "Epoch:  6  Training Loss:  0.5477574938979427  Training Accuracy:  0.70904946\n",
      "Epoch:  7  Training Loss:  0.5467037666791401  Training Accuracy:  0.7113119\n",
      "Epoch:  8  Training Loss:  0.536135811950839  Training Accuracy:  0.7180676\n"
     ]
    }
   ],
   "source": [
    "model2 = Model(dataset_obj2)\n",
    "model2.build_model(self_training=True, num_transforms=2)\n",
    "transforms = [identity, permute]\n",
    "model2.self_train(transforms, 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model = Model(dataset_obj)\n",
    "stats = Statistics()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.424260291186246  Training Accuracy:  0.22690256\n",
      "Epoch:  1  Training Loss:  2.0981661926616324  Training Accuracy:  0.3232238\n",
      "Epoch:  2  Training Loss:  1.89937696240165  Training Accuracy:  0.39202473\n",
      "Epoch:  3  Training Loss:  1.7363032844933597  Training Accuracy:  0.44004494\n",
      "Epoch:  4  Training Loss:  1.5785949988798662  Training Accuracy:  0.47149676\n",
      "Epoch:  5  Training Loss:  1.4310157280076634  Training Accuracy:  0.5012637\n",
      "Epoch:  6  Training Loss:  1.314735661311583  Training Accuracy:  0.5464757\n",
      "Epoch:  7  Training Loss:  1.2177152156829834  Training Accuracy:  0.58242065\n",
      "Epoch:  8  Training Loss:  1.1215237980539148  Training Accuracy:  0.61218756\n",
      "Epoch:  9  Training Loss:  1.0516582475467162  Training Accuracy:  0.6402696\n",
      "Epoch:  10  Training Loss:  0.9817088105461814  Training Accuracy:  0.6618927\n",
      "Epoch:  11  Training Loss:  0.9147212600166147  Training Accuracy:  0.6826734\n",
      "Epoch:  12  Training Loss:  0.858596862446178  Training Accuracy:  0.70008427\n",
      "Epoch:  13  Training Loss:  0.8126277929002589  Training Accuracy:  0.72114575\n",
      "Epoch:  14  Training Loss:  0.7753949466076764  Training Accuracy:  0.71974164\n",
      "Epoch:  15  Training Loss:  0.7121282065456563  Training Accuracy:  0.727043\n",
      "Epoch:  16  Training Loss:  0.6836468872698871  Training Accuracy:  0.73799497\n",
      "Epoch:  17  Training Loss:  0.6437459436329929  Training Accuracy:  0.7438922\n",
      "Epoch:  18  Training Loss:  0.6201187160882082  Training Accuracy:  0.767481\n",
      "Epoch:  19  Training Loss:  0.6087311362678355  Training Accuracy:  0.77646726\n",
      "Epoch:  20  Training Loss:  0.5936531477353789  Training Accuracy:  0.778433\n",
      "Epoch:  21  Training Loss:  0.5836822187358682  Training Accuracy:  0.7770289\n",
      "Epoch:  22  Training Loss:  0.5895342569459568  Training Accuracy:  0.7834878\n",
      "Epoch:  23  Training Loss:  0.591322882744399  Training Accuracy:  0.7739399\n",
      "Epoch:  24  Training Loss:  0.6090368335897273  Training Accuracy:  0.7868576\n",
      "Epoch:  25  Training Loss:  0.6205683017318899  Training Accuracy:  0.7801179\n",
      "Epoch:  26  Training Loss:  0.5606746921485121  Training Accuracy:  0.8169054\n",
      "Epoch:  27  Training Loss:  0.4457553268833594  Training Accuracy:  0.8301039\n",
      "Epoch:  28  Training Loss:  0.40591650503602894  Training Accuracy:  0.8230834\n",
      "Epoch:  29  Training Loss:  0.3814766998318109  Training Accuracy:  0.8326313\n",
      "Epoch:  30  Training Loss:  0.35955919989130714  Training Accuracy:  0.82841897\n",
      "Epoch:  31  Training Loss:  0.37315721010619946  Training Accuracy:  0.83656275\n",
      "Epoch:  32  Training Loss:  0.3474088458175009  Training Accuracy:  0.8360011\n",
      "Epoch:  33  Training Loss:  0.3426602763208476  Training Accuracy:  0.8374052\n",
      "Epoch:  34  Training Loss:  0.33972605581987986  Training Accuracy:  0.83824766\n",
      "Epoch:  35  Training Loss:  0.3429607500406829  Training Accuracy:  0.8357203\n",
      "Epoch:  36  Training Loss:  0.36253574290736157  Training Accuracy:  0.8298231\n",
      "Epoch:  37  Training Loss:  0.37372725971720433  Training Accuracy:  0.8275765\n",
      "Epoch:  38  Training Loss:  0.3923873356797478  Training Accuracy:  0.84470654\n",
      "Epoch:  39  Training Loss:  0.45831270289014686  Training Accuracy:  0.8289806\n",
      "Epoch:  40  Training Loss:  0.48273465271023186  Training Accuracy:  0.845549\n",
      "Epoch:  41  Training Loss:  0.6493766070089557  Training Accuracy:  0.82364506\n",
      "Epoch:  42  Training Loss:  0.6936172192746942  Training Accuracy:  0.8371244\n",
      "Epoch:  43  Training Loss:  0.8094258218665015  Training Accuracy:  0.81381637\n",
      "Epoch:  44  Training Loss:  0.901905439116738  Training Accuracy:  0.8076383\n",
      "Epoch:  45  Training Loss:  1.1607283365320076  Training Accuracy:  0.7792755\n",
      "Epoch:  46  Training Loss:  1.3809316096658057  Training Accuracy:  0.77983713\n",
      "Epoch:  47  Training Loss:  1.892658176713369  Training Accuracy:  0.7489469\n",
      "Epoch:  48  Training Loss:  2.2376990623433484  Training Accuracy:  0.77983713\n",
      "Epoch:  49  Training Loss:  2.5513880976221777  Training Accuracy:  0.7660769\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.6990446\n",
      "validation accuracy: 0.6990446\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.4610214320096104  Training Accuracy:  0.2429093\n",
      "Epoch:  1  Training Loss:  2.152508993582292  Training Accuracy:  0.29177198\n",
      "Epoch:  2  Training Loss:  1.9453655324198984  Training Accuracy:  0.32968268\n",
      "Epoch:  3  Training Loss:  1.7775288137522611  Training Accuracy:  0.37601796\n",
      "Epoch:  4  Training Loss:  1.6125811538913033  Training Accuracy:  0.44818872\n",
      "Epoch:  5  Training Loss:  1.451950918002562  Training Accuracy:  0.52064025\n",
      "Epoch:  6  Training Loss:  1.3059347607872702  Training Accuracy:  0.5706262\n",
      "Epoch:  7  Training Loss:  1.208433023095131  Training Accuracy:  0.6023589\n",
      "Epoch:  8  Training Loss:  1.135317690535025  Training Accuracy:  0.63437235\n",
      "Epoch:  9  Training Loss:  1.0485155113718727  Training Accuracy:  0.65487224\n",
      "Epoch:  10  Training Loss:  0.9666310854933479  Training Accuracy:  0.6908172\n",
      "Epoch:  11  Training Loss:  0.9204933532259681  Training Accuracy:  0.7059815\n",
      "Epoch:  12  Training Loss:  0.8483446048064666  Training Accuracy:  0.7205841\n",
      "Epoch:  13  Training Loss:  0.8054177538915114  Training Accuracy:  0.73350185\n",
      "Epoch:  14  Training Loss:  0.7526967433365909  Training Accuracy:  0.73687166\n",
      "Epoch:  15  Training Loss:  0.6918224881995808  Training Accuracy:  0.7601797\n",
      "Epoch:  16  Training Loss:  0.65597828369249  Training Accuracy:  0.7629879\n",
      "Epoch:  17  Training Loss:  0.6087007988582958  Training Accuracy:  0.76691943\n",
      "Epoch:  18  Training Loss:  0.5813762716271661  Training Accuracy:  0.79837126\n",
      "Epoch:  19  Training Loss:  0.5559161954305388  Training Accuracy:  0.7961247\n",
      "Epoch:  20  Training Loss:  0.5226875603199005  Training Accuracy:  0.8025835\n",
      "Epoch:  21  Training Loss:  0.48850203400308434  Training Accuracy:  0.80960405\n",
      "Epoch:  22  Training Loss:  0.4810545257546685  Training Accuracy:  0.8247683\n",
      "Epoch:  23  Training Loss:  0.4740202695131302  Training Accuracy:  0.82645327\n",
      "Epoch:  24  Training Loss:  0.44718795249407944  Training Accuracy:  0.82392585\n",
      "Epoch:  25  Training Loss:  0.4460821230980483  Training Accuracy:  0.8427408\n",
      "Epoch:  26  Training Loss:  0.41609750762581826  Training Accuracy:  0.83909017\n",
      "Epoch:  27  Training Loss:  0.43502514084631744  Training Accuracy:  0.83375454\n",
      "Epoch:  28  Training Loss:  0.3888934530995109  Training Accuracy:  0.8399326\n",
      "Epoch:  29  Training Loss:  0.37302669828588314  Training Accuracy:  0.8452682\n",
      "Epoch:  30  Training Loss:  0.37133944932032714  Training Accuracy:  0.8427408\n",
      "Epoch:  31  Training Loss:  0.3559710707515478  Training Accuracy:  0.8404942\n",
      "Epoch:  32  Training Loss:  0.3521224090998823  Training Accuracy:  0.8469531\n",
      "Epoch:  33  Training Loss:  0.356647043641318  Training Accuracy:  0.83206964\n",
      "Epoch:  34  Training Loss:  0.34776091484183613  Training Accuracy:  0.8480764\n",
      "Epoch:  35  Training Loss:  0.33374830707907677  Training Accuracy:  0.8483572\n",
      "Epoch:  36  Training Loss:  0.3288694863292304  Training Accuracy:  0.84779555\n",
      "Epoch:  37  Training Loss:  0.34863155690783804  Training Accuracy:  0.83796686\n",
      "Epoch:  38  Training Loss:  0.36403197464956477  Training Accuracy:  0.85200787\n",
      "Epoch:  39  Training Loss:  0.3428946885872971  Training Accuracy:  0.84246\n",
      "Epoch:  40  Training Loss:  0.43279781692068686  Training Accuracy:  0.8441449\n",
      "Epoch:  41  Training Loss:  0.5058858222582123  Training Accuracy:  0.8076383\n",
      "Epoch:  42  Training Loss:  0.45262488864192907  Training Accuracy:  0.8059534\n",
      "Epoch:  43  Training Loss:  0.5276082572950558  Training Accuracy:  0.8199944\n",
      "Epoch:  44  Training Loss:  0.5880021962591193  Training Accuracy:  0.78713846\n",
      "Epoch:  45  Training Loss:  0.6594228905371644  Training Accuracy:  0.8169054\n",
      "Epoch:  46  Training Loss:  0.7596586273898456  Training Accuracy:  0.8045493\n",
      "Epoch:  47  Training Loss:  1.0156962675804442  Training Accuracy:  0.8042685\n",
      "Epoch:  48  Training Loss:  1.155058310959827  Training Accuracy:  0.803426\n",
      "Epoch:  49  Training Loss:  1.2549769203771244  Training Accuracy:  0.7756248\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.78503186\n",
      "validation accuracy: 0.78503186\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.428789921240373  Training Accuracy:  0.21566975\n",
      "Epoch:  1  Training Loss:  2.1445510387420654  Training Accuracy:  0.3105869\n",
      "Epoch:  2  Training Loss:  1.9271774449131704  Training Accuracy:  0.34905925\n",
      "Epoch:  3  Training Loss:  1.7910497283393687  Training Accuracy:  0.4004493\n",
      "Epoch:  4  Training Loss:  1.6775303865020925  Training Accuracy:  0.45773658\n",
      "Epoch:  5  Training Loss:  1.575254019282081  Training Accuracy:  0.50772256\n",
      "Epoch:  6  Training Loss:  1.4395426460287788  Training Accuracy:  0.55827016\n",
      "Epoch:  7  Training Loss:  1.316828271204775  Training Accuracy:  0.59926987\n",
      "Epoch:  8  Training Loss:  1.2195872474800458  Training Accuracy:  0.6144341\n",
      "Epoch:  9  Training Loss:  1.1030046796256845  Training Accuracy:  0.6335299\n",
      "Epoch:  10  Training Loss:  1.0456433919343082  Training Accuracy:  0.648975\n",
      "Epoch:  11  Training Loss:  0.9574690173972736  Training Accuracy:  0.67059815\n",
      "Epoch:  12  Training Loss:  0.9096975256096232  Training Accuracy:  0.6793036\n",
      "Epoch:  13  Training Loss:  0.8610972409898584  Training Accuracy:  0.6756529\n",
      "Epoch:  14  Training Loss:  0.8229506542736834  Training Accuracy:  0.7048582\n",
      "Epoch:  15  Training Loss:  0.7633446165106513  Training Accuracy:  0.7124403\n",
      "Epoch:  16  Training Loss:  0.7234554109248248  Training Accuracy:  0.705139\n",
      "Epoch:  17  Training Loss:  0.6719877313483845  Training Accuracy:  0.73715246\n",
      "Epoch:  18  Training Loss:  0.6382898026569324  Training Accuracy:  0.761303\n",
      "Epoch:  19  Training Loss:  0.5856969836083326  Training Accuracy:  0.78320694\n",
      "Epoch:  20  Training Loss:  0.5551043892448598  Training Accuracy:  0.7902275\n",
      "Epoch:  21  Training Loss:  0.5145470238544724  Training Accuracy:  0.7994945\n",
      "Epoch:  22  Training Loss:  0.5104673185131766  Training Accuracy:  0.78854257\n",
      "Epoch:  23  Training Loss:  0.4787997705692595  Training Accuracy:  0.81381637\n",
      "Epoch:  24  Training Loss:  0.46334326294335454  Training Accuracy:  0.8121314\n",
      "Epoch:  25  Training Loss:  0.4405651478604837  Training Accuracy:  0.8228026\n",
      "Epoch:  26  Training Loss:  0.4224652534858747  Training Accuracy:  0.8343162\n",
      "Epoch:  27  Training Loss:  0.4075846410610459  Training Accuracy:  0.83909017\n",
      "Epoch:  28  Training Loss:  0.40068194859407164  Training Accuracy:  0.85060376\n",
      "Epoch:  29  Training Loss:  0.390400865199891  Training Accuracy:  0.85565853\n",
      "Epoch:  30  Training Loss:  0.39779039817777545  Training Accuracy:  0.85706264\n",
      "Epoch:  31  Training Loss:  0.3767904320223765  Training Accuracy:  0.8531311\n",
      "Epoch:  32  Training Loss:  0.3787782942706888  Training Accuracy:  0.8233642\n",
      "Epoch:  33  Training Loss:  0.3966471007601781  Training Accuracy:  0.8286998\n",
      "Epoch:  34  Training Loss:  0.41355542405085133  Training Accuracy:  0.8494805\n",
      "Epoch:  35  Training Loss:  0.3362952972677621  Training Accuracy:  0.86969954\n",
      "Epoch:  36  Training Loss:  0.3221684058620171  Training Accuracy:  0.8660489\n",
      "Epoch:  37  Training Loss:  0.34003037569875066  Training Accuracy:  0.8812131\n",
      "Epoch:  38  Training Loss:  0.3106748788194223  Training Accuracy:  0.8795282\n",
      "Epoch:  39  Training Loss:  0.32911588563160465  Training Accuracy:  0.88542545\n",
      "Epoch:  40  Training Loss:  0.2914357125251131  Training Accuracy:  0.89160347\n",
      "Epoch:  41  Training Loss:  0.3084661217914386  Training Accuracy:  0.8685762\n",
      "Epoch:  42  Training Loss:  0.3054903841831467  Training Accuracy:  0.88570625\n",
      "Epoch:  43  Training Loss:  0.33576446534557775  Training Accuracy:  0.8800899\n",
      "Epoch:  44  Training Loss:  0.377057039805434  Training Accuracy:  0.8668913\n",
      "Epoch:  45  Training Loss:  0.38565530522980473  Training Accuracy:  0.87166524\n",
      "Epoch:  46  Training Loss:  0.4782951249995015  Training Accuracy:  0.8609941\n",
      "Epoch:  47  Training Loss:  0.48666433705524964  Training Accuracy:  0.8666105\n",
      "Epoch:  48  Training Loss:  0.5503823507407849  Training Accuracy:  0.86352146\n",
      "Epoch:  49  Training Loss:  0.6102908483960412  Training Accuracy:  0.8247683\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.85987264\n",
      "validation accuracy: 0.85987264\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.463963107629256  Training Accuracy:  0.17495085\n",
      "Epoch:  1  Training Loss:  2.235682953487743  Training Accuracy:  0.29008704\n",
      "Epoch:  2  Training Loss:  2.0068448630246247  Training Accuracy:  0.3751755\n",
      "Epoch:  3  Training Loss:  1.7924386544661088  Training Accuracy:  0.44285312\n",
      "Epoch:  4  Training Loss:  1.6035490014336327  Training Accuracy:  0.49115416\n",
      "Epoch:  5  Training Loss:  1.4454345827752895  Training Accuracy:  0.52344847\n",
      "Epoch:  6  Training Loss:  1.3038632975383238  Training Accuracy:  0.5509688\n",
      "Epoch:  7  Training Loss:  1.20646566640247  Training Accuracy:  0.589722\n",
      "Epoch:  8  Training Loss:  1.0940361581065439  Training Accuracy:  0.61050266\n",
      "Epoch:  9  Training Loss:  1.0383442334153437  Training Accuracy:  0.623982\n",
      "Epoch:  10  Training Loss:  0.9731577827171846  Training Accuracy:  0.64813256\n",
      "Epoch:  11  Training Loss:  0.9090996620329943  Training Accuracy:  0.6669475\n",
      "Epoch:  12  Training Loss:  0.8603020810268142  Training Accuracy:  0.67537206\n",
      "Epoch:  13  Training Loss:  0.8082597521218386  Training Accuracy:  0.69278294\n",
      "Epoch:  14  Training Loss:  0.7632890270514922  Training Accuracy:  0.71131706\n",
      "Epoch:  15  Training Loss:  0.7553202111612667  Training Accuracy:  0.7250772\n",
      "Epoch:  16  Training Loss:  0.7676595338366249  Training Accuracy:  0.73097444\n",
      "Epoch:  17  Training Loss:  0.8135522968389771  Training Accuracy:  0.7026116\n",
      "Epoch:  18  Training Loss:  0.9992235713384369  Training Accuracy:  0.6995226\n",
      "Epoch:  19  Training Loss:  0.7988236623731526  Training Accuracy:  0.73687166\n",
      "Epoch:  20  Training Loss:  0.6279497157443653  Training Accuracy:  0.74670035\n",
      "Epoch:  21  Training Loss:  0.5789764953607862  Training Accuracy:  0.7520359\n",
      "Epoch:  22  Training Loss:  0.5358384949239817  Training Accuracy:  0.758214\n",
      "Epoch:  23  Training Loss:  0.5219293354587121  Training Accuracy:  0.75877565\n",
      "Epoch:  24  Training Loss:  0.5173683299598368  Training Accuracy:  0.77309746\n",
      "Epoch:  25  Training Loss:  0.504970072819428  Training Accuracy:  0.772255\n",
      "Epoch:  26  Training Loss:  0.4891112613407048  Training Accuracy:  0.77590567\n",
      "Epoch:  27  Training Loss:  0.469172826544805  Training Accuracy:  0.78713846\n",
      "Epoch:  28  Training Loss:  0.4328486464240334  Training Accuracy:  0.80005616\n",
      "Epoch:  29  Training Loss:  0.4172560370781205  Training Accuracy:  0.7975288\n",
      "Epoch:  30  Training Loss:  0.41634997681460595  Training Accuracy:  0.8149396\n",
      "Epoch:  31  Training Loss:  0.4054652517492121  Training Accuracy:  0.8188711\n",
      "Epoch:  32  Training Loss:  0.38346196379173886  Training Accuracy:  0.8171862\n",
      "Epoch:  33  Training Loss:  0.37852840838445856  Training Accuracy:  0.8371244\n",
      "Epoch:  34  Training Loss:  0.39164625145494936  Training Accuracy:  0.83824766\n",
      "Epoch:  35  Training Loss:  0.3728459074585275  Training Accuracy:  0.8531311\n",
      "Epoch:  36  Training Loss:  0.42494016790931877  Training Accuracy:  0.8289806\n",
      "Epoch:  37  Training Loss:  0.45980966809121043  Training Accuracy:  0.83319294\n",
      "Epoch:  38  Training Loss:  0.49373573715036567  Training Accuracy:  0.83628196\n",
      "Epoch:  39  Training Loss:  0.5900292599743063  Training Accuracy:  0.83796686\n",
      "Epoch:  40  Training Loss:  0.6765933508222753  Training Accuracy:  0.82532996\n",
      "Epoch:  41  Training Loss:  0.8331211871721528  Training Accuracy:  0.8090424\n",
      "Epoch:  42  Training Loss:  1.0974588381295853  Training Accuracy:  0.82083684\n",
      "Epoch:  43  Training Loss:  1.1589388056573542  Training Accuracy:  0.786296\n",
      "Epoch:  44  Training Loss:  1.6892346094955097  Training Accuracy:  0.7739399\n",
      "Epoch:  45  Training Loss:  1.9192318334498188  Training Accuracy:  0.74361134\n",
      "Epoch:  46  Training Loss:  2.2364774116399615  Training Accuracy:  0.75091267\n",
      "Epoch:  47  Training Loss:  3.369038042290644  Training Accuracy:  0.74192643\n",
      "Epoch:  48  Training Loss:  4.373321996493773  Training Accuracy:  0.7121595\n",
      "Epoch:  49  Training Loss:  5.351303124698726  Training Accuracy:  0.7500702\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.72611463\n",
      "validation accuracy: 0.72611463\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.434925588694486  Training Accuracy:  0.21566975\n",
      "Epoch:  1  Training Loss:  2.1906783949245106  Training Accuracy:  0.3018815\n",
      "Epoch:  2  Training Loss:  1.9921973412687128  Training Accuracy:  0.393148\n",
      "Epoch:  3  Training Loss:  1.8003962934017181  Training Accuracy:  0.45155856\n",
      "Epoch:  4  Training Loss:  1.6118606215173548  Training Accuracy:  0.51474303\n",
      "Epoch:  5  Training Loss:  1.457072925567627  Training Accuracy:  0.5529346\n",
      "Epoch:  6  Training Loss:  1.3135742008686067  Training Accuracy:  0.5796125\n",
      "Epoch:  7  Training Loss:  1.1874445042826913  Training Accuracy:  0.62426287\n",
      "Epoch:  8  Training Loss:  1.1192411842671308  Training Accuracy:  0.64420104\n",
      "Epoch:  9  Training Loss:  1.0378627075390383  Training Accuracy:  0.6388655\n",
      "Epoch:  10  Training Loss:  0.9549837871031328  Training Accuracy:  0.64700925\n",
      "Epoch:  11  Training Loss:  0.9166967652060769  Training Accuracy:  0.64055043\n",
      "Epoch:  12  Training Loss:  0.8607988059520721  Training Accuracy:  0.66891325\n",
      "Epoch:  13  Training Loss:  0.8063206076622009  Training Accuracy:  0.6686324\n",
      "Epoch:  14  Training Loss:  0.7569461585445838  Training Accuracy:  0.6953103\n",
      "Epoch:  15  Training Loss:  0.7139674606648359  Training Accuracy:  0.70008427\n",
      "Epoch:  16  Training Loss:  0.6694258051839742  Training Accuracy:  0.7264813\n",
      "Epoch:  17  Training Loss:  0.6235125129873103  Training Accuracy:  0.7430497\n",
      "Epoch:  18  Training Loss:  0.6016524476083842  Training Accuracy:  0.74501544\n",
      "Epoch:  19  Training Loss:  0.5707896267825907  Training Accuracy:  0.75596744\n",
      "Epoch:  20  Training Loss:  0.5573509569872509  Training Accuracy:  0.7789947\n",
      "Epoch:  21  Training Loss:  0.5492219670252366  Training Accuracy:  0.7756248\n",
      "Epoch:  22  Training Loss:  0.5161166923967275  Training Accuracy:  0.786296\n",
      "Epoch:  23  Training Loss:  0.4997939640825445  Training Accuracy:  0.79724795\n",
      "Epoch:  24  Training Loss:  0.482487144659866  Training Accuracy:  0.78882337\n",
      "Epoch:  25  Training Loss:  0.4697343980724161  Training Accuracy:  0.7978096\n",
      "Epoch:  26  Training Loss:  0.45683611184358597  Training Accuracy:  0.80033696\n",
      "Epoch:  27  Training Loss:  0.44174592176621613  Training Accuracy:  0.80679584\n",
      "Epoch:  28  Training Loss:  0.43674977083097805  Training Accuracy:  0.80033696\n",
      "Epoch:  29  Training Loss:  0.42387643070383507  Training Accuracy:  0.758214\n",
      "Epoch:  30  Training Loss:  0.43577253100546925  Training Accuracy:  0.7486661\n",
      "Epoch:  31  Training Loss:  0.4266509240323847  Training Accuracy:  0.7556866\n",
      "Epoch:  32  Training Loss:  0.43514535386453973  Training Accuracy:  0.76860434\n",
      "Epoch:  33  Training Loss:  0.447583292695609  Training Accuracy:  0.7803988\n",
      "Epoch:  34  Training Loss:  0.46366378617557613  Training Accuracy:  0.79556304\n",
      "Epoch:  35  Training Loss:  0.5429018789394335  Training Accuracy:  0.78152204\n",
      "Epoch:  36  Training Loss:  0.5334605892950838  Training Accuracy:  0.8247683\n",
      "Epoch:  37  Training Loss:  0.6682730786502361  Training Accuracy:  0.81409717\n",
      "Epoch:  38  Training Loss:  0.7113992324606939  Training Accuracy:  0.8104465\n",
      "Epoch:  39  Training Loss:  0.8286424512212927  Training Accuracy:  0.7919124\n",
      "Epoch:  40  Training Loss:  0.9350865507667715  Training Accuracy:  0.79247403\n",
      "Epoch:  41  Training Loss:  1.275201331299137  Training Accuracy:  0.7964055\n",
      "Epoch:  42  Training Loss:  1.5255381544543938  Training Accuracy:  0.77506316\n",
      "Epoch:  43  Training Loss:  1.6906600551171735  Training Accuracy:  0.78292614\n",
      "Epoch:  44  Training Loss:  1.9219319934872063  Training Accuracy:  0.7770289\n",
      "Epoch:  45  Training Loss:  2.547946408932859  Training Accuracy:  0.77000844\n",
      "Epoch:  46  Training Loss:  3.5366756550290366  Training Accuracy:  0.73237854\n",
      "Epoch:  47  Training Loss:  4.28032669140534  Training Accuracy:  0.73069364\n",
      "Epoch:  48  Training Loss:  5.707205369018696  Training Accuracy:  0.7346251\n",
      "Epoch:  49  Training Loss:  6.0778241872448815  Training Accuracy:  0.71946084\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.7420382\n",
      "validation accuracy: 0.7420382\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 5\n",
    "\n",
    "for i in range(num_experiments):\n",
    "    model.W_conv2_weight = model2.W_conv2_weight\n",
    "    model.b_conv2_weight = model2.b_conv2_weight\n",
    "    model.build_model(self_training=False, load_weights=True)\n",
    "    model.run_model(training_epochs=100)\n",
    "    test_accuracy, val_accuracy, y_pred, y_true = model.test()\n",
    "    stats.add(test_accuracy, val_accuracy, y_pred, y_true = model.test())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multi-class classification: flip, permute, time warp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats3 = Statistics()\n",
    "model3 = Model(dataset_obj2)\n",
    "model3.build_model(self_training=True, num_transforms=4)\n",
    "transforms = [identity, flip, permute, time_warp]\n",
    "model3.self_train(transforms, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(num_experiments):\n",
    "    model.W_conv2_weight = model3.W_conv2_weight\n",
    "    model.b_conv2_weight = model3.b_conv2_weight\n",
    "    model.build_model(self_training=False, load_weights=True)\n",
    "    model.run_model(training_epochs=100)\n",
    "    test_accuracy, val_accuracy, y_pred, y_true = model.test()\n",
    "    stats3.add(test_accuracy, val_accuracy, y_pred, y_true = model.test())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats3.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}