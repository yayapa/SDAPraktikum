{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Self-training as pretraining\n",
    "The idea is based on the [paper](https://arxiv.org/abs/2206.02909).\n",
    "The transformation are used as pretext tasks on unlabeled data to learn features.\n",
    "The learnt weights are used for initialization of weights.\n",
    "To see different transformation, look into Transformations notebook.\n",
    "Two types of self-training are tested:\n",
    "1. binary classification, whether the transformation of time series was applied\n",
    "2. multi-task classification, which transformation was applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Binary classification\n",
    "Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dmitrii/anaconda3/envs/work/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from cnn1d_modules import Model, Dataset\n",
    "from transformation import identity, flip, permute, time_warp, negate\n",
    "from statistics import Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH:  /home/dmitrii/GitHub/SDAPraktikum/E3/PAMAP2_Dataset/pamap2.h5\n",
      "x_train shape =  (128247, 52)\n",
      "y_train shape = (128247,)\n",
      "x_test shape = (22659, 52)\n",
      "y_test shape = (22659,)\n",
      "x_train shape(downsampled) =  (42749, 52)\n",
      "y_train shape(downsampled) = (42749,)\n",
      "x_test shape(downsampled) = (7553, 52)\n",
      "y_test shape(downsampled) = (7553,)\n",
      "[ 1  2  3  4  5  6  7 11 12 13 14 18]\n",
      "[ 1  2  3  4  5  6  7 11 12 13 14 18]\n",
      "segmenting signal...\n",
      "signal segmented.\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "PATH:  /home/dmitrii/GitHub/SDAPraktikum/E3/OpportunityUCIDataset/opportunity.h5\n",
      "x_train shape =  (700165, 77)\n",
      "y_train shape = (700165,)\n",
      "x_test shape = (120516, 77)\n",
      "y_test shape = (120516,)\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "segmenting signal...\n",
      "signal segmented.\n",
      "train_x shape = (63650, 23, 77)\n",
      "train_y shape = (63650,)\n",
      "test_x shape = (10955, 23, 77)\n",
      "test_y shape = (10955,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[[-9.830e-01, -1.990e-01,  1.190e-01, ...,  2.000e-02,\n           4.200e-02,  1.750e-01],\n         [-9.860e-01, -2.200e-01,  1.140e-01, ...,  1.700e-02,\n           3.100e-02,  1.750e-01],\n         [-9.870e-01, -2.270e-01,  1.120e-01, ..., -2.700e-02,\n           1.500e-02,  1.750e-01],\n         ...,\n         [-9.720e-01, -1.420e-01,  6.900e-02, ..., -4.500e-02,\n           5.800e-02,  1.750e-01],\n         [-9.680e-01, -1.420e-01,  6.400e-02, ..., -1.600e-02,\n           4.400e-02,  1.750e-01],\n         [-9.650e-01, -1.450e-01,  8.700e-02, ...,  8.700e-02,\n           2.400e-02,  1.750e-01]],\n \n        [[-9.990e-01, -1.420e-01,  1.190e-01, ..., -4.000e-03,\n           9.000e-03,  1.750e-01],\n         [-9.710e-01, -1.370e-01,  9.000e-02, ..., -1.300e-02,\n           2.000e-02,  1.750e-01],\n         [-9.680e-01, -1.530e-01,  6.900e-02, ..., -7.000e-03,\n           1.500e-02,  1.750e-01],\n         ...,\n         [-9.640e-01, -1.050e-01,  1.700e-02, ..., -5.400e-02,\n          -3.459e+00,  1.760e-01],\n         [-9.770e-01, -1.250e-01,  3.000e-03, ...,  9.790e-01,\n          -5.223e+00,  1.740e-01],\n         [-9.880e-01, -1.520e-01,  4.700e-02, ..., -1.306e+00,\n          -2.782e+00,  1.720e-01]],\n \n        [[-9.650e-01, -1.450e-01,  8.700e-02, ...,  8.700e-02,\n           2.400e-02,  1.750e-01],\n         [-9.700e-01, -1.390e-01,  9.000e-02, ...,  3.800e-02,\n           4.200e-02,  1.750e-01],\n         [-9.870e-01, -1.300e-01,  8.000e-02, ...,  2.360e-01,\n           6.200e-02,  1.760e-01],\n         ...,\n         [-9.540e-01, -2.360e-01,  1.170e-01, ..., -5.100e-02,\n          -3.000e-03,  1.700e-01],\n         [-9.400e-01, -2.430e-01,  9.600e-02, ..., -1.400e-02,\n          -2.700e-02,  1.700e-01],\n         [-9.290e-01, -2.580e-01,  8.200e-02, ...,  1.300e-02,\n          -2.600e-02,  1.700e-01]],\n \n        ...,\n \n        [[-9.840e-01, -1.240e-01,  7.800e-02, ..., -1.900e-02,\n          -2.000e-02, -7.700e-02],\n         [-9.790e-01, -1.340e-01,  7.500e-02, ...,  3.700e-02,\n           9.000e-03, -7.700e-02],\n         [-9.860e-01, -1.310e-01,  7.700e-02, ...,  5.000e-03,\n          -1.000e-03, -7.700e-02],\n         ...,\n         [-9.880e-01, -1.250e-01,  8.300e-02, ..., -8.000e-03,\n           2.100e-02, -7.700e-02],\n         [-9.920e-01, -1.220e-01,  7.700e-02, ..., -1.400e-02,\n           1.200e-02, -7.700e-02],\n         [-9.960e-01, -1.290e-01,  7.500e-02, ..., -1.600e-02,\n          -1.500e-02, -7.700e-02]],\n \n        [[-9.810e-01, -1.190e-01,  8.700e-02, ..., -1.000e-03,\n           1.200e-02, -7.700e-02],\n         [-9.810e-01, -1.180e-01,  8.800e-02, ...,  0.000e+00,\n           1.200e-02, -7.700e-02],\n         [-9.850e-01, -1.160e-01,  8.700e-02, ...,  3.200e-02,\n           2.500e-02, -7.700e-02],\n         ...,\n         [-9.970e-01, -1.310e-01,  7.400e-02, ...,  1.200e-02,\n           3.400e-02, -7.700e-02],\n         [-9.940e-01, -1.150e-01,  7.300e-02, ..., -2.200e-02,\n           3.100e-02, -7.700e-02],\n         [-9.940e-01, -1.360e-01,  7.700e-02, ..., -1.500e-02,\n           6.000e-03, -7.700e-02]],\n \n        [[-9.960e-01, -1.290e-01,  7.500e-02, ..., -1.600e-02,\n          -1.500e-02, -7.700e-02],\n         [-9.930e-01, -1.250e-01,  7.500e-02, ...,  3.000e-03,\n          -7.000e-03, -7.700e-02],\n         [-9.910e-01, -1.270e-01,  7.400e-02, ...,  3.000e-03,\n           1.100e-02, -7.700e-02],\n         ...,\n         [-9.890e-01, -1.280e-01,  8.800e-02, ...,  1.000e-03,\n          -2.600e-02, -7.700e-02],\n         [-9.840e-01, -1.420e-01,  8.600e-02, ..., -1.500e-02,\n           3.500e-02, -7.700e-02],\n         [-9.850e-01, -1.660e-01,  8.600e-02, ...,  0.000e+00,\n           2.000e-03, -7.700e-02]]]),\n array([1., 1., 1., ..., 1., 1., 1.]),\n array([[[-9.620e-01, -1.660e-01,  9.600e-02, ...,  0.000e+00,\n           3.000e-03,  1.390e-01],\n         [-9.610e-01, -1.550e-01,  7.900e-02, ...,  6.000e-03,\n           3.900e-02,  1.400e-01],\n         [-9.810e-01, -1.510e-01,  6.900e-02, ...,  5.000e-03,\n           3.700e-02,  1.400e-01],\n         ...,\n         [-9.900e-01, -1.730e-01,  3.600e-02, ...,  1.700e-02,\n          -3.500e-02,  1.390e-01],\n         [-9.630e-01, -1.540e-01,  2.700e-02, ..., -7.000e-03,\n           4.300e-02,  1.390e-01],\n         [-9.710e-01, -1.500e-01,  2.700e-02, ..., -2.300e-02,\n           1.300e-02,  1.400e-01]],\n \n        [[-9.900e-01, -1.530e-01,  5.700e-02, ...,  9.000e-03,\n           1.600e-02,  1.400e-01],\n         [-9.850e-01, -1.750e-01,  6.900e-02, ..., -2.000e-02,\n           2.600e-02,  1.390e-01],\n         [-9.890e-01, -1.960e-01,  1.000e-02, ..., -4.400e-02,\n           5.000e-03,  1.380e-01],\n         ...,\n         [-1.003e+00, -1.680e-01,  1.600e-02, ...,  2.500e-02,\n           3.700e-02,  1.410e-01],\n         [-9.940e-01, -1.800e-01,  6.000e-03, ..., -9.000e-03,\n           1.600e-02,  1.410e-01],\n         [-9.890e-01, -1.800e-01,  7.000e-03, ...,  1.000e-03,\n           3.000e-03,  1.400e-01]],\n \n        [[-9.710e-01, -1.500e-01,  2.700e-02, ..., -2.300e-02,\n           1.300e-02,  1.400e-01],\n         [-9.760e-01, -1.510e-01,  4.000e-02, ..., -2.000e-03,\n          -8.000e-03,  1.400e-01],\n         [-9.920e-01, -1.450e-01,  3.000e-02, ...,  1.200e-02,\n           3.000e-02,  1.390e-01],\n         ...,\n         [-9.900e-01, -1.610e-01,  1.500e-02, ...,  7.000e-03,\n           0.000e+00,  1.400e-01],\n         [-9.850e-01, -1.560e-01,  6.000e-03, ...,  1.500e-02,\n          -3.500e-02,  1.400e-01],\n         [-9.810e-01, -1.610e-01,  1.000e-03, ..., -1.600e-02,\n           5.000e-03,  1.400e-01]],\n \n        ...,\n \n        [[-9.690e-01, -4.600e-02,  2.530e-01, ..., -2.900e-02,\n          -1.500e-02,  1.200e-02],\n         [-9.660e-01, -4.300e-02,  2.530e-01, ...,  5.200e-02,\n           2.200e-02,  1.200e-02],\n         [-9.710e-01, -4.500e-02,  2.500e-01, ...,  1.700e-02,\n           0.000e+00,  1.200e-02],\n         ...,\n         [-9.720e-01, -3.600e-02,  2.480e-01, ...,  9.000e-03,\n           2.300e-02,  1.200e-02],\n         [-9.690e-01, -4.300e-02,  2.620e-01, ...,  1.100e-02,\n           3.500e-02,  1.200e-02],\n         [-9.660e-01, -3.600e-02,  2.500e-01, ..., -1.500e-02,\n          -2.000e-03,  1.200e-02]],\n \n        [[-9.670e-01, -3.900e-02,  2.490e-01, ..., -1.800e-02,\n           1.100e-02,  1.200e-02],\n         [-9.690e-01, -4.100e-02,  2.530e-01, ..., -1.200e-02,\n          -2.800e-02,  1.200e-02],\n         [-9.700e-01, -4.000e-02,  2.540e-01, ..., -1.200e-02,\n          -1.200e-02,  1.200e-02],\n         ...,\n         [-9.710e-01, -5.000e-02,  2.510e-01, ...,  2.800e-02,\n          -1.700e-02,  1.200e-02],\n         [-9.690e-01, -5.000e-02,  2.500e-01, ..., -8.000e-03,\n          -6.000e-02,  1.200e-02],\n         [-9.670e-01, -4.900e-02,  2.470e-01, ...,  2.800e-02,\n          -1.400e-02,  1.200e-02]],\n \n        [[ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00],\n         [ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00],\n         [ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00],\n         ...,\n         [ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00],\n         [ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00],\n         [ 0.000e+00,  0.000e+00,  0.000e+00, ...,  0.000e+00,\n           0.000e+00,  0.000e+00]]]),\n array([1., 1., 1., ..., 1., 1., 0.]))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_obj = Dataset(\"pa2\")\n",
    "dataset_obj.read_dataset()\n",
    "dataset_obj.downsample_dataset()\n",
    "dataset_obj.segment_dataset()\n",
    "\n",
    "dataset_obj2 = Dataset(\"opp\")\n",
    "dataset_obj2.read_dataset()\n",
    "dataset_obj2.downsample_dataset()\n",
    "dataset_obj2.segment_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train on one pretext task: permute transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opp\n",
      "X shape = (?, 1, 23, 77)\n",
      "Y shape = (?, 2)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 77, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 17, 128)\n",
      "h_pool1 shape = (?, 1, 6, 128)\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 4, 128)\n",
      "h_pool2 shape = (?, 1, 1, 128)\n",
      "shape's shape: [None, 1, 1, 128]\n",
      "c_flat shape = (?, 128)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (63650, 18)\n",
      "test_y shape(1-hot) = (10955, 18)\n",
      "train_x_reshaped =  (63650, 1, 23, 77)\n",
      "test_x_reshaped =  (10955, 1, 23, 77)\n",
      "train_x shape = (63650, 23, 77)\n",
      "train_y shape = (63650,)\n",
      "test_x shape = (10955, 23, 77)\n",
      "test_y shape = (10955,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/GitHub/SDAPraktikum/E3/transformation.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  splitted = np.array(np.split(sample_i, np.append(segments, sample.shape[1])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Training Loss:  0.6380585195792753  Training Accuracy:  0.72221524\n",
      "Epoch:  1  Training Loss:  0.4761764254398509  Training Accuracy:  0.7453417\n",
      "Epoch:  2  Training Loss:  0.4446214212318301  Training Accuracy:  0.7717361\n",
      "Epoch:  3  Training Loss:  0.4099332014214945  Training Accuracy:  0.7885153\n",
      "Epoch:  4  Training Loss:  0.38423654918279687  Training Accuracy:  0.80180675\n",
      "Epoch:  5  Training Loss:  0.37304419479979356  Training Accuracy:  0.7974077\n",
      "Epoch:  6  Training Loss:  0.36196343050576313  Training Accuracy:  0.81803614\n",
      "Epoch:  7  Training Loss:  0.35363956540073427  Training Accuracy:  0.8177219\n",
      "Epoch:  8  Training Loss:  0.34420418985547796  Training Accuracy:  0.817282\n",
      "Epoch:  9  Training Loss:  0.3356748224279171  Training Accuracy:  0.8100707\n",
      "Epoch:  10  Training Loss:  0.33293109525827097  Training Accuracy:  0.8298036\n",
      "Epoch:  11  Training Loss:  0.32748651072397916  Training Accuracy:  0.820817\n",
      "Epoch:  12  Training Loss:  0.3248609694084471  Training Accuracy:  0.8385703\n",
      "Epoch:  13  Training Loss:  0.318406363825503  Training Accuracy:  0.8371406\n",
      "Epoch:  14  Training Loss:  0.3108831342849393  Training Accuracy:  0.8369835\n",
      "Epoch:  15  Training Loss:  0.31238698271258736  Training Accuracy:  0.84845245\n",
      "Epoch:  16  Training Loss:  0.3010334523986853  Training Accuracy:  0.84075415\n",
      "Epoch:  17  Training Loss:  0.30104188131771875  Training Accuracy:  0.847934\n",
      "Epoch:  18  Training Loss:  0.30670925652911846  Training Accuracy:  0.8505734\n",
      "Epoch:  19  Training Loss:  0.29274691225140087  Training Accuracy:  0.84164965\n",
      "Epoch:  20  Training Loss:  0.29776405002659473  Training Accuracy:  0.850652\n",
      "Epoch:  21  Training Loss:  0.2902332229101262  Training Accuracy:  0.85170466\n",
      "Epoch:  22  Training Loss:  0.28867899440791106  Training Accuracy:  0.8520503\n",
      "Epoch:  23  Training Loss:  0.27914731874424864  Training Accuracy:  0.8676041\n",
      "Epoch:  24  Training Loss:  0.2863165293042539  Training Accuracy:  0.85934013\n",
      "Epoch:  25  Training Loss:  0.28069333409819325  Training Accuracy:  0.8547054\n",
      "Epoch:  26  Training Loss:  0.2855602349632493  Training Accuracy:  0.87113905\n",
      "Epoch:  27  Training Loss:  0.27659164749693044  Training Accuracy:  0.8619167\n",
      "Epoch:  28  Training Loss:  0.2761233932792136  Training Accuracy:  0.8589474\n",
      "Epoch:  29  Training Loss:  0.2759992038897638  Training Accuracy:  0.8704006\n",
      "Epoch:  30  Training Loss:  0.26955534318195923  Training Accuracy:  0.86955225\n",
      "Epoch:  31  Training Loss:  0.2625523475289225  Training Accuracy:  0.865216\n",
      "Epoch:  32  Training Loss:  0.26197913561252434  Training Accuracy:  0.87608796\n",
      "Epoch:  33  Training Loss:  0.26440456266640505  Training Accuracy:  0.8771877\n",
      "Epoch:  34  Training Loss:  0.266426414444338  Training Accuracy:  0.8749882\n",
      "Epoch:  35  Training Loss:  0.259144905524542  Training Accuracy:  0.86926943\n",
      "Epoch:  36  Training Loss:  0.2599867025026733  Training Accuracy:  0.87470543\n",
      "Epoch:  37  Training Loss:  0.2690110027347832  Training Accuracy:  0.87731344\n",
      "Epoch:  38  Training Loss:  0.25120821253769476  Training Accuracy:  0.88278085\n",
      "Epoch:  39  Training Loss:  0.24968645788384394  Training Accuracy:  0.8702121\n",
      "Epoch:  40  Training Loss:  0.24760147068139832  Training Accuracy:  0.8836292\n",
      "Epoch:  41  Training Loss:  0.2529988806719107  Training Accuracy:  0.87113905\n",
      "Epoch:  42  Training Loss:  0.25220434839033357  Training Accuracy:  0.88139826\n",
      "Epoch:  43  Training Loss:  0.23919183995773344  Training Accuracy:  0.87945014\n",
      "Epoch:  44  Training Loss:  0.24398503580713415  Training Accuracy:  0.88076985\n",
      "Epoch:  45  Training Loss:  0.24562072260698803  Training Accuracy:  0.88496464\n",
      "Epoch:  46  Training Loss:  0.23553267078168721  Training Accuracy:  0.8873841\n",
      "Epoch:  47  Training Loss:  0.2428582778474095  Training Accuracy:  0.8879183\n",
      "Epoch:  48  Training Loss:  0.24949315510141162  Training Accuracy:  0.8865043\n",
      "Epoch:  49  Training Loss:  0.23462029418044197  Training Accuracy:  0.8918303\n"
     ]
    }
   ],
   "source": [
    "model2 = Model(dataset_obj2)\n",
    "model2.build_model(self_training=True, num_transforms=2)\n",
    "transforms = [identity, permute]\n",
    "model2.self_train(transforms, 50, 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(dataset_obj)\n",
    "stats = Statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.5241180593317205  Training Accuracy:  0.108958155\n",
      "Epoch:  1  Training Loss:  2.3758114554665304  Training Accuracy:  0.121595055\n",
      "Epoch:  2  Training Loss:  2.338084743239663  Training Accuracy:  0.14995788\n",
      "Epoch:  3  Training Loss:  2.2740111220966686  Training Accuracy:  0.18337546\n",
      "Epoch:  4  Training Loss:  2.2169200745495883  Training Accuracy:  0.22269025\n",
      "Epoch:  5  Training Loss:  2.1714345455169677  Training Accuracy:  0.27042964\n",
      "Epoch:  6  Training Loss:  2.124583686481823  Training Accuracy:  0.29092953\n",
      "Epoch:  7  Training Loss:  2.072641216624867  Training Accuracy:  0.32210052\n",
      "Epoch:  8  Training Loss:  2.0159144401550293  Training Accuracy:  0.3499017\n",
      "Epoch:  9  Training Loss:  1.9567063483324918  Training Accuracy:  0.36871666\n",
      "Epoch:  10  Training Loss:  1.9164737863974137  Training Accuracy:  0.3847234\n",
      "Epoch:  11  Training Loss:  1.8644623496315695  Training Accuracy:  0.40129176\n",
      "Epoch:  12  Training Loss:  1.8184571959755638  Training Accuracy:  0.39848357\n",
      "Epoch:  13  Training Loss:  1.7732060844247992  Training Accuracy:  0.40943554\n",
      "Epoch:  14  Training Loss:  1.7319231634790246  Training Accuracy:  0.42094916\n",
      "Epoch:  15  Training Loss:  1.6748159603639083  Training Accuracy:  0.43049705\n",
      "Epoch:  16  Training Loss:  1.6447473753582347  Training Accuracy:  0.4397641\n",
      "Epoch:  17  Training Loss:  1.5883355352011594  Training Accuracy:  0.4465038\n",
      "Epoch:  18  Training Loss:  1.5557741284370423  Training Accuracy:  0.45829824\n",
      "Epoch:  19  Training Loss:  1.506217232617465  Training Accuracy:  0.47402415\n",
      "Epoch:  20  Training Loss:  1.4680899305777115  Training Accuracy:  0.48694187\n",
      "Epoch:  21  Training Loss:  1.4331976565447722  Training Accuracy:  0.5012637\n",
      "Epoch:  22  Training Loss:  1.3979011958295648  Training Accuracy:  0.5124965\n",
      "Epoch:  23  Training Loss:  1.3661767555908724  Training Accuracy:  0.53299636\n",
      "Epoch:  24  Training Loss:  1.3244744457981803  Training Accuracy:  0.5374895\n",
      "Epoch:  25  Training Loss:  1.3025537902658635  Training Accuracy:  0.54282504\n",
      "Epoch:  26  Training Loss:  1.2724915144118396  Training Accuracy:  0.55995506\n",
      "Epoch:  27  Training Loss:  1.2503883185711775  Training Accuracy:  0.5768043\n",
      "Epoch:  28  Training Loss:  1.2139656286347995  Training Accuracy:  0.5885987\n",
      "Epoch:  29  Training Loss:  1.192512361569838  Training Accuracy:  0.59477675\n",
      "Epoch:  30  Training Loss:  1.1761766910552978  Training Accuracy:  0.6048863\n",
      "Epoch:  31  Training Loss:  1.1445277921178125  Training Accuracy:  0.6023589\n",
      "Epoch:  32  Training Loss:  1.1309514303099026  Training Accuracy:  0.6161191\n",
      "Epoch:  33  Training Loss:  1.095407981222326  Training Accuracy:  0.6225779\n",
      "Epoch:  34  Training Loss:  1.0805434021082791  Training Accuracy:  0.6259478\n",
      "Epoch:  35  Training Loss:  1.0702009163119577  Training Accuracy:  0.64223534\n",
      "Epoch:  36  Training Loss:  1.054137214205482  Training Accuracy:  0.6557147\n",
      "Epoch:  37  Training Loss:  1.0239801582964985  Training Accuracy:  0.64560515\n",
      "Epoch:  38  Training Loss:  1.009182707829909  Training Accuracy:  0.65683794\n",
      "Epoch:  39  Training Loss:  1.0013214181769978  Training Accuracy:  0.66778994\n",
      "Epoch:  40  Training Loss:  0.9751086657697504  Training Accuracy:  0.68351585\n",
      "Epoch:  41  Training Loss:  0.9605008886619048  Training Accuracy:  0.67509127\n",
      "Epoch:  42  Training Loss:  0.9385743347081271  Training Accuracy:  0.68351585\n",
      "Epoch:  43  Training Loss:  0.9281803234056993  Training Accuracy:  0.6939062\n",
      "Epoch:  44  Training Loss:  0.9065774158997969  Training Accuracy:  0.69474864\n",
      "Epoch:  45  Training Loss:  0.9033010732043874  Training Accuracy:  0.70541984\n",
      "Epoch:  46  Training Loss:  0.8818181130019102  Training Accuracy:  0.7096321\n",
      "Epoch:  47  Training Loss:  0.8686216668649154  Training Accuracy:  0.7205841\n",
      "Epoch:  48  Training Loss:  0.8683600146662105  Training Accuracy:  0.72451556\n",
      "Epoch:  49  Training Loss:  0.8510510284792293  Training Accuracy:  0.7155293\n",
      "Epoch:  50  Training Loss:  0.8364906308325855  Training Accuracy:  0.7304128\n",
      "Epoch:  51  Training Loss:  0.8256389279257167  Training Accuracy:  0.73406345\n",
      "Epoch:  52  Training Loss:  0.8070988042788072  Training Accuracy:  0.7357484\n",
      "Epoch:  53  Training Loss:  0.7897740139202638  Training Accuracy:  0.7469812\n",
      "Epoch:  54  Training Loss:  0.780157027461312  Training Accuracy:  0.73827577\n",
      "Epoch:  55  Training Loss:  0.7716713691299611  Training Accuracy:  0.7458579\n",
      "Epoch:  56  Training Loss:  0.7550036172975193  Training Accuracy:  0.7548441\n",
      "Epoch:  57  Training Loss:  0.7570554015311328  Training Accuracy:  0.755125\n",
      "Epoch:  58  Training Loss:  0.7403316508639942  Training Accuracy:  0.75877565\n",
      "Epoch:  59  Training Loss:  0.72896361107176  Training Accuracy:  0.7610222\n",
      "Epoch:  60  Training Loss:  0.7196781759912317  Training Accuracy:  0.7711317\n",
      "Epoch:  61  Training Loss:  0.7022304144772616  Training Accuracy:  0.77028924\n",
      "Epoch:  62  Training Loss:  0.6929936558008194  Training Accuracy:  0.77478236\n",
      "Epoch:  63  Training Loss:  0.6867133376273242  Training Accuracy:  0.7789947\n",
      "Epoch:  64  Training Loss:  0.6884182547981089  Training Accuracy:  0.77983713\n",
      "Epoch:  65  Training Loss:  0.6580055345188488  Training Accuracy:  0.78573436\n",
      "Epoch:  66  Training Loss:  0.6566607322205197  Training Accuracy:  0.7851727\n",
      "Epoch:  67  Training Loss:  0.6489056373184378  Training Accuracy:  0.789385\n",
      "Epoch:  68  Training Loss:  0.6357523047111251  Training Accuracy:  0.7947206\n",
      "Epoch:  69  Training Loss:  0.6273647218942642  Training Accuracy:  0.78882337\n",
      "Epoch:  70  Training Loss:  0.6107854561372237  Training Accuracy:  0.79668635\n",
      "Epoch:  71  Training Loss:  0.6102443141016093  Training Accuracy:  0.7879809\n",
      "Epoch:  72  Training Loss:  0.6038260186260397  Training Accuracy:  0.79696715\n",
      "Epoch:  73  Training Loss:  0.5831499525091864  Training Accuracy:  0.8056726\n",
      "Epoch:  74  Training Loss:  0.5811808897690339  Training Accuracy:  0.80511093\n",
      "Epoch:  75  Training Loss:  0.5749138769778338  Training Accuracy:  0.8163437\n",
      "Epoch:  76  Training Loss:  0.5684736738828096  Training Accuracy:  0.80988485\n",
      "Epoch:  77  Training Loss:  0.5596810332753441  Training Accuracy:  0.81269306\n",
      "Epoch:  78  Training Loss:  0.5470936175097119  Training Accuracy:  0.8073575\n",
      "Epoch:  79  Training Loss:  0.5380318162116138  Training Accuracy:  0.8152204\n",
      "Epoch:  80  Training Loss:  0.5281511217355728  Training Accuracy:  0.81297386\n",
      "Epoch:  81  Training Loss:  0.5338795212182131  Training Accuracy:  0.8132547\n",
      "Epoch:  82  Training Loss:  0.5208139691840519  Training Accuracy:  0.8258916\n",
      "Epoch:  83  Training Loss:  0.5083286449313164  Training Accuracy:  0.8244875\n",
      "Epoch:  84  Training Loss:  0.5166603264483538  Training Accuracy:  0.8244875\n",
      "Epoch:  85  Training Loss:  0.5024220749735833  Training Accuracy:  0.8399326\n",
      "Epoch:  86  Training Loss:  0.493434309146621  Training Accuracy:  0.82701486\n",
      "Epoch:  87  Training Loss:  0.4872574118050662  Training Accuracy:  0.8301039\n",
      "Epoch:  88  Training Loss:  0.4841801916333762  Training Accuracy:  0.8404942\n",
      "Epoch:  89  Training Loss:  0.47922061837532304  Training Accuracy:  0.8295423\n",
      "Epoch:  90  Training Loss:  0.469733050736514  Training Accuracy:  0.8371244\n",
      "Epoch:  91  Training Loss:  0.4716866756027395  Training Accuracy:  0.8416175\n",
      "Epoch:  92  Training Loss:  0.459721207076853  Training Accuracy:  0.84302163\n",
      "Epoch:  93  Training Loss:  0.4606427425010638  Training Accuracy:  0.8368436\n",
      "Epoch:  94  Training Loss:  0.4467114556919445  Training Accuracy:  0.8421792\n",
      "Epoch:  95  Training Loss:  0.4386615556749431  Training Accuracy:  0.83909017\n",
      "Epoch:  96  Training Loss:  0.4362190134823322  Training Accuracy:  0.84582984\n",
      "Epoch:  97  Training Loss:  0.4376050900329243  Training Accuracy:  0.85200787\n",
      "Epoch:  98  Training Loss:  0.4329147995872931  Training Accuracy:  0.84751475\n",
      "Epoch:  99  Training Loss:  0.4163887153972279  Training Accuracy:  0.84723395\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.85987264\n",
      "validation accuracy: 0.85987264\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.4482139110565186  Training Accuracy:  0.11176636\n",
      "Epoch:  1  Training Loss:  2.354009099440141  Training Accuracy:  0.14237574\n",
      "Epoch:  2  Training Loss:  2.298857480829412  Training Accuracy:  0.17495085\n",
      "Epoch:  3  Training Loss:  2.242932881008495  Training Accuracy:  0.20387532\n",
      "Epoch:  4  Training Loss:  2.196580498868769  Training Accuracy:  0.25217634\n",
      "Epoch:  5  Training Loss:  2.140382664853876  Training Accuracy:  0.25554618\n",
      "Epoch:  6  Training Loss:  2.0800314274701206  Training Accuracy:  0.29121032\n",
      "Epoch:  7  Training Loss:  2.025345982204784  Training Accuracy:  0.30384722\n",
      "Epoch:  8  Training Loss:  1.9886088241230357  Training Accuracy:  0.32827857\n",
      "Epoch:  9  Training Loss:  1.9512833671136336  Training Accuracy:  0.3428812\n",
      "Epoch:  10  Training Loss:  1.9124189474365927  Training Accuracy:  0.35916877\n",
      "Epoch:  11  Training Loss:  1.866949823769656  Training Accuracy:  0.37433305\n",
      "Epoch:  12  Training Loss:  1.820109049840407  Training Accuracy:  0.38528502\n",
      "Epoch:  13  Training Loss:  1.7804222193631258  Training Accuracy:  0.39539456\n",
      "Epoch:  14  Training Loss:  1.7378722104159268  Training Accuracy:  0.41280538\n",
      "Epoch:  15  Training Loss:  1.7026918909766457  Training Accuracy:  0.44060656\n",
      "Epoch:  16  Training Loss:  1.6647071264006874  Training Accuracy:  0.4580174\n",
      "Epoch:  17  Training Loss:  1.6343791896646673  Training Accuracy:  0.4566133\n",
      "Epoch:  18  Training Loss:  1.5842374303124167  Training Accuracy:  0.4692502\n",
      "Epoch:  19  Training Loss:  1.5569165408611298  Training Accuracy:  0.4970514\n",
      "Epoch:  20  Training Loss:  1.5295900252732364  Training Accuracy:  0.50631845\n",
      "Epoch:  21  Training Loss:  1.4840630371462216  Training Accuracy:  0.50940746\n",
      "Epoch:  22  Training Loss:  1.460321220484647  Training Accuracy:  0.5259758\n",
      "Epoch:  23  Training Loss:  1.4286452721465717  Training Accuracy:  0.53440046\n",
      "Epoch:  24  Training Loss:  1.3935946291143244  Training Accuracy:  0.5422634\n",
      "Epoch:  25  Training Loss:  1.3693947044285861  Training Accuracy:  0.5504072\n",
      "Epoch:  26  Training Loss:  1.3329195559024811  Training Accuracy:  0.5714687\n",
      "Epoch:  27  Training Loss:  1.3040564201094889  Training Accuracy:  0.5689413\n",
      "Epoch:  28  Training Loss:  1.2821836628697134  Training Accuracy:  0.5717495\n",
      "Epoch:  29  Training Loss:  1.2625891674648633  Training Accuracy:  0.5883179\n",
      "Epoch:  30  Training Loss:  1.2464623602953824  Training Accuracy:  0.5922494\n",
      "Epoch:  31  Training Loss:  1.2220079492438922  Training Accuracy:  0.59758496\n",
      "Epoch:  32  Training Loss:  1.1990269249135799  Training Accuracy:  0.6107835\n",
      "Epoch:  33  Training Loss:  1.174809897758744  Training Accuracy:  0.606852\n",
      "Epoch:  34  Training Loss:  1.1566918270154434  Training Accuracy:  0.62033135\n",
      "Epoch:  35  Training Loss:  1.1458603035319934  Training Accuracy:  0.6237012\n",
      "Epoch:  36  Training Loss:  1.1167821363969284  Training Accuracy:  0.64055043\n",
      "Epoch:  37  Training Loss:  1.0961345463991166  Training Accuracy:  0.645886\n",
      "Epoch:  38  Training Loss:  1.089419162273407  Training Accuracy:  0.64532435\n",
      "Epoch:  39  Training Loss:  1.0727284488352862  Training Accuracy:  0.6537489\n",
      "Epoch:  40  Training Loss:  1.058301970091733  Training Accuracy:  0.6523448\n",
      "Epoch:  41  Training Loss:  1.036268719217994  Training Accuracy:  0.6573996\n",
      "Epoch:  42  Training Loss:  1.0244102689352903  Training Accuracy:  0.65318733\n",
      "Epoch:  43  Training Loss:  1.0155429463494907  Training Accuracy:  0.66919404\n",
      "Epoch:  44  Training Loss:  0.9995184044946324  Training Accuracy:  0.66582423\n",
      "Epoch:  45  Training Loss:  0.9937524375590411  Training Accuracy:  0.677057\n",
      "Epoch:  46  Training Loss:  0.968870551477779  Training Accuracy:  0.68183094\n",
      "Epoch:  47  Training Loss:  0.9710898431864652  Training Accuracy:  0.68463916\n",
      "Epoch:  48  Training Loss:  0.9503227632154118  Training Accuracy:  0.6885706\n",
      "Epoch:  49  Training Loss:  0.9269705460830169  Training Accuracy:  0.69137883\n",
      "Epoch:  50  Training Loss:  0.9283397325060584  Training Accuracy:  0.69727606\n",
      "Epoch:  51  Training Loss:  0.9208199468525973  Training Accuracy:  0.6902555\n",
      "Epoch:  52  Training Loss:  0.8944225983186201  Training Accuracy:  0.70401573\n",
      "Epoch:  53  Training Loss:  0.8899190937930888  Training Accuracy:  0.7026116\n",
      "Epoch:  54  Training Loss:  0.874731050025333  Training Accuracy:  0.7172143\n",
      "Epoch:  55  Training Loss:  0.87704496383667  Training Accuracy:  0.7250772\n",
      "Epoch:  56  Training Loss:  0.851728576963598  Training Accuracy:  0.7233923\n",
      "Epoch:  57  Training Loss:  0.849257895079526  Training Accuracy:  0.72563887\n",
      "Epoch:  58  Training Loss:  0.8365181549028917  Training Accuracy:  0.7281662\n",
      "Epoch:  59  Training Loss:  0.8276139736175537  Training Accuracy:  0.7233923\n",
      "Epoch:  60  Training Loss:  0.8135002380067652  Training Accuracy:  0.73378265\n",
      "Epoch:  61  Training Loss:  0.7969392049041661  Training Accuracy:  0.730132\n",
      "Epoch:  62  Training Loss:  0.7925857151096517  Training Accuracy:  0.73378265\n",
      "Epoch:  63  Training Loss:  0.7924169085242532  Training Accuracy:  0.74501544\n",
      "Epoch:  64  Training Loss:  0.7708680429241874  Training Accuracy:  0.7438922\n",
      "Epoch:  65  Training Loss:  0.7679142117500305  Training Accuracy:  0.75456333\n",
      "Epoch:  66  Training Loss:  0.7551822142167525  Training Accuracy:  0.7514743\n",
      "Epoch:  67  Training Loss:  0.7385412419384176  Training Accuracy:  0.7548441\n",
      "Epoch:  68  Training Loss:  0.7269049043005164  Training Accuracy:  0.7548441\n",
      "Epoch:  69  Training Loss:  0.7304958817633715  Training Accuracy:  0.75877565\n",
      "Epoch:  70  Training Loss:  0.7214700417085127  Training Accuracy:  0.7655153\n",
      "Epoch:  71  Training Loss:  0.7081045274030079  Training Accuracy:  0.7601797\n",
      "Epoch:  72  Training Loss:  0.6982463731007142  Training Accuracy:  0.7683235\n",
      "Epoch:  73  Training Loss:  0.6919320667331869  Training Accuracy:  0.7728166\n",
      "Epoch:  74  Training Loss:  0.6768548196012324  Training Accuracy:  0.7781522\n",
      "Epoch:  75  Training Loss:  0.6765628343278711  Training Accuracy:  0.7820837\n",
      "Epoch:  76  Training Loss:  0.6636674045161768  Training Accuracy:  0.7778714\n",
      "Epoch:  77  Training Loss:  0.6549151411110704  Training Accuracy:  0.7823645\n",
      "Epoch:  78  Training Loss:  0.6424352206967093  Training Accuracy:  0.78433025\n",
      "Epoch:  79  Training Loss:  0.6355628062378277  Training Accuracy:  0.7930357\n",
      "Epoch:  80  Training Loss:  0.6256859068166126  Training Accuracy:  0.786296\n",
      "Epoch:  81  Training Loss:  0.6152862936258316  Training Accuracy:  0.7975288\n",
      "Epoch:  82  Training Loss:  0.6096991501071236  Training Accuracy:  0.80117947\n",
      "Epoch:  83  Training Loss:  0.603354115377773  Training Accuracy:  0.80174106\n",
      "Epoch:  84  Training Loss:  0.596570267460563  Training Accuracy:  0.7975288\n",
      "Epoch:  85  Training Loss:  0.5831472830338912  Training Accuracy:  0.8025835\n",
      "Epoch:  86  Training Loss:  0.580263335054571  Training Accuracy:  0.8023027\n",
      "Epoch:  87  Training Loss:  0.5703352462161672  Training Accuracy:  0.8059534\n",
      "Epoch:  88  Training Loss:  0.562322758544575  Training Accuracy:  0.80651504\n",
      "Epoch:  89  Training Loss:  0.552155894853852  Training Accuracy:  0.8163437\n",
      "Epoch:  90  Training Loss:  0.5482728752222928  Training Accuracy:  0.8197136\n",
      "Epoch:  91  Training Loss:  0.5446436909112063  Training Accuracy:  0.8166245\n",
      "Epoch:  92  Training Loss:  0.5279884204268456  Training Accuracy:  0.82504916\n",
      "Epoch:  93  Training Loss:  0.5294441022656181  Training Accuracy:  0.82701486\n",
      "Epoch:  94  Training Loss:  0.5222952184352008  Training Accuracy:  0.8228026\n",
      "Epoch:  95  Training Loss:  0.5088746669617566  Training Accuracy:  0.8258916\n",
      "Epoch:  96  Training Loss:  0.5105003091421995  Training Accuracy:  0.8202752\n",
      "Epoch:  97  Training Loss:  0.5033216752789237  Training Accuracy:  0.82841897\n",
      "Epoch:  98  Training Loss:  0.49615744176236065  Training Accuracy:  0.82392585\n",
      "Epoch:  99  Training Loss:  0.48434202522039416  Training Accuracy:  0.8292614\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.85987264\n",
      "validation accuracy: 0.85987264\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.4983816558664493  Training Accuracy:  0.1053075\n",
      "Epoch:  1  Training Loss:  2.3965054100210015  Training Accuracy:  0.11345128\n",
      "Epoch:  2  Training Loss:  2.354634501717307  Training Accuracy:  0.119629316\n",
      "Epoch:  3  Training Loss:  2.3214873573996804  Training Accuracy:  0.14658804\n",
      "Epoch:  4  Training Loss:  2.281152527982538  Training Accuracy:  0.18197136\n",
      "Epoch:  5  Training Loss:  2.2376881165937945  Training Accuracy:  0.21623139\n",
      "Epoch:  6  Training Loss:  2.183837803927335  Training Accuracy:  0.26453245\n",
      "Epoch:  7  Training Loss:  2.141879851167852  Training Accuracy:  0.29149115\n",
      "Epoch:  8  Training Loss:  2.0873472820628773  Training Accuracy:  0.3215389\n",
      "Epoch:  9  Training Loss:  2.021758378635753  Training Accuracy:  0.33108678\n",
      "Epoch:  10  Training Loss:  1.9754661310802806  Training Accuracy:  0.34653187\n",
      "Epoch:  11  Training Loss:  1.920945271578702  Training Accuracy:  0.35327154\n",
      "Epoch:  12  Training Loss:  1.8678863541646438  Training Accuracy:  0.36843583\n",
      "Epoch:  13  Training Loss:  1.8211267666383224  Training Accuracy:  0.38303846\n",
      "Epoch:  14  Training Loss:  1.7712432671676983  Training Accuracy:  0.39427128\n",
      "Epoch:  15  Training Loss:  1.7340538973158055  Training Accuracy:  0.4015726\n",
      "Epoch:  16  Training Loss:  1.6840623595497826  Training Accuracy:  0.4201067\n",
      "Epoch:  17  Training Loss:  1.645588688958775  Training Accuracy:  0.42600393\n",
      "Epoch:  18  Training Loss:  1.5965959202159534  Training Accuracy:  0.43639427\n",
      "Epoch:  19  Training Loss:  1.5712489019740712  Training Accuracy:  0.44032574\n",
      "Epoch:  20  Training Loss:  1.5272090781818737  Training Accuracy:  0.44285312\n",
      "Epoch:  21  Training Loss:  1.495354055816477  Training Accuracy:  0.46447626\n",
      "Epoch:  22  Training Loss:  1.4647639789364555  Training Accuracy:  0.48076382\n",
      "Epoch:  23  Training Loss:  1.4295231970873745  Training Accuracy:  0.4745858\n",
      "Epoch:  24  Training Loss:  1.4163974957032637  Training Accuracy:  0.49340072\n",
      "Epoch:  25  Training Loss:  1.3896500863812187  Training Accuracy:  0.49340072\n",
      "Epoch:  26  Training Loss:  1.3545392594554209  Training Accuracy:  0.51053077\n",
      "Epoch:  27  Training Loss:  1.33841102773493  Training Accuracy:  0.5071609\n",
      "Epoch:  28  Training Loss:  1.318947652795098  Training Accuracy:  0.53046894\n",
      "Epoch:  29  Training Loss:  1.2936961030418224  Training Accuracy:  0.5369278\n",
      "Epoch:  30  Training Loss:  1.2812794059515  Training Accuracy:  0.536647\n",
      "Epoch:  31  Training Loss:  1.2563660963015122  Training Accuracy:  0.54254425\n",
      "Epoch:  32  Training Loss:  1.2301607435399835  Training Accuracy:  0.5447908\n",
      "Epoch:  33  Training Loss:  1.2200352560390126  Training Accuracy:  0.5515305\n",
      "Epoch:  34  Training Loss:  1.2088648714802481  Training Accuracy:  0.5714687\n",
      "Epoch:  35  Training Loss:  1.1771759911016983  Training Accuracy:  0.58354396\n",
      "Epoch:  36  Training Loss:  1.1756924604827708  Training Accuracy:  0.5717495\n",
      "Epoch:  37  Training Loss:  1.1505680864507501  Training Accuracy:  0.5765234\n",
      "Epoch:  38  Training Loss:  1.1365430509502237  Training Accuracy:  0.59505755\n",
      "Epoch:  39  Training Loss:  1.1293127049099316  Training Accuracy:  0.5967425\n",
      "Epoch:  40  Training Loss:  1.116372248530388  Training Accuracy:  0.59955066\n",
      "Epoch:  41  Training Loss:  1.0973921488631855  Training Accuracy:  0.614715\n",
      "Epoch:  42  Training Loss:  1.0692131977189672  Training Accuracy:  0.625667\n",
      "Epoch:  43  Training Loss:  1.0620665978301655  Training Accuracy:  0.631845\n",
      "Epoch:  44  Training Loss:  1.049409670992331  Training Accuracy:  0.6251053\n",
      "Epoch:  45  Training Loss:  1.0339539750055833  Training Accuracy:  0.63605726\n",
      "Epoch:  46  Training Loss:  1.0156440818851644  Training Accuracy:  0.6444819\n",
      "Epoch:  47  Training Loss:  1.0060864573175257  Training Accuracy:  0.645886\n",
      "Epoch:  48  Training Loss:  0.9961667540398511  Training Accuracy:  0.65318733\n",
      "Epoch:  49  Training Loss:  0.9683695728128606  Training Accuracy:  0.6663858\n",
      "Epoch:  50  Training Loss:  0.955910135941072  Training Accuracy:  0.68211174\n",
      "Epoch:  51  Training Loss:  0.9456519915298982  Training Accuracy:  0.6759337\n",
      "Epoch:  52  Training Loss:  0.9318237326361917  Training Accuracy:  0.6854816\n",
      "Epoch:  53  Training Loss:  0.9168631060556932  Training Accuracy:  0.6925021\n",
      "Epoch:  54  Training Loss:  0.9034063602035696  Training Accuracy:  0.70036507\n",
      "Epoch:  55  Training Loss:  0.8873493936928836  Training Accuracy:  0.7076664\n",
      "Epoch:  56  Training Loss:  0.8805478748950091  Training Accuracy:  0.7034541\n",
      "Epoch:  57  Training Loss:  0.8635109822858463  Training Accuracy:  0.70822805\n",
      "Epoch:  58  Training Loss:  0.8436599005352367  Training Accuracy:  0.72591966\n",
      "Epoch:  59  Training Loss:  0.840812270749699  Training Accuracy:  0.7284471\n",
      "Epoch:  60  Training Loss:  0.8211330617016012  Training Accuracy:  0.7357484\n",
      "Epoch:  61  Training Loss:  0.8092616799202832  Training Accuracy:  0.7329402\n",
      "Epoch:  62  Training Loss:  0.7995595230297609  Training Accuracy:  0.7500702\n",
      "Epoch:  63  Training Loss:  0.7838534444570542  Training Accuracy:  0.7531592\n",
      "Epoch:  64  Training Loss:  0.7620268973437223  Training Accuracy:  0.74473464\n",
      "Epoch:  65  Training Loss:  0.7457647068934007  Training Accuracy:  0.7528784\n",
      "Epoch:  66  Training Loss:  0.7442329921505668  Training Accuracy:  0.7596181\n",
      "Epoch:  67  Training Loss:  0.7291485012932257  Training Accuracy:  0.7657961\n",
      "Epoch:  68  Training Loss:  0.7278655201196671  Training Accuracy:  0.7708509\n",
      "Epoch:  69  Training Loss:  0.7142464964227243  Training Accuracy:  0.7789947\n",
      "Epoch:  70  Training Loss:  0.6910794015635143  Training Accuracy:  0.77197415\n",
      "Epoch:  71  Training Loss:  0.6835697482932698  Training Accuracy:  0.7801179\n",
      "Epoch:  72  Training Loss:  0.6773668207905509  Training Accuracy:  0.7809604\n",
      "Epoch:  73  Training Loss:  0.6605182176286524  Training Accuracy:  0.78264534\n",
      "Epoch:  74  Training Loss:  0.6533713117241859  Training Accuracy:  0.7868576\n",
      "Epoch:  75  Training Loss:  0.6382378350604664  Training Accuracy:  0.7910699\n",
      "Epoch:  76  Training Loss:  0.6370173074982383  Training Accuracy:  0.7950014\n",
      "Epoch:  77  Training Loss:  0.6153415452350269  Training Accuracy:  0.7947206\n",
      "Epoch:  78  Training Loss:  0.6197458991950209  Training Accuracy:  0.8008986\n",
      "Epoch:  79  Training Loss:  0.6141186042265459  Training Accuracy:  0.8056726\n",
      "Epoch:  80  Training Loss:  0.5937950529835441  Training Accuracy:  0.8048301\n",
      "Epoch:  81  Training Loss:  0.5894828753037886  Training Accuracy:  0.7994945\n",
      "Epoch:  82  Training Loss:  0.5726861043409868  Training Accuracy:  0.80174106\n",
      "Epoch:  83  Training Loss:  0.5741606651382013  Training Accuracy:  0.8048301\n",
      "Epoch:  84  Training Loss:  0.5687929321419108  Training Accuracy:  0.8087616\n",
      "Epoch:  85  Training Loss:  0.5626286777583036  Training Accuracy:  0.8107273\n",
      "Epoch:  86  Training Loss:  0.5523795463822104  Training Accuracy:  0.81578207\n",
      "Epoch:  87  Training Loss:  0.5392834200777791  Training Accuracy:  0.8185903\n",
      "Epoch:  88  Training Loss:  0.5320494941689752  Training Accuracy:  0.8171862\n",
      "Epoch:  89  Training Loss:  0.5216325368393552  Training Accuracy:  0.82364506\n",
      "Epoch:  90  Training Loss:  0.5146168290214105  Training Accuracy:  0.8247683\n",
      "Epoch:  91  Training Loss:  0.5089274208654057  Training Accuracy:  0.82504916\n",
      "Epoch:  92  Training Loss:  0.5085827380418777  Training Accuracy:  0.83038473\n",
      "Epoch:  93  Training Loss:  0.4938689788634127  Training Accuracy:  0.8242067\n",
      "Epoch:  94  Training Loss:  0.49448117099025035  Training Accuracy:  0.8360011\n",
      "Epoch:  95  Training Loss:  0.48979369456117805  Training Accuracy:  0.8413367\n",
      "Epoch:  96  Training Loss:  0.490293261679736  Training Accuracy:  0.83937097\n",
      "Epoch:  97  Training Loss:  0.4736335190859708  Training Accuracy:  0.83487785\n",
      "Epoch:  98  Training Loss:  0.47948822582309897  Training Accuracy:  0.8388093\n",
      "Epoch:  99  Training Loss:  0.48005906275727533  Training Accuracy:  0.83937097\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.87261146\n",
      "validation accuracy: 0.87261146\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.5674081693996085  Training Accuracy:  0.1024993\n",
      "Epoch:  1  Training Loss:  2.395236301422119  Training Accuracy:  0.12552653\n",
      "Epoch:  2  Training Loss:  2.3360828139565206  Training Accuracy:  0.1488346\n",
      "Epoch:  3  Training Loss:  2.2894228263334795  Training Accuracy:  0.17438921\n",
      "Epoch:  4  Training Loss:  2.238864150914279  Training Accuracy:  0.20640269\n",
      "Epoch:  5  Training Loss:  2.196181845664978  Training Accuracy:  0.24150519\n",
      "Epoch:  6  Training Loss:  2.1366727915677157  Training Accuracy:  0.26509407\n",
      "Epoch:  7  Training Loss:  2.088011880354448  Training Accuracy:  0.28334737\n",
      "Epoch:  8  Training Loss:  2.0299607916311784  Training Accuracy:  0.3046897\n",
      "Epoch:  9  Training Loss:  1.974999120018699  Training Accuracy:  0.31844988\n",
      "Epoch:  10  Training Loss:  1.9080470778725365  Training Accuracy:  0.34400448\n",
      "Epoch:  11  Training Loss:  1.8555429675362327  Training Accuracy:  0.36534682\n",
      "Epoch:  12  Training Loss:  1.8170746857469733  Training Accuracy:  0.39651784\n",
      "Epoch:  13  Training Loss:  1.7692129536108536  Training Accuracy:  0.41954508\n",
      "Epoch:  14  Training Loss:  1.7188539835539731  Training Accuracy:  0.44734624\n",
      "Epoch:  15  Training Loss:  1.6661412385377017  Training Accuracy:  0.45717496\n",
      "Epoch:  16  Training Loss:  1.6198562069372697  Training Accuracy:  0.4717776\n",
      "Epoch:  17  Training Loss:  1.5816899286075072  Training Accuracy:  0.48385286\n",
      "Epoch:  18  Training Loss:  1.5342469762672077  Training Accuracy:  0.50182533\n",
      "Epoch:  19  Training Loss:  1.4945567266507582  Training Accuracy:  0.5068801\n",
      "Epoch:  20  Training Loss:  1.4664265483617782  Training Accuracy:  0.52344847\n",
      "Epoch:  21  Training Loss:  1.4284515071998942  Training Accuracy:  0.5279416\n",
      "Epoch:  22  Training Loss:  1.3955771570855922  Training Accuracy:  0.5467565\n",
      "Epoch:  23  Training Loss:  1.3702540069818496  Training Accuracy:  0.5638865\n",
      "Epoch:  24  Training Loss:  1.3363312447612936  Training Accuracy:  0.5765234\n",
      "Epoch:  25  Training Loss:  1.3058618556369435  Training Accuracy:  0.58185905\n",
      "Epoch:  26  Training Loss:  1.2721750887957486  Training Accuracy:  0.59196854\n",
      "Epoch:  27  Training Loss:  1.2550996647639707  Training Accuracy:  0.59309185\n",
      "Epoch:  28  Training Loss:  1.2198677062988281  Training Accuracy:  0.6048863\n",
      "Epoch:  29  Training Loss:  1.2164262741804124  Training Accuracy:  0.6127492\n",
      "Epoch:  30  Training Loss:  1.1889488984238017  Training Accuracy:  0.628756\n",
      "Epoch:  31  Training Loss:  1.1552014827728272  Training Accuracy:  0.6222971\n",
      "Epoch:  32  Training Loss:  1.1379007279872895  Training Accuracy:  0.63746136\n",
      "Epoch:  33  Training Loss:  1.121877100521868  Training Accuracy:  0.6385847\n",
      "Epoch:  34  Training Loss:  1.1021698358384047  Training Accuracy:  0.65515304\n",
      "Epoch:  35  Training Loss:  1.0769340032880956  Training Accuracy:  0.6590845\n",
      "Epoch:  36  Training Loss:  1.0627926422791047  Training Accuracy:  0.652064\n",
      "Epoch:  37  Training Loss:  1.043444858897816  Training Accuracy:  0.6655434\n",
      "Epoch:  38  Training Loss:  1.0137532832947644  Training Accuracy:  0.67059815\n",
      "Epoch:  39  Training Loss:  1.00033973347057  Training Accuracy:  0.6837967\n",
      "Epoch:  40  Training Loss:  0.9892971987074072  Training Accuracy:  0.6852008\n",
      "Epoch:  41  Training Loss:  0.9782385530796918  Training Accuracy:  0.6950295\n",
      "Epoch:  42  Training Loss:  0.9484468442472545  Training Accuracy:  0.6967144\n",
      "Epoch:  43  Training Loss:  0.9272673782977191  Training Accuracy:  0.7028924\n",
      "Epoch:  44  Training Loss:  0.925976458733732  Training Accuracy:  0.7146869\n",
      "Epoch:  45  Training Loss:  0.9056241475723007  Training Accuracy:  0.7155293\n",
      "Epoch:  46  Training Loss:  0.8897411297668111  Training Accuracy:  0.71833754\n",
      "Epoch:  47  Training Loss:  0.8749566422267394  Training Accuracy:  0.7287279\n",
      "Epoch:  48  Training Loss:  0.8543902047655799  Training Accuracy:  0.7281662\n",
      "Epoch:  49  Training Loss:  0.8389933848922903  Training Accuracy:  0.73350185\n",
      "Epoch:  50  Training Loss:  0.8311293461106041  Training Accuracy:  0.73827577\n",
      "Epoch:  51  Training Loss:  0.8152197122573852  Training Accuracy:  0.750351\n",
      "Epoch:  52  Training Loss:  0.8029194447127256  Training Accuracy:  0.74782366\n",
      "Epoch:  53  Training Loss:  0.7903649786656554  Training Accuracy:  0.7489469\n",
      "Epoch:  54  Training Loss:  0.7727698775854978  Training Accuracy:  0.75091267\n",
      "Epoch:  55  Training Loss:  0.7576638720252297  Training Accuracy:  0.7627071\n",
      "Epoch:  56  Training Loss:  0.7532272848215971  Training Accuracy:  0.76326877\n",
      "Epoch:  57  Training Loss:  0.7365756928920746  Training Accuracy:  0.769166\n",
      "Epoch:  58  Training Loss:  0.7225488345731389  Training Accuracy:  0.7641112\n",
      "Epoch:  59  Training Loss:  0.7040815440091219  Training Accuracy:  0.7666386\n",
      "Epoch:  60  Training Loss:  0.702778880704533  Training Accuracy:  0.7736591\n",
      "Epoch:  61  Training Loss:  0.6898426478559321  Training Accuracy:  0.78573436\n",
      "Epoch:  62  Training Loss:  0.6837004096670585  Training Accuracy:  0.7823645\n",
      "Epoch:  63  Training Loss:  0.6650943249464035  Training Accuracy:  0.78264534\n",
      "Epoch:  64  Training Loss:  0.6696920747106726  Training Accuracy:  0.7910699\n",
      "Epoch:  65  Training Loss:  0.6556568576530977  Training Accuracy:  0.7919124\n",
      "Epoch:  66  Training Loss:  0.6407435533675281  Training Accuracy:  0.7964055\n",
      "Epoch:  67  Training Loss:  0.6319468931718306  Training Accuracy:  0.7913507\n",
      "Epoch:  68  Training Loss:  0.6230719207362695  Training Accuracy:  0.7975288\n",
      "Epoch:  69  Training Loss:  0.6113674014806747  Training Accuracy:  0.8056726\n",
      "Epoch:  70  Training Loss:  0.5937882865017111  Training Accuracy:  0.80146027\n",
      "Epoch:  71  Training Loss:  0.589861563322219  Training Accuracy:  0.81100816\n",
      "Epoch:  72  Training Loss:  0.5784415148198605  Training Accuracy:  0.81578207\n",
      "Epoch:  73  Training Loss:  0.5721508887681094  Training Accuracy:  0.8062342\n",
      "Epoch:  74  Training Loss:  0.5603756392543966  Training Accuracy:  0.8152204\n",
      "Epoch:  75  Training Loss:  0.5502911272374067  Training Accuracy:  0.8152204\n",
      "Epoch:  76  Training Loss:  0.5430991537191651  Training Accuracy:  0.81943274\n",
      "Epoch:  77  Training Loss:  0.5366089917719364  Training Accuracy:  0.8171862\n",
      "Epoch:  78  Training Loss:  0.5289171075956388  Training Accuracy:  0.8242067\n",
      "Epoch:  79  Training Loss:  0.5218281451951373  Training Accuracy:  0.8278573\n",
      "Epoch:  80  Training Loss:  0.516584974527359  Training Accuracy:  0.8301039\n",
      "Epoch:  81  Training Loss:  0.4999633790417151  Training Accuracy:  0.82645327\n",
      "Epoch:  82  Training Loss:  0.4988872142000632  Training Accuracy:  0.83656275\n",
      "Epoch:  83  Training Loss:  0.487772700055079  Training Accuracy:  0.83178884\n",
      "Epoch:  84  Training Loss:  0.4823372759602287  Training Accuracy:  0.83319294\n",
      "Epoch:  85  Training Loss:  0.48783194639466027  Training Accuracy:  0.8281382\n",
      "Epoch:  86  Training Loss:  0.4773763864555142  Training Accuracy:  0.83628196\n",
      "Epoch:  87  Training Loss:  0.46545597186142745  Training Accuracy:  0.83909017\n",
      "Epoch:  88  Training Loss:  0.4628783204338767  Training Accuracy:  0.83347374\n",
      "Epoch:  89  Training Loss:  0.4598093646493825  Training Accuracy:  0.8418983\n",
      "Epoch:  90  Training Loss:  0.4597080539573323  Training Accuracy:  0.8452682\n",
      "Epoch:  91  Training Loss:  0.45177851861173457  Training Accuracy:  0.845549\n",
      "Epoch:  92  Training Loss:  0.4463509898294102  Training Accuracy:  0.8427408\n",
      "Epoch:  93  Training Loss:  0.44480515623634514  Training Accuracy:  0.8514462\n",
      "Epoch:  94  Training Loss:  0.4308365695855834  Training Accuracy:  0.85088456\n",
      "Epoch:  95  Training Loss:  0.4260184940289367  Training Accuracy:  0.84891886\n",
      "Epoch:  96  Training Loss:  0.42554183622652836  Training Accuracy:  0.85060376\n",
      "Epoch:  97  Training Loss:  0.4192397888411175  Training Accuracy:  0.8511654\n",
      "Epoch:  98  Training Loss:  0.41590709361163053  Training Accuracy:  0.8483572\n",
      "Epoch:  99  Training Loss:  0.41389334533702243  Training Accuracy:  0.8528503\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.8678344\n",
      "validation accuracy: 0.8678344\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.4613447232679886  Training Accuracy:  0.12833473\n",
      "Epoch:  1  Training Loss:  2.352722419391979  Training Accuracy:  0.15108116\n",
      "Epoch:  2  Training Loss:  2.2970517201857135  Training Accuracy:  0.17298512\n",
      "Epoch:  3  Training Loss:  2.2376987608996304  Training Accuracy:  0.21735467\n",
      "Epoch:  4  Training Loss:  2.1660174109719015  Training Accuracy:  0.24796405\n",
      "Epoch:  5  Training Loss:  2.116449015790766  Training Accuracy:  0.26790228\n",
      "Epoch:  6  Training Loss:  2.0638087771155615  Training Accuracy:  0.30384722\n",
      "Epoch:  7  Training Loss:  2.0091627153483302  Training Accuracy:  0.31844988\n",
      "Epoch:  8  Training Loss:  1.9595784111456438  Training Accuracy:  0.34597024\n",
      "Epoch:  9  Training Loss:  1.9169485969976945  Training Accuracy:  0.35860714\n",
      "Epoch:  10  Training Loss:  1.8701346158981322  Training Accuracy:  0.36759338\n",
      "Epoch:  11  Training Loss:  1.8276871757073836  Training Accuracy:  0.39090145\n",
      "Epoch:  12  Training Loss:  1.7752417607740922  Training Accuracy:  0.41954508\n",
      "Epoch:  13  Training Loss:  1.7380485534667969  Training Accuracy:  0.42094916\n",
      "Epoch:  14  Training Loss:  1.7031438952142541  Training Accuracy:  0.44116822\n",
      "Epoch:  15  Training Loss:  1.6631948080929844  Training Accuracy:  0.45885986\n",
      "Epoch:  16  Training Loss:  1.6244550005956129  Training Accuracy:  0.4619489\n",
      "Epoch:  17  Training Loss:  1.593536167795008  Training Accuracy:  0.47570908\n",
      "Epoch:  18  Training Loss:  1.560945839773525  Training Accuracy:  0.47711316\n",
      "Epoch:  19  Training Loss:  1.521347742730921  Training Accuracy:  0.48694187\n",
      "Epoch:  20  Training Loss:  1.4893785633824088  Training Accuracy:  0.5043527\n",
      "Epoch:  21  Training Loss:  1.4564152159474113  Training Accuracy:  0.49873632\n",
      "Epoch:  22  Training Loss:  1.4243003211238168  Training Accuracy:  0.49761304\n",
      "Epoch:  23  Training Loss:  1.4107951437885111  Training Accuracy:  0.51586634\n",
      "Epoch:  24  Training Loss:  1.3707947498018092  Training Accuracy:  0.5282224\n",
      "Epoch:  25  Training Loss:  1.3517336785793304  Training Accuracy:  0.5408593\n",
      "Epoch:  26  Training Loss:  1.3172532295638866  Training Accuracy:  0.5461949\n",
      "Epoch:  27  Training Loss:  1.3031105529178273  Training Accuracy:  0.55209213\n",
      "Epoch:  28  Training Loss:  1.281987046382644  Training Accuracy:  0.5495647\n",
      "Epoch:  29  Training Loss:  1.2617833012884314  Training Accuracy:  0.5641674\n",
      "Epoch:  30  Training Loss:  1.2436571898785505  Training Accuracy:  0.58073574\n",
      "Epoch:  31  Training Loss:  1.2202923893928528  Training Accuracy:  0.56529063\n",
      "Epoch:  32  Training Loss:  1.202863776141947  Training Accuracy:  0.592811\n",
      "Epoch:  33  Training Loss:  1.1864835798740387  Training Accuracy:  0.5998315\n",
      "Epoch:  34  Training Loss:  1.1578842615539378  Training Accuracy:  0.6048863\n",
      "Epoch:  35  Training Loss:  1.147078346122395  Training Accuracy:  0.6040438\n",
      "Epoch:  36  Training Loss:  1.1247483716769653  Training Accuracy:  0.62005055\n",
      "Epoch:  37  Training Loss:  1.1056727609851145  Training Accuracy:  0.6304409\n",
      "Epoch:  38  Training Loss:  1.087395803494887  Training Accuracy:  0.6352148\n",
      "Epoch:  39  Training Loss:  1.081528706442226  Training Accuracy:  0.6385847\n",
      "Epoch:  40  Training Loss:  1.0563058582219211  Training Accuracy:  0.63689977\n",
      "Epoch:  41  Training Loss:  1.0382919346744364  Training Accuracy:  0.63577646\n",
      "Epoch:  42  Training Loss:  1.022117712280967  Training Accuracy:  0.65824205\n",
      "Epoch:  43  Training Loss:  1.0104353660886938  Training Accuracy:  0.6559955\n",
      "Epoch:  44  Training Loss:  1.002691481601108  Training Accuracy:  0.6585229\n",
      "Epoch:  45  Training Loss:  0.9837753396142613  Training Accuracy:  0.6700365\n",
      "Epoch:  46  Training Loss:  0.9646953531286934  Training Accuracy:  0.6759337\n",
      "Epoch:  47  Training Loss:  0.9542146130041642  Training Accuracy:  0.68632406\n",
      "Epoch:  48  Training Loss:  0.9373600710522044  Training Accuracy:  0.68772817\n",
      "Epoch:  49  Training Loss:  0.9384134764021094  Training Accuracy:  0.6899747\n",
      "Epoch:  50  Training Loss:  0.9058334919539365  Training Accuracy:  0.69559115\n",
      "Epoch:  51  Training Loss:  0.9037947503003207  Training Accuracy:  0.70036507\n",
      "Epoch:  52  Training Loss:  0.8794851698658683  Training Accuracy:  0.7110362\n",
      "Epoch:  53  Training Loss:  0.8748315001075918  Training Accuracy:  0.7090705\n",
      "Epoch:  54  Training Loss:  0.8644785163077441  Training Accuracy:  0.71665263\n",
      "Epoch:  55  Training Loss:  0.8464791964400898  Training Accuracy:  0.7262005\n",
      "Epoch:  56  Training Loss:  0.8266866613518108  Training Accuracy:  0.7264813\n",
      "Epoch:  57  Training Loss:  0.829155032472177  Training Accuracy:  0.7374333\n",
      "Epoch:  58  Training Loss:  0.8038570626215501  Training Accuracy:  0.73827577\n",
      "Epoch:  59  Training Loss:  0.7994270517067475  Training Accuracy:  0.7413648\n",
      "Epoch:  60  Training Loss:  0.7880328286777843  Training Accuracy:  0.7438922\n",
      "Epoch:  61  Training Loss:  0.7715287642045454  Training Accuracy:  0.75063187\n",
      "Epoch:  62  Training Loss:  0.76564506102692  Training Accuracy:  0.74950856\n",
      "Epoch:  63  Training Loss:  0.7569625775922428  Training Accuracy:  0.7610222\n",
      "Epoch:  64  Training Loss:  0.7431060585108671  Training Accuracy:  0.75933725\n",
      "Epoch:  65  Training Loss:  0.7157071129842238  Training Accuracy:  0.76242626\n",
      "Epoch:  66  Training Loss:  0.7135734124617144  Training Accuracy:  0.77450156\n",
      "Epoch:  67  Training Loss:  0.7119666370478543  Training Accuracy:  0.77000844\n",
      "Epoch:  68  Training Loss:  0.691746221889149  Training Accuracy:  0.77309746\n",
      "Epoch:  69  Training Loss:  0.6860277668996291  Training Accuracy:  0.78292614\n",
      "Epoch:  70  Training Loss:  0.6686958838592876  Training Accuracy:  0.7803988\n",
      "Epoch:  71  Training Loss:  0.6549904636361382  Training Accuracy:  0.78882337\n",
      "Epoch:  72  Training Loss:  0.648279012333263  Training Accuracy:  0.7896658\n",
      "Epoch:  73  Training Loss:  0.635838214375756  Training Accuracy:  0.7947206\n",
      "Epoch:  74  Training Loss:  0.6330723068930886  Training Accuracy:  0.7964055\n",
      "Epoch:  75  Training Loss:  0.6175013906576416  Training Accuracy:  0.8062342\n",
      "Epoch:  76  Training Loss:  0.6087436085397547  Training Accuracy:  0.8037068\n",
      "Epoch:  77  Training Loss:  0.602414191311056  Training Accuracy:  0.80174106\n",
      "Epoch:  78  Training Loss:  0.5936144845052199  Training Accuracy:  0.8104465\n",
      "Epoch:  79  Training Loss:  0.5796147349205885  Training Accuracy:  0.8185903\n",
      "Epoch:  80  Training Loss:  0.5742851283062588  Training Accuracy:  0.8169054\n",
      "Epoch:  81  Training Loss:  0.5656759281050076  Training Accuracy:  0.8213985\n",
      "Epoch:  82  Training Loss:  0.5544233644550497  Training Accuracy:  0.82224095\n",
      "Epoch:  83  Training Loss:  0.5405768433755095  Training Accuracy:  0.8242067\n",
      "Epoch:  84  Training Loss:  0.5377309429374608  Training Accuracy:  0.8289806\n",
      "Epoch:  85  Training Loss:  0.5234731557694349  Training Accuracy:  0.8242067\n",
      "Epoch:  86  Training Loss:  0.5304686815901236  Training Accuracy:  0.82504916\n",
      "Epoch:  87  Training Loss:  0.5102513887665489  Training Accuracy:  0.82841897\n",
      "Epoch:  88  Training Loss:  0.5062157960777933  Training Accuracy:  0.83796686\n",
      "Epoch:  89  Training Loss:  0.4838842264630578  Training Accuracy:  0.8435833\n",
      "Epoch:  90  Training Loss:  0.48641709956255824  Training Accuracy:  0.83937097\n",
      "Epoch:  91  Training Loss:  0.4739135198972442  Training Accuracy:  0.8374052\n",
      "Epoch:  92  Training Loss:  0.4773795738816261  Training Accuracy:  0.83459705\n",
      "Epoch:  93  Training Loss:  0.4654504988681186  Training Accuracy:  0.84723395\n",
      "Epoch:  94  Training Loss:  0.4722128561951897  Training Accuracy:  0.845549\n",
      "Epoch:  95  Training Loss:  0.4617290206930854  Training Accuracy:  0.8511654\n",
      "Epoch:  96  Training Loss:  0.4541215547106483  Training Accuracy:  0.8494805\n",
      "Epoch:  97  Training Loss:  0.43942916704849766  Training Accuracy:  0.8621174\n",
      "Epoch:  98  Training Loss:  0.4281100331382318  Training Accuracy:  0.8514462\n",
      "Epoch:  99  Training Loss:  0.42711732577193867  Training Accuracy:  0.8514462\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.8996815\n",
      "validation accuracy: 0.8996815\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 5\n",
    "\n",
    "for i in range(num_experiments):\n",
    "    model.W_conv2_weight = model2.W_conv2_weight\n",
    "    model.b_conv2_weight = model2.b_conv2_weight\n",
    "    model.build_model(self_training=False, load_weights=True)\n",
    "    model.run_model(training_epochs=100, learning_rate=0.0001)\n",
    "    test_accuracy, val_accuracy, y_pred, y_true = model.test()\n",
    "    stats.add(test_accuracy, val_accuracy, y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy. Mean (std) = 0.872 (0.015)\n",
      "Val accuracy. Mean (std) = 0.872 (0.015)\n",
      "f1 score weighted. Mean (std) = 0.869 (0.016)\n",
      "f1 score mean. Mean (std) = 0.858 (0.016)\n"
     ]
    }
   ],
   "source": [
    "stats.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Multi-class classification: flip, permute, time warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opp\n",
      "X shape = (?, 1, 23, 77)\n",
      "Y shape = (?, 4)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 77, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 17, 128)\n",
      "h_pool1 shape = (?, 1, 6, 128)\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 4, 128)\n",
      "h_pool2 shape = (?, 1, 1, 128)\n",
      "shape's shape: [None, 1, 1, 128]\n",
      "c_flat shape = (?, 128)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (63650, 18)\n",
      "test_y shape(1-hot) = (10955, 18)\n",
      "train_x_reshaped =  (63650, 1, 23, 77)\n",
      "test_x_reshaped =  (10955, 1, 23, 77)\n",
      "train_x shape = (63650, 23, 77)\n",
      "train_y shape = (63650,)\n",
      "test_x shape = (10955, 23, 77)\n",
      "test_y shape = (10955,)\n",
      "Epoch:  0  Training Loss:  1.4693549322170512  Training Accuracy:  0.2492066\n",
      "Epoch:  1  Training Loss:  1.3923014126553142  Training Accuracy:  0.2522388\n",
      "Epoch:  2  Training Loss:  1.3902625898480176  Training Accuracy:  0.24981932\n",
      "Epoch:  3  Training Loss:  1.3892356820509468  Training Accuracy:  0.2504792\n",
      "Epoch:  4  Training Loss:  1.3886245978430243  Training Accuracy:  0.25115475\n",
      "Epoch:  5  Training Loss:  1.3881777602901881  Training Accuracy:  0.25032207\n",
      "Epoch:  6  Training Loss:  1.387413090263574  Training Accuracy:  0.25233307\n",
      "Epoch:  7  Training Loss:  1.3876038590667232  Training Accuracy:  0.2504949\n",
      "Epoch:  8  Training Loss:  1.3874346272086713  Training Accuracy:  0.25104478\n",
      "Epoch:  9  Training Loss:  1.3869733524994112  Training Accuracy:  0.25110763\n",
      "Epoch:  10  Training Loss:  1.386629989449407  Training Accuracy:  0.2522231\n",
      "Epoch:  11  Training Loss:  1.3867855021651363  Training Accuracy:  0.25233307\n",
      "Epoch:  12  Training Loss:  1.3864447822273378  Training Accuracy:  0.24994501\n",
      "Epoch:  13  Training Loss:  1.3864626456314408  Training Accuracy:  0.24917518\n",
      "Epoch:  14  Training Loss:  1.3865805184337454  Training Accuracy:  0.25065202\n",
      "Epoch:  15  Training Loss:  1.386564502173986  Training Accuracy:  0.25142184\n",
      "Epoch:  16  Training Loss:  1.3869646792440586  Training Accuracy:  0.25118616\n",
      "Epoch:  17  Training Loss:  1.3864321646316191  Training Accuracy:  0.24840534\n",
      "Epoch:  18  Training Loss:  1.386244070721824  Training Accuracy:  0.25084054\n",
      "Epoch:  19  Training Loss:  1.3862840520064357  Training Accuracy:  0.248641\n",
      "Epoch:  20  Training Loss:  1.386359436651111  Training Accuracy:  0.24942656\n",
      "Epoch:  21  Training Loss:  1.386677109859359  Training Accuracy:  0.25146896\n",
      "Epoch:  22  Training Loss:  1.3862246320521088  Training Accuracy:  0.249348\n",
      "Epoch:  23  Training Loss:  1.3862270330279407  Training Accuracy:  0.24959937\n",
      "Epoch:  24  Training Loss:  1.3864471375102727  Training Accuracy:  0.25154752\n",
      "Epoch:  25  Training Loss:  1.3861956976549006  Training Accuracy:  0.24967793\n",
      "Epoch:  26  Training Loss:  1.3866244526936016  Training Accuracy:  0.24892381\n",
      "Epoch:  27  Training Loss:  1.3861694026521034  Training Accuracy:  0.24947369\n",
      "Epoch:  28  Training Loss:  1.3862201909663932  Training Accuracy:  0.25228593\n",
      "Epoch:  29  Training Loss:  1.3863901450360565  Training Accuracy:  0.24928515\n",
      "Epoch:  30  Training Loss:  1.3862977974131794  Training Accuracy:  0.25255302\n",
      "Epoch:  31  Training Loss:  1.386180645263411  Training Accuracy:  0.2508248\n",
      "Epoch:  32  Training Loss:  1.386134934017596  Training Accuracy:  0.25011784\n",
      "Epoch:  33  Training Loss:  1.3861183470163787  Training Accuracy:  0.24827966\n",
      "Epoch:  34  Training Loss:  1.3861364595127297  Training Accuracy:  0.25132757\n",
      "Epoch:  35  Training Loss:  1.3866448647059666  Training Accuracy:  0.25055775\n",
      "Epoch:  36  Training Loss:  1.3862624449029535  Training Accuracy:  0.24953653\n",
      "Epoch:  37  Training Loss:  1.386237654527668  Training Accuracy:  0.25055775\n",
      "Epoch:  38  Training Loss:  1.386220329844016  Training Accuracy:  0.2508091\n",
      "Epoch:  39  Training Loss:  1.3861338108837964  Training Accuracy:  0.24815397\n",
      "Epoch:  40  Training Loss:  1.3864526438041471  Training Accuracy:  0.24917518\n",
      "Epoch:  41  Training Loss:  1.3861865066666479  Training Accuracy:  0.2505106\n",
      "Epoch:  42  Training Loss:  1.3861982366688534  Training Accuracy:  0.25231737\n",
      "Epoch:  43  Training Loss:  1.386172729838542  Training Accuracy:  0.24983503\n",
      "Epoch:  44  Training Loss:  1.3860778235333786  Training Accuracy:  0.25231737\n",
      "Epoch:  45  Training Loss:  1.386195185318799  Training Accuracy:  0.25113904\n",
      "Epoch:  46  Training Loss:  1.3862320347810895  Training Accuracy:  0.24779262\n",
      "Epoch:  47  Training Loss:  1.3866334563529708  Training Accuracy:  0.24900235\n",
      "Epoch:  48  Training Loss:  1.386341412182545  Training Accuracy:  0.24915947\n",
      "Epoch:  49  Training Loss:  1.386266738356239  Training Accuracy:  0.24996072\n"
     ]
    }
   ],
   "source": [
    "stats3 = Statistics()\n",
    "model3 = Model(dataset_obj2)\n",
    "model3.build_model(self_training=True, num_transforms=4)\n",
    "transforms = [identity, flip, permute, time_warp]\n",
    "model3.self_train(transforms, 50, 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.5631681290539827  Training Accuracy:  0.1151362\n",
      "Epoch:  1  Training Loss:  2.388054453242909  Training Accuracy:  0.13086212\n",
      "Epoch:  2  Training Loss:  2.313029967654835  Training Accuracy:  0.17523168\n",
      "Epoch:  3  Training Loss:  2.2757794293490323  Training Accuracy:  0.20050548\n",
      "Epoch:  4  Training Loss:  2.236397647857666  Training Accuracy:  0.23223813\n",
      "Epoch:  5  Training Loss:  2.177324227853255  Training Accuracy:  0.24262847\n",
      "Epoch:  6  Training Loss:  2.1331098383123224  Training Accuracy:  0.2614434\n",
      "Epoch:  7  Training Loss:  2.077520567720587  Training Accuracy:  0.2875597\n",
      "Epoch:  8  Training Loss:  2.037169415300543  Training Accuracy:  0.30440888\n",
      "Epoch:  9  Training Loss:  1.9854110945354808  Training Accuracy:  0.32799774\n",
      "Epoch:  10  Training Loss:  1.9387850631367076  Training Accuracy:  0.34765515\n",
      "Epoch:  11  Training Loss:  1.8947310252623124  Training Accuracy:  0.37236732\n",
      "Epoch:  12  Training Loss:  1.8517158356579868  Training Accuracy:  0.38725078\n",
      "Epoch:  13  Training Loss:  1.797160378369418  Training Accuracy:  0.4085931\n",
      "Epoch:  14  Training Loss:  1.7623937379230152  Training Accuracy:  0.42881215\n",
      "Epoch:  15  Training Loss:  1.7196227832274003  Training Accuracy:  0.44313395\n",
      "Epoch:  16  Training Loss:  1.674868322502483  Training Accuracy:  0.45268184\n",
      "Epoch:  17  Training Loss:  1.6356496014378288  Training Accuracy:  0.4650379\n",
      "Epoch:  18  Training Loss:  1.5884731395678087  Training Accuracy:  0.4818871\n",
      "Epoch:  19  Training Loss:  1.5580994993448258  Training Accuracy:  0.4903117\n",
      "Epoch:  20  Training Loss:  1.5194716247645292  Training Accuracy:  0.49368155\n",
      "Epoch:  21  Training Loss:  1.4921060849319805  Training Accuracy:  0.4998596\n",
      "Epoch:  22  Training Loss:  1.4510170378468252  Training Accuracy:  0.50940746\n",
      "Epoch:  23  Training Loss:  1.4145406872034072  Training Accuracy:  0.5209211\n",
      "Epoch:  24  Training Loss:  1.3896177817474713  Training Accuracy:  0.5296265\n",
      "Epoch:  25  Training Loss:  1.3652504660866478  Training Accuracy:  0.53440046\n",
      "Epoch:  26  Training Loss:  1.3359857938506388  Training Accuracy:  0.5467565\n",
      "Epoch:  27  Training Loss:  1.3104726845567876  Training Accuracy:  0.55855095\n",
      "Epoch:  28  Training Loss:  1.2848915262655778  Training Accuracy:  0.55967426\n",
      "Epoch:  29  Training Loss:  1.2517704895951531  Training Accuracy:  0.5644482\n",
      "Epoch:  30  Training Loss:  1.232698345184326  Training Accuracy:  0.5728728\n",
      "Epoch:  31  Training Loss:  1.211502038619735  Training Accuracy:  0.5784892\n",
      "Epoch:  32  Training Loss:  1.2008512291041287  Training Accuracy:  0.5751194\n",
      "Epoch:  33  Training Loss:  1.1840700455687263  Training Accuracy:  0.59337264\n",
      "Epoch:  34  Training Loss:  1.1648205469955097  Training Accuracy:  0.6127492\n",
      "Epoch:  35  Training Loss:  1.1491168203678999  Training Accuracy:  0.6124684\n",
      "Epoch:  36  Training Loss:  1.1174157746813513  Training Accuracy:  0.62426287\n",
      "Epoch:  37  Training Loss:  1.1057960580695758  Training Accuracy:  0.62145466\n",
      "Epoch:  38  Training Loss:  1.09223871095614  Training Accuracy:  0.6276327\n",
      "Epoch:  39  Training Loss:  1.076548171043396  Training Accuracy:  0.6385847\n",
      "Epoch:  40  Training Loss:  1.060329486023296  Training Accuracy:  0.6413929\n",
      "Epoch:  41  Training Loss:  1.043548542802984  Training Accuracy:  0.6472901\n",
      "Epoch:  42  Training Loss:  1.0408098139546134  Training Accuracy:  0.65796125\n",
      "Epoch:  43  Training Loss:  1.0214177930896933  Training Accuracy:  0.6554339\n",
      "Epoch:  44  Training Loss:  0.9957193453203548  Training Accuracy:  0.6590845\n",
      "Epoch:  45  Training Loss:  0.9843990618532354  Training Accuracy:  0.6700365\n",
      "Epoch:  46  Training Loss:  0.974868661978028  Training Accuracy:  0.6697557\n",
      "Epoch:  47  Training Loss:  0.9667380847714164  Training Accuracy:  0.67537206\n",
      "Epoch:  48  Training Loss:  0.9529503508047624  Training Accuracy:  0.67228305\n",
      "Epoch:  49  Training Loss:  0.9490721518343145  Training Accuracy:  0.6905364\n",
      "Epoch:  50  Training Loss:  0.925177490440282  Training Accuracy:  0.69474864\n",
      "Epoch:  51  Training Loss:  0.9163723940199072  Training Accuracy:  0.6837967\n",
      "Epoch:  52  Training Loss:  0.9069181176749143  Training Accuracy:  0.6896939\n",
      "Epoch:  53  Training Loss:  0.8920744998888536  Training Accuracy:  0.68211174\n",
      "Epoch:  54  Training Loss:  0.8717699273066087  Training Accuracy:  0.7031733\n",
      "Epoch:  55  Training Loss:  0.8720590512860905  Training Accuracy:  0.70710474\n",
      "Epoch:  56  Training Loss:  0.8594766446135261  Training Accuracy:  0.7034541\n",
      "Epoch:  57  Training Loss:  0.8570761358196085  Training Accuracy:  0.71918\n",
      "Epoch:  58  Training Loss:  0.8332820190624757  Training Accuracy:  0.72535807\n",
      "Epoch:  59  Training Loss:  0.817289039221677  Training Accuracy:  0.72591966\n",
      "Epoch:  60  Training Loss:  0.8183639014309103  Training Accuracy:  0.730132\n",
      "Epoch:  61  Training Loss:  0.7989084167913957  Training Accuracy:  0.7273238\n",
      "Epoch:  62  Training Loss:  0.8002672314643859  Training Accuracy:  0.73659086\n",
      "Epoch:  63  Training Loss:  0.7879725456237793  Training Accuracy:  0.74613875\n",
      "Epoch:  64  Training Loss:  0.7803579902107065  Training Accuracy:  0.74782366\n",
      "Epoch:  65  Training Loss:  0.775064295259389  Training Accuracy:  0.74333054\n",
      "Epoch:  66  Training Loss:  0.7536834930831736  Training Accuracy:  0.74613875\n",
      "Epoch:  67  Training Loss:  0.7414678784933957  Training Accuracy:  0.75877565\n",
      "Epoch:  68  Training Loss:  0.7309861605817621  Training Accuracy:  0.74922776\n",
      "Epoch:  69  Training Loss:  0.7251229269938035  Training Accuracy:  0.7568099\n",
      "Epoch:  70  Training Loss:  0.7164456161585722  Training Accuracy:  0.75091267\n",
      "Epoch:  71  Training Loss:  0.713630490953272  Training Accuracy:  0.75933725\n",
      "Epoch:  72  Training Loss:  0.6971813770857724  Training Accuracy:  0.75765234\n",
      "Epoch:  73  Training Loss:  0.6970905244350434  Training Accuracy:  0.7663578\n",
      "Epoch:  74  Training Loss:  0.6780478533018719  Training Accuracy:  0.769166\n",
      "Epoch:  75  Training Loss:  0.683211399750276  Training Accuracy:  0.769166\n",
      "Epoch:  76  Training Loss:  0.6771270172162489  Training Accuracy:  0.77197415\n",
      "Epoch:  77  Training Loss:  0.6503862692551179  Training Accuracy:  0.7728166\n",
      "Epoch:  78  Training Loss:  0.6565949632362886  Training Accuracy:  0.78264534\n",
      "Epoch:  79  Training Loss:  0.6524009336124766  Training Accuracy:  0.77955633\n",
      "Epoch:  80  Training Loss:  0.6416447753256017  Training Accuracy:  0.7756248\n",
      "Epoch:  81  Training Loss:  0.636943682892756  Training Accuracy:  0.7775906\n",
      "Epoch:  82  Training Loss:  0.6128824872049419  Training Accuracy:  0.7865768\n",
      "Epoch:  83  Training Loss:  0.63830845952034  Training Accuracy:  0.7773097\n",
      "Epoch:  84  Training Loss:  0.622548107938333  Training Accuracy:  0.7834878\n",
      "Epoch:  85  Training Loss:  0.6105795581232417  Training Accuracy:  0.79415894\n",
      "Epoch:  86  Training Loss:  0.6042809785767035  Training Accuracy:  0.78854257\n",
      "Epoch:  87  Training Loss:  0.5979342203248631  Training Accuracy:  0.80117947\n",
      "Epoch:  88  Training Loss:  0.5903653738173571  Training Accuracy:  0.7902275\n",
      "Epoch:  89  Training Loss:  0.5824148970571431  Training Accuracy:  0.80033696\n",
      "Epoch:  90  Training Loss:  0.5811809279701926  Training Accuracy:  0.7978096\n",
      "Epoch:  91  Training Loss:  0.5655258292501623  Training Accuracy:  0.80679584\n",
      "Epoch:  92  Training Loss:  0.554419485682791  Training Accuracy:  0.8056726\n",
      "Epoch:  93  Training Loss:  0.553203065016053  Training Accuracy:  0.80651504\n",
      "Epoch:  94  Training Loss:  0.5598112665794113  Training Accuracy:  0.8062342\n",
      "Epoch:  95  Training Loss:  0.5314138692888346  Training Accuracy:  0.80679584\n",
      "Epoch:  96  Training Loss:  0.5374895179813558  Training Accuracy:  0.81241226\n",
      "Epoch:  97  Training Loss:  0.530163918977434  Training Accuracy:  0.82083684\n",
      "Epoch:  98  Training Loss:  0.5269967638633468  Training Accuracy:  0.8160629\n",
      "Epoch:  99  Training Loss:  0.5202657709067519  Training Accuracy:  0.81578207\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.83598727\n",
      "validation accuracy: 0.83598727\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.4876030510122127  Training Accuracy:  0.1039034\n",
      "Epoch:  1  Training Loss:  2.3806334582242097  Training Accuracy:  0.12608817\n",
      "Epoch:  2  Training Loss:  2.3224337946284903  Training Accuracy:  0.15473181\n",
      "Epoch:  3  Training Loss:  2.286643628640608  Training Accuracy:  0.17747824\n",
      "Epoch:  4  Training Loss:  2.2323685559359463  Training Accuracy:  0.22577928\n",
      "Epoch:  5  Training Loss:  2.1734532291238957  Training Accuracy:  0.26509407\n",
      "Epoch:  6  Training Loss:  2.1125527403571387  Training Accuracy:  0.29458016\n",
      "Epoch:  7  Training Loss:  2.0450926824049516  Training Accuracy:  0.3372648\n",
      "Epoch:  8  Training Loss:  1.9980576796965166  Training Accuracy:  0.35748386\n",
      "Epoch:  9  Training Loss:  1.9152758121490479  Training Accuracy:  0.37826455\n",
      "Epoch:  10  Training Loss:  1.8572788325223055  Training Accuracy:  0.39932603\n",
      "Epoch:  11  Training Loss:  1.8043355399912053  Training Accuracy:  0.41757932\n",
      "Epoch:  12  Training Loss:  1.7525113051587886  Training Accuracy:  0.43190116\n",
      "Epoch:  13  Training Loss:  1.6884813492948358  Training Accuracy:  0.4422915\n",
      "Epoch:  14  Training Loss:  1.6525796695189043  Training Accuracy:  0.46812692\n",
      "Epoch:  15  Training Loss:  1.5946172865954313  Training Accuracy:  0.47093514\n",
      "Epoch:  16  Training Loss:  1.549171764200384  Training Accuracy:  0.4745858\n",
      "Epoch:  17  Training Loss:  1.5152713510123166  Training Accuracy:  0.5004212\n",
      "Epoch:  18  Training Loss:  1.4813887146386233  Training Accuracy:  0.50603765\n",
      "Epoch:  19  Training Loss:  1.4477263840762051  Training Accuracy:  0.5102499\n",
      "Epoch:  20  Training Loss:  1.41064760630781  Training Accuracy:  0.5310306\n",
      "Epoch:  21  Training Loss:  1.38423393368721  Training Accuracy:  0.54591405\n",
      "Epoch:  22  Training Loss:  1.3545770515095104  Training Accuracy:  0.55658525\n",
      "Epoch:  23  Training Loss:  1.335773089799014  Training Accuracy:  0.57905084\n",
      "Epoch:  24  Training Loss:  1.3033811303702267  Training Accuracy:  0.57736593\n",
      "Epoch:  25  Training Loss:  1.2720023588700728  Training Accuracy:  0.57764673\n",
      "Epoch:  26  Training Loss:  1.2622684679248117  Training Accuracy:  0.5860713\n",
      "Epoch:  27  Training Loss:  1.2285928016359156  Training Accuracy:  0.59955066\n",
      "Epoch:  28  Training Loss:  1.2116059227423235  Training Accuracy:  0.6048863\n",
      "Epoch:  29  Training Loss:  1.1888965053991838  Training Accuracy:  0.6163999\n",
      "Epoch:  30  Training Loss:  1.169191618941047  Training Accuracy:  0.61696154\n",
      "Epoch:  31  Training Loss:  1.149253723296252  Training Accuracy:  0.62426287\n",
      "Epoch:  32  Training Loss:  1.1374298507517033  Training Accuracy:  0.62819433\n",
      "Epoch:  33  Training Loss:  1.1181412878361616  Training Accuracy:  0.62173545\n",
      "Epoch:  34  Training Loss:  1.0983516622673382  Training Accuracy:  0.6332491\n",
      "Epoch:  35  Training Loss:  1.0792801786552777  Training Accuracy:  0.6517832\n",
      "Epoch:  36  Training Loss:  1.0630642492662776  Training Accuracy:  0.65627635\n",
      "Epoch:  37  Training Loss:  1.0599583241072568  Training Accuracy:  0.6616119\n",
      "Epoch:  38  Training Loss:  1.0306096496907147  Training Accuracy:  0.6588037\n",
      "Epoch:  39  Training Loss:  1.0129318898374384  Training Accuracy:  0.67228305\n",
      "Epoch:  40  Training Loss:  0.9990845886143771  Training Accuracy:  0.6778995\n",
      "Epoch:  41  Training Loss:  0.9928691663525321  Training Accuracy:  0.6790227\n",
      "Epoch:  42  Training Loss:  0.9820056877352975  Training Accuracy:  0.6899747\n",
      "Epoch:  43  Training Loss:  0.9562745676799254  Training Accuracy:  0.6776186\n",
      "Epoch:  44  Training Loss:  0.9392404981634833  Training Accuracy:  0.69727606\n",
      "Epoch:  45  Training Loss:  0.9258734258738431  Training Accuracy:  0.7009267\n",
      "Epoch:  46  Training Loss:  0.9097558812661605  Training Accuracy:  0.7042965\n",
      "Epoch:  47  Training Loss:  0.8983327207240192  Training Accuracy:  0.70008427\n",
      "Epoch:  48  Training Loss:  0.8970128639177842  Training Accuracy:  0.70738554\n",
      "Epoch:  49  Training Loss:  0.8878512729297985  Training Accuracy:  0.71805674\n",
      "Epoch:  50  Training Loss:  0.8554675500501286  Training Accuracy:  0.7174951\n",
      "Epoch:  51  Training Loss:  0.8537472957914526  Training Accuracy:  0.7146869\n",
      "Epoch:  52  Training Loss:  0.8435256389054385  Training Accuracy:  0.7304128\n",
      "Epoch:  53  Training Loss:  0.8416268264705484  Training Accuracy:  0.7346251\n",
      "Epoch:  54  Training Loss:  0.8228409832174127  Training Accuracy:  0.7438922\n",
      "Epoch:  55  Training Loss:  0.8011580683968283  Training Accuracy:  0.74978936\n",
      "Epoch:  56  Training Loss:  0.7932573768225584  Training Accuracy:  0.733221\n",
      "Epoch:  57  Training Loss:  0.7878394527868791  Training Accuracy:  0.74473464\n",
      "Epoch:  58  Training Loss:  0.7701763245192441  Training Accuracy:  0.750351\n",
      "Epoch:  59  Training Loss:  0.7645241377028552  Training Accuracy:  0.7556866\n",
      "Epoch:  60  Training Loss:  0.7590788036584855  Training Accuracy:  0.758214\n",
      "Epoch:  61  Training Loss:  0.748389606313272  Training Accuracy:  0.76242626\n",
      "Epoch:  62  Training Loss:  0.7321136477318677  Training Accuracy:  0.76242626\n",
      "Epoch:  63  Training Loss:  0.7007253776897083  Training Accuracy:  0.7677619\n",
      "Epoch:  64  Training Loss:  0.7125867036255923  Training Accuracy:  0.7655153\n",
      "Epoch:  65  Training Loss:  0.7010443197055296  Training Accuracy:  0.77618647\n",
      "Epoch:  66  Training Loss:  0.6855644318190488  Training Accuracy:  0.7789947\n",
      "Epoch:  67  Training Loss:  0.6764344079927964  Training Accuracy:  0.78320694\n",
      "Epoch:  68  Training Loss:  0.6629671868952838  Training Accuracy:  0.7820837\n",
      "Epoch:  69  Training Loss:  0.6676768311045387  Training Accuracy:  0.7868576\n",
      "Epoch:  70  Training Loss:  0.6488706735047427  Training Accuracy:  0.78292614\n",
      "Epoch:  71  Training Loss:  0.6390707034956326  Training Accuracy:  0.78601515\n",
      "Epoch:  72  Training Loss:  0.6304819659753279  Training Accuracy:  0.786296\n",
      "Epoch:  73  Training Loss:  0.6269942730665207  Training Accuracy:  0.7919124\n",
      "Epoch:  74  Training Loss:  0.6191905517469752  Training Accuracy:  0.7902275\n",
      "Epoch:  75  Training Loss:  0.6138002062385732  Training Accuracy:  0.79387814\n",
      "Epoch:  76  Training Loss:  0.6039936486970294  Training Accuracy:  0.80511093\n",
      "Epoch:  77  Training Loss:  0.5936876585537737  Training Accuracy:  0.80033696\n",
      "Epoch:  78  Training Loss:  0.590256467461586  Training Accuracy:  0.80791914\n",
      "Epoch:  79  Training Loss:  0.5776626035571099  Training Accuracy:  0.80511093\n",
      "Epoch:  80  Training Loss:  0.5799458077008074  Training Accuracy:  0.8045493\n",
      "Epoch:  81  Training Loss:  0.5714220977642319  Training Accuracy:  0.8135355\n",
      "Epoch:  82  Training Loss:  0.5618570376526225  Training Accuracy:  0.8107273\n",
      "Epoch:  83  Training Loss:  0.5558356003327803  Training Accuracy:  0.8171862\n",
      "Epoch:  84  Training Loss:  0.5446482268246737  Training Accuracy:  0.82111764\n",
      "Epoch:  85  Training Loss:  0.541685743088072  Training Accuracy:  0.8149396\n",
      "Epoch:  86  Training Loss:  0.5353531590916893  Training Accuracy:  0.8247683\n",
      "Epoch:  87  Training Loss:  0.5217605794017965  Training Accuracy:  0.8242067\n",
      "Epoch:  88  Training Loss:  0.5320509296926585  Training Accuracy:  0.82392585\n",
      "Epoch:  89  Training Loss:  0.5067251924764026  Training Accuracy:  0.8272957\n",
      "Epoch:  90  Training Loss:  0.5126969914544712  Training Accuracy:  0.8216793\n",
      "Epoch:  91  Training Loss:  0.5027248129248619  Training Accuracy:  0.83038473\n",
      "Epoch:  92  Training Loss:  0.5042733038013631  Training Accuracy:  0.82561076\n",
      "Epoch:  93  Training Loss:  0.4937571975317868  Training Accuracy:  0.82841897\n",
      "Epoch:  94  Training Loss:  0.4943518476052718  Training Accuracy:  0.8306655\n",
      "Epoch:  95  Training Loss:  0.4827874821695414  Training Accuracy:  0.8329121\n",
      "Epoch:  96  Training Loss:  0.48002507307312703  Training Accuracy:  0.8281382\n",
      "Epoch:  97  Training Loss:  0.4707951537587426  Training Accuracy:  0.83656275\n",
      "Epoch:  98  Training Loss:  0.46713864559477025  Training Accuracy:  0.8326313\n",
      "Epoch:  99  Training Loss:  0.4579336354678327  Training Accuracy:  0.831508\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.85987264\n",
      "validation accuracy: 0.85987264\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.538635830445723  Training Accuracy:  0.11260882\n",
      "Epoch:  1  Training Loss:  2.3780725890939887  Training Accuracy:  0.1319854\n",
      "Epoch:  2  Training Loss:  2.3166781598871404  Training Accuracy:  0.16231395\n",
      "Epoch:  3  Training Loss:  2.254623545299877  Training Accuracy:  0.20303285\n",
      "Epoch:  4  Training Loss:  2.219108627059243  Training Accuracy:  0.23925863\n",
      "Epoch:  5  Training Loss:  2.175683032382618  Training Accuracy:  0.2670598\n",
      "Epoch:  6  Training Loss:  2.120029993490739  Training Accuracy:  0.2822241\n",
      "Epoch:  7  Training Loss:  2.072669425877658  Training Accuracy:  0.29795\n",
      "Epoch:  8  Training Loss:  2.0295968304980887  Training Accuracy:  0.3131143\n",
      "Epoch:  9  Training Loss:  1.9781007755886424  Training Accuracy:  0.32940185\n",
      "Epoch:  10  Training Loss:  1.930510821125724  Training Accuracy:  0.34737432\n",
      "Epoch:  11  Training Loss:  1.8867435693740844  Training Accuracy:  0.36141533\n",
      "Epoch:  12  Training Loss:  1.85250775272196  Training Accuracy:  0.36927828\n",
      "Epoch:  13  Training Loss:  1.8197622369636188  Training Accuracy:  0.39090145\n",
      "Epoch:  14  Training Loss:  1.7707182607867502  Training Accuracy:  0.39988768\n",
      "Epoch:  15  Training Loss:  1.7396558436480436  Training Accuracy:  0.42094916\n",
      "Epoch:  16  Training Loss:  1.7130069892514836  Training Accuracy:  0.4271272\n",
      "Epoch:  17  Training Loss:  1.6764780656857925  Training Accuracy:  0.43330526\n",
      "Epoch:  18  Training Loss:  1.6437261955304578  Training Accuracy:  0.4636338\n",
      "Epoch:  19  Training Loss:  1.6120807528495789  Training Accuracy:  0.47430497\n",
      "Epoch:  20  Training Loss:  1.5778191035444087  Training Accuracy:  0.4858186\n",
      "Epoch:  21  Training Loss:  1.5555253543637015  Training Accuracy:  0.5037911\n",
      "Epoch:  22  Training Loss:  1.514699095758525  Training Accuracy:  0.52316767\n",
      "Epoch:  23  Training Loss:  1.4824720030481164  Training Accuracy:  0.5251334\n",
      "Epoch:  24  Training Loss:  1.4524642277847637  Training Accuracy:  0.54422915\n",
      "Epoch:  25  Training Loss:  1.425537506016818  Training Accuracy:  0.5529346\n",
      "Epoch:  26  Training Loss:  1.3861749109896746  Training Accuracy:  0.56163996\n",
      "Epoch:  27  Training Loss:  1.37659987996925  Training Accuracy:  0.5759618\n",
      "Epoch:  28  Training Loss:  1.3401519347320903  Training Accuracy:  0.57877\n",
      "Epoch:  29  Training Loss:  1.3072763881900094  Training Accuracy:  0.59365344\n",
      "Epoch:  30  Training Loss:  1.2849702347408642  Training Accuracy:  0.6003932\n",
      "Epoch:  31  Training Loss:  1.2709957372058522  Training Accuracy:  0.60909855\n",
      "Epoch:  32  Training Loss:  1.227953300150958  Training Accuracy:  0.60292053\n",
      "Epoch:  33  Training Loss:  1.2134996584870599  Training Accuracy:  0.62285876\n",
      "Epoch:  34  Training Loss:  1.1775649525902487  Training Accuracy:  0.6253861\n",
      "Epoch:  35  Training Loss:  1.1533698453144594  Training Accuracy:  0.6237012\n",
      "Epoch:  36  Training Loss:  1.140097151832147  Training Accuracy:  0.6265094\n",
      "Epoch:  37  Training Loss:  1.1128724547949704  Training Accuracy:  0.6413929\n",
      "Epoch:  38  Training Loss:  1.108954941142689  Training Accuracy:  0.6430778\n",
      "Epoch:  39  Training Loss:  1.0824737668037414  Training Accuracy:  0.6604886\n",
      "Epoch:  40  Training Loss:  1.0740854545073075  Training Accuracy:  0.66133106\n",
      "Epoch:  41  Training Loss:  1.0425803127613935  Training Accuracy:  0.65824205\n",
      "Epoch:  42  Training Loss:  1.033890568668192  Training Accuracy:  0.66778994\n",
      "Epoch:  43  Training Loss:  1.0151843095367605  Training Accuracy:  0.67340636\n",
      "Epoch:  44  Training Loss:  0.99817420352589  Training Accuracy:  0.6700365\n",
      "Epoch:  45  Training Loss:  0.9855226551944559  Training Accuracy:  0.6812693\n",
      "Epoch:  46  Training Loss:  0.9789972830902446  Training Accuracy:  0.68463916\n",
      "Epoch:  47  Training Loss:  0.9621795369820161  Training Accuracy:  0.6852008\n",
      "Epoch:  48  Training Loss:  0.9480538427829742  Training Accuracy:  0.68660486\n",
      "Epoch:  49  Training Loss:  0.927837459878488  Training Accuracy:  0.68660486\n",
      "Epoch:  50  Training Loss:  0.9196031066504392  Training Accuracy:  0.6983993\n",
      "Epoch:  51  Training Loss:  0.9147567041895607  Training Accuracy:  0.6983993\n",
      "Epoch:  52  Training Loss:  0.9009142230857502  Training Accuracy:  0.70878965\n",
      "Epoch:  53  Training Loss:  0.8825684753331271  Training Accuracy:  0.70850885\n",
      "Epoch:  54  Training Loss:  0.869414961067113  Training Accuracy:  0.716091\n",
      "Epoch:  55  Training Loss:  0.8574078757654536  Training Accuracy:  0.7231115\n",
      "Epoch:  56  Training Loss:  0.8502919180826707  Training Accuracy:  0.71019375\n",
      "Epoch:  57  Training Loss:  0.842110654305328  Training Accuracy:  0.71300197\n",
      "Epoch:  58  Training Loss:  0.8404594699090178  Training Accuracy:  0.7188992\n",
      "Epoch:  59  Training Loss:  0.8180026796731081  Training Accuracy:  0.7262005\n",
      "Epoch:  60  Training Loss:  0.8057966069741682  Training Accuracy:  0.73406345\n",
      "Epoch:  61  Training Loss:  0.8103903897783973  Training Accuracy:  0.7312553\n",
      "Epoch:  62  Training Loss:  0.799296242811463  Training Accuracy:  0.73518676\n",
      "Epoch:  63  Training Loss:  0.7876427829265594  Training Accuracy:  0.73265934\n",
      "Epoch:  64  Training Loss:  0.7739559621973471  Training Accuracy:  0.7374333\n",
      "Epoch:  65  Training Loss:  0.766175196387551  Training Accuracy:  0.744173\n",
      "Epoch:  66  Training Loss:  0.7616798185489394  Training Accuracy:  0.74192643\n",
      "Epoch:  67  Training Loss:  0.7470390061085874  Training Accuracy:  0.74473464\n",
      "Epoch:  68  Training Loss:  0.7403517167676579  Training Accuracy:  0.7556866\n",
      "Epoch:  69  Training Loss:  0.7224392438476736  Training Accuracy:  0.75119346\n",
      "Epoch:  70  Training Loss:  0.7286886093291369  Training Accuracy:  0.75063187\n",
      "Epoch:  71  Training Loss:  0.7174312446605076  Training Accuracy:  0.7615838\n",
      "Epoch:  72  Training Loss:  0.698933813653209  Training Accuracy:  0.7629879\n",
      "Epoch:  73  Training Loss:  0.7160867468877272  Training Accuracy:  0.75596744\n",
      "Epoch:  74  Training Loss:  0.6878174334764481  Training Accuracy:  0.76326877\n",
      "Epoch:  75  Training Loss:  0.6838768437504769  Training Accuracy:  0.77450156\n",
      "Epoch:  76  Training Loss:  0.6710638223723931  Training Accuracy:  0.7728166\n",
      "Epoch:  77  Training Loss:  0.6667057893492959  Training Accuracy:  0.76888514\n",
      "Epoch:  78  Training Loss:  0.6617251593958248  Training Accuracy:  0.77057004\n",
      "Epoch:  79  Training Loss:  0.6498543697324666  Training Accuracy:  0.7789947\n",
      "Epoch:  80  Training Loss:  0.6463582913983952  Training Accuracy:  0.7711317\n",
      "Epoch:  81  Training Loss:  0.6343471180308949  Training Accuracy:  0.78461105\n",
      "Epoch:  82  Training Loss:  0.6350618107752366  Training Accuracy:  0.78770006\n",
      "Epoch:  83  Training Loss:  0.6213771730661393  Training Accuracy:  0.7882617\n",
      "Epoch:  84  Training Loss:  0.6232967926697297  Training Accuracy:  0.7882617\n",
      "Epoch:  85  Training Loss:  0.6102995747869665  Training Accuracy:  0.7919124\n",
      "Epoch:  86  Training Loss:  0.6092621276324446  Training Accuracy:  0.79865205\n",
      "Epoch:  87  Training Loss:  0.5959729292175987  Training Accuracy:  0.80117947\n",
      "Epoch:  88  Training Loss:  0.5792907000942664  Training Accuracy:  0.7994945\n",
      "Epoch:  89  Training Loss:  0.5795388595624403  Training Accuracy:  0.8045493\n",
      "Epoch:  90  Training Loss:  0.5794956292618405  Training Accuracy:  0.80146027\n",
      "Epoch:  91  Training Loss:  0.5632143655283884  Training Accuracy:  0.8118506\n",
      "Epoch:  92  Training Loss:  0.5695936459031972  Training Accuracy:  0.80819994\n",
      "Epoch:  93  Training Loss:  0.5544055784290487  Training Accuracy:  0.8087616\n",
      "Epoch:  94  Training Loss:  0.5477092351425777  Training Accuracy:  0.81409717\n",
      "Epoch:  95  Training Loss:  0.5373141241344539  Training Accuracy:  0.8199944\n",
      "Epoch:  96  Training Loss:  0.531140838902105  Training Accuracy:  0.81241226\n",
      "Epoch:  97  Training Loss:  0.5271052880720659  Training Accuracy:  0.8169054\n",
      "Epoch:  98  Training Loss:  0.5225639003244313  Training Accuracy:  0.8118506\n",
      "Epoch:  99  Training Loss:  0.517729056220163  Training Accuracy:  0.8216793\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.82961786\n",
      "validation accuracy: 0.82961786\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.5558820616115225  Training Accuracy:  0.09772536\n",
      "Epoch:  1  Training Loss:  2.3844275799664585  Training Accuracy:  0.1305813\n",
      "Epoch:  2  Training Loss:  2.342024241794239  Training Accuracy:  0.13451278\n",
      "Epoch:  3  Training Loss:  2.309422826766968  Training Accuracy:  0.16456051\n",
      "Epoch:  4  Training Loss:  2.2750710985877296  Training Accuracy:  0.18112889\n",
      "Epoch:  5  Training Loss:  2.232200130549344  Training Accuracy:  0.22297108\n",
      "Epoch:  6  Training Loss:  2.1756727261976763  Training Accuracy:  0.24768324\n",
      "Epoch:  7  Training Loss:  2.113923686200922  Training Accuracy:  0.2695872\n",
      "Epoch:  8  Training Loss:  2.063779726895419  Training Accuracy:  0.2850323\n",
      "Epoch:  9  Training Loss:  2.0047107458114626  Training Accuracy:  0.3145184\n",
      "Epoch:  10  Training Loss:  1.9626422448591752  Training Accuracy:  0.32631284\n",
      "Epoch:  11  Training Loss:  1.9165282872590153  Training Accuracy:  0.33614153\n",
      "Epoch:  12  Training Loss:  1.8803198012438687  Training Accuracy:  0.36310026\n",
      "Epoch:  13  Training Loss:  1.82293600006537  Training Accuracy:  0.3734906\n",
      "Epoch:  14  Training Loss:  1.7998715910044583  Training Accuracy:  0.4074698\n",
      "Epoch:  15  Training Loss:  1.7481850721619345  Training Accuracy:  0.41505194\n",
      "Epoch:  16  Training Loss:  1.724447890845212  Training Accuracy:  0.4296546\n",
      "Epoch:  17  Training Loss:  1.6793392430652272  Training Accuracy:  0.4591407\n",
      "Epoch:  18  Training Loss:  1.6468238670717585  Training Accuracy:  0.46700364\n",
      "Epoch:  19  Training Loss:  1.6055743065747348  Training Accuracy:  0.49115416\n",
      "Epoch:  20  Training Loss:  1.553139693628658  Training Accuracy:  0.5127773\n",
      "Epoch:  21  Training Loss:  1.5328772534023631  Training Accuracy:  0.51109236\n",
      "Epoch:  22  Training Loss:  1.4958644904873588  Training Accuracy:  0.5296265\n",
      "Epoch:  23  Training Loss:  1.4603573606772857  Training Accuracy:  0.5481606\n",
      "Epoch:  24  Training Loss:  1.4213583813472228  Training Accuracy:  0.5498456\n",
      "Epoch:  25  Training Loss:  1.4012122723189266  Training Accuracy:  0.55714685\n",
      "Epoch:  26  Training Loss:  1.3531622458587993  Training Accuracy:  0.57118785\n",
      "Epoch:  27  Training Loss:  1.329881611737338  Training Accuracy:  0.5841056\n",
      "Epoch:  28  Training Loss:  1.3038882824507627  Training Accuracy:  0.5922494\n",
      "Epoch:  29  Training Loss:  1.2729824505069038  Training Accuracy:  0.60600954\n",
      "Epoch:  30  Training Loss:  1.2405028760433197  Training Accuracy:  0.61696154\n",
      "Epoch:  31  Training Loss:  1.2088946532119405  Training Accuracy:  0.6194889\n",
      "Epoch:  32  Training Loss:  1.1893374331972815  Training Accuracy:  0.64251614\n",
      "Epoch:  33  Training Loss:  1.1539478624408894  Training Accuracy:  0.6385847\n",
      "Epoch:  34  Training Loss:  1.1427312807603316  Training Accuracy:  0.6526257\n",
      "Epoch:  35  Training Loss:  1.116897961768237  Training Accuracy:  0.6557147\n",
      "Epoch:  36  Training Loss:  1.0910336890003898  Training Accuracy:  0.66245437\n",
      "Epoch:  37  Training Loss:  1.0702444789084522  Training Accuracy:  0.6762146\n",
      "Epoch:  38  Training Loss:  1.045854695818641  Training Accuracy:  0.6823926\n",
      "Epoch:  39  Training Loss:  1.0294289209625938  Training Accuracy:  0.69559115\n",
      "Epoch:  40  Training Loss:  1.0034746901555496  Training Accuracy:  0.69109803\n",
      "Epoch:  41  Training Loss:  0.9831751771948555  Training Accuracy:  0.6925021\n",
      "Epoch:  42  Training Loss:  0.9614044750278646  Training Accuracy:  0.7023308\n",
      "Epoch:  43  Training Loss:  0.9586550731550564  Training Accuracy:  0.7141252\n",
      "Epoch:  44  Training Loss:  0.9336961862715808  Training Accuracy:  0.7236731\n",
      "Epoch:  45  Training Loss:  0.909199579466473  Training Accuracy:  0.7188992\n",
      "Epoch:  46  Training Loss:  0.9002502899278294  Training Accuracy:  0.73209774\n",
      "Epoch:  47  Training Loss:  0.874457101388411  Training Accuracy:  0.73378265\n",
      "Epoch:  48  Training Loss:  0.8593044546517459  Training Accuracy:  0.73659086\n",
      "Epoch:  49  Training Loss:  0.8477642888372595  Training Accuracy:  0.7525976\n",
      "Epoch:  50  Training Loss:  0.8374610640785911  Training Accuracy:  0.74782366\n",
      "Epoch:  51  Training Loss:  0.8047798649831251  Training Accuracy:  0.76326877\n",
      "Epoch:  52  Training Loss:  0.7986118219115518  Training Accuracy:  0.77000844\n",
      "Epoch:  53  Training Loss:  0.7752620073882016  Training Accuracy:  0.76354957\n",
      "Epoch:  54  Training Loss:  0.7575341579588977  Training Accuracy:  0.7694468\n",
      "Epoch:  55  Training Loss:  0.7438590068708767  Training Accuracy:  0.77618647\n",
      "Epoch:  56  Training Loss:  0.7292791737751527  Training Accuracy:  0.7781522\n",
      "Epoch:  57  Training Loss:  0.7287554120475596  Training Accuracy:  0.789385\n",
      "Epoch:  58  Training Loss:  0.7076632231473923  Training Accuracy:  0.78854257\n",
      "Epoch:  59  Training Loss:  0.6855195061727004  Training Accuracy:  0.7902275\n",
      "Epoch:  60  Training Loss:  0.678154000098055  Training Accuracy:  0.78433025\n",
      "Epoch:  61  Training Loss:  0.6712442698803815  Training Accuracy:  0.7944398\n",
      "Epoch:  62  Training Loss:  0.6499687007882379  Training Accuracy:  0.7947206\n",
      "Epoch:  63  Training Loss:  0.6407982411709698  Training Accuracy:  0.7933165\n",
      "Epoch:  64  Training Loss:  0.6298417679288171  Training Accuracy:  0.8031452\n",
      "Epoch:  65  Training Loss:  0.6146865129470825  Training Accuracy:  0.803426\n",
      "Epoch:  66  Training Loss:  0.6198121322826906  Training Accuracy:  0.8101657\n",
      "Epoch:  67  Training Loss:  0.5944741208444942  Training Accuracy:  0.80960405\n",
      "Epoch:  68  Training Loss:  0.5802073925733566  Training Accuracy:  0.81241226\n",
      "Epoch:  69  Training Loss:  0.5883267590945417  Training Accuracy:  0.81578207\n",
      "Epoch:  70  Training Loss:  0.573383834280751  Training Accuracy:  0.81241226\n",
      "Epoch:  71  Training Loss:  0.5574530188332905  Training Accuracy:  0.8107273\n",
      "Epoch:  72  Training Loss:  0.5515032458034429  Training Accuracy:  0.8188711\n",
      "Epoch:  73  Training Loss:  0.5436248905279419  Training Accuracy:  0.8213985\n",
      "Epoch:  74  Training Loss:  0.540420624749227  Training Accuracy:  0.8202752\n",
      "Epoch:  75  Training Loss:  0.5289224627343091  Training Accuracy:  0.82701486\n",
      "Epoch:  76  Training Loss:  0.5182033331556753  Training Accuracy:  0.8244875\n",
      "Epoch:  77  Training Loss:  0.5106267328966748  Training Accuracy:  0.8281382\n",
      "Epoch:  78  Training Loss:  0.511514802141623  Training Accuracy:  0.8272957\n",
      "Epoch:  79  Training Loss:  0.5015765074979175  Training Accuracy:  0.831508\n",
      "Epoch:  80  Training Loss:  0.49630842886187815  Training Accuracy:  0.83178884\n",
      "Epoch:  81  Training Loss:  0.4852576568722725  Training Accuracy:  0.8323505\n",
      "Epoch:  82  Training Loss:  0.4850630200722001  Training Accuracy:  0.83515865\n",
      "Epoch:  83  Training Loss:  0.4701055110855536  Training Accuracy:  0.8385285\n",
      "Epoch:  84  Training Loss:  0.47253542948852884  Training Accuracy:  0.83515865\n",
      "Epoch:  85  Training Loss:  0.46219443475658245  Training Accuracy:  0.8413367\n",
      "Epoch:  86  Training Loss:  0.4592107526280663  Training Accuracy:  0.8371244\n",
      "Epoch:  87  Training Loss:  0.4538624424826015  Training Accuracy:  0.8438641\n",
      "Epoch:  88  Training Loss:  0.44698543507944455  Training Accuracy:  0.8421792\n",
      "Epoch:  89  Training Loss:  0.4437399711121212  Training Accuracy:  0.8413367\n",
      "Epoch:  90  Training Loss:  0.44836388541893524  Training Accuracy:  0.84470654\n",
      "Epoch:  91  Training Loss:  0.43757595988837156  Training Accuracy:  0.845549\n",
      "Epoch:  92  Training Loss:  0.4321180457418615  Training Accuracy:  0.84442574\n",
      "Epoch:  93  Training Loss:  0.4287583886222406  Training Accuracy:  0.85060376\n",
      "Epoch:  94  Training Loss:  0.4182663889093833  Training Accuracy:  0.8528503\n",
      "Epoch:  95  Training Loss:  0.42823918055404314  Training Accuracy:  0.8449874\n",
      "Epoch:  96  Training Loss:  0.418219851363789  Training Accuracy:  0.8553777\n",
      "Epoch:  97  Training Loss:  0.4216712705113671  Training Accuracy:  0.84891886\n",
      "Epoch:  98  Training Loss:  0.402524841373617  Training Accuracy:  0.8553777\n",
      "Epoch:  99  Training Loss:  0.410984791950746  Training Accuracy:  0.853412\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.88535035\n",
      "validation accuracy: 0.88535035\n",
      "pa2\n",
      "X shape = (?, 1, 25, 52)\n",
      "Y shape = (?, 11)\n",
      "hidden layer 1 shape\n",
      "W_conv1 shape = (1, 7, 52, 128)\n",
      "b_conv1 shape = (128,)\n",
      "h_conv1 shape = (?, 1, 19, 128)\n",
      "h_pool1 shape = (?, 1, 7, 128)\n",
      "WEIGHTS ARE LOADED\n",
      "WEIGHTS ARE LOADED\n",
      "hidden layer 2 shape\n",
      "W_conv2 shape = (1, 3, 128, 128)\n",
      "b_conv2 shape = (128,)\n",
      "h_conv2 shape = (?, 1, 5, 128)\n",
      "h_pool2 shape = (?, 1, 2, 128)\n",
      "shape's shape: [None, 1, 2, 128]\n",
      "c_flat shape = (?, 256)\n",
      "unique test_y [0 1]\n",
      "unique train_y [0 1]\n",
      "test_y[1]= [1 0 0 0 0 0 0 0 0 0 0]\n",
      "train_y shape(1-hot) = (3561, 11)\n",
      "test_y shape(1-hot) = (628, 11)\n",
      "train_x_reshaped =  (3561, 1, 25, 52)\n",
      "test_x_reshaped =  (628, 1, 25, 52)\n",
      "train_x shape = (3561, 25, 52)\n",
      "train_y shape = (3561,)\n",
      "test_x shape = (628, 25, 52)\n",
      "test_y shape = (628,)\n",
      "Epoch:  0  Training Loss:  2.5228226921775123  Training Accuracy:  0.11878686\n",
      "Epoch:  1  Training Loss:  2.384143584424799  Training Accuracy:  0.12861556\n",
      "Epoch:  2  Training Loss:  2.334704214876348  Training Accuracy:  0.15978658\n",
      "Epoch:  3  Training Loss:  2.2806976708498867  Training Accuracy:  0.19376579\n",
      "Epoch:  4  Training Loss:  2.225019732388583  Training Accuracy:  0.23083404\n",
      "Epoch:  5  Training Loss:  2.180027868530967  Training Accuracy:  0.25723112\n",
      "Epoch:  6  Training Loss:  2.1311987074938687  Training Accuracy:  0.2639708\n",
      "Epoch:  7  Training Loss:  2.074200683290308  Training Accuracy:  0.29598427\n",
      "Epoch:  8  Training Loss:  2.025942220471122  Training Accuracy:  0.30609378\n",
      "Epoch:  9  Training Loss:  1.9898029110648416  Training Accuracy:  0.3201348\n",
      "Epoch:  10  Training Loss:  1.9339225866577843  Training Accuracy:  0.33361414\n",
      "Epoch:  11  Training Loss:  1.898572606390173  Training Accuracy:  0.34400448\n",
      "Epoch:  12  Training Loss:  1.8612634712999516  Training Accuracy:  0.36731255\n",
      "Epoch:  13  Training Loss:  1.82485308972272  Training Accuracy:  0.37938783\n",
      "Epoch:  14  Training Loss:  1.7940473545681346  Training Accuracy:  0.39567536\n",
      "Epoch:  15  Training Loss:  1.7612910969690843  Training Accuracy:  0.40803146\n",
      "Epoch:  16  Training Loss:  1.7291061693971808  Training Accuracy:  0.41364786\n",
      "Epoch:  17  Training Loss:  1.6978952567685734  Training Accuracy:  0.42628476\n",
      "Epoch:  18  Training Loss:  1.667600298469717  Training Accuracy:  0.44116822\n",
      "Epoch:  19  Training Loss:  1.6314314885572954  Training Accuracy:  0.43920246\n",
      "Epoch:  20  Training Loss:  1.6118560086597096  Training Accuracy:  0.45183936\n",
      "Epoch:  21  Training Loss:  1.5756189568476244  Training Accuracy:  0.46700364\n",
      "Epoch:  22  Training Loss:  1.5554499244148081  Training Accuracy:  0.47233924\n",
      "Epoch:  23  Training Loss:  1.5216289216821843  Training Accuracy:  0.4762707\n",
      "Epoch:  24  Training Loss:  1.5052221742543308  Training Accuracy:  0.48666105\n",
      "Epoch:  25  Training Loss:  1.4814728086644953  Training Accuracy:  0.49508566\n",
      "Epoch:  26  Training Loss:  1.4599361834200946  Training Accuracy:  0.50659925\n",
      "Epoch:  27  Training Loss:  1.439391460201957  Training Accuracy:  0.50659925\n",
      "Epoch:  28  Training Loss:  1.4058941320939498  Training Accuracy:  0.519517\n",
      "Epoch:  29  Training Loss:  1.3916204858909953  Training Accuracy:  0.51923615\n",
      "Epoch:  30  Training Loss:  1.36557245796377  Training Accuracy:  0.53131145\n",
      "Epoch:  31  Training Loss:  1.3389305786652999  Training Accuracy:  0.536647\n",
      "Epoch:  32  Training Loss:  1.3162854140455074  Training Accuracy:  0.5563044\n",
      "Epoch:  33  Training Loss:  1.2991134199229153  Training Accuracy:  0.55209213\n",
      "Epoch:  34  Training Loss:  1.2831830815835432  Training Accuracy:  0.5602359\n",
      "Epoch:  35  Training Loss:  1.2715008917179975  Training Accuracy:  0.5655715\n",
      "Epoch:  36  Training Loss:  1.2513462497429415  Training Accuracy:  0.5754002\n",
      "Epoch:  37  Training Loss:  1.2279931889338926  Training Accuracy:  0.5745577\n",
      "Epoch:  38  Training Loss:  1.207620050961321  Training Accuracy:  0.58185905\n",
      "Epoch:  39  Training Loss:  1.1971607121554289  Training Accuracy:  0.5911261\n",
      "Epoch:  40  Training Loss:  1.1738301659172232  Training Accuracy:  0.6110643\n",
      "Epoch:  41  Training Loss:  1.1457574963569641  Training Accuracy:  0.60909855\n",
      "Epoch:  42  Training Loss:  1.1443781687454744  Training Accuracy:  0.6113451\n",
      "Epoch:  43  Training Loss:  1.1251555009321732  Training Accuracy:  0.61696154\n",
      "Epoch:  44  Training Loss:  1.107040069049055  Training Accuracy:  0.62173545\n",
      "Epoch:  45  Training Loss:  1.0929073683240198  Training Accuracy:  0.6259478\n",
      "Epoch:  46  Training Loss:  1.0794656658714468  Training Accuracy:  0.6402696\n",
      "Epoch:  47  Training Loss:  1.050297823548317  Training Accuracy:  0.64083123\n",
      "Epoch:  48  Training Loss:  1.0393968590281226  Training Accuracy:  0.6509408\n",
      "Epoch:  49  Training Loss:  1.0103292232209986  Training Accuracy:  0.6638585\n",
      "Epoch:  50  Training Loss:  1.0060258182612332  Training Accuracy:  0.6773378\n",
      "Epoch:  51  Training Loss:  0.98177152113481  Training Accuracy:  0.6728447\n",
      "Epoch:  52  Training Loss:  0.9574911059303717  Training Accuracy:  0.6868857\n",
      "Epoch:  53  Training Loss:  0.9429666689851067  Training Accuracy:  0.6939062\n",
      "Epoch:  54  Training Loss:  0.9384726621887901  Training Accuracy:  0.6969952\n",
      "Epoch:  55  Training Loss:  0.9213279193097895  Training Accuracy:  0.7034541\n",
      "Epoch:  56  Training Loss:  0.9022555003112013  Training Accuracy:  0.70822805\n",
      "Epoch:  57  Training Loss:  0.8869453698396683  Training Accuracy:  0.7034541\n",
      "Epoch:  58  Training Loss:  0.8841833810914647  Training Accuracy:  0.72086495\n",
      "Epoch:  59  Training Loss:  0.8705605200745843  Training Accuracy:  0.7264813\n",
      "Epoch:  60  Training Loss:  0.8465697280385277  Training Accuracy:  0.7276046\n",
      "Epoch:  61  Training Loss:  0.8384641526774926  Training Accuracy:  0.7399607\n",
      "Epoch:  62  Training Loss:  0.8184755264358087  Training Accuracy:  0.7318169\n",
      "Epoch:  63  Training Loss:  0.8101364306428216  Training Accuracy:  0.74950856\n",
      "Epoch:  64  Training Loss:  0.8006040006875992  Training Accuracy:  0.750351\n",
      "Epoch:  65  Training Loss:  0.777438874407248  Training Accuracy:  0.7528784\n",
      "Epoch:  66  Training Loss:  0.7690376582470807  Training Accuracy:  0.74529624\n",
      "Epoch:  67  Training Loss:  0.747014232115312  Training Accuracy:  0.76046056\n",
      "Epoch:  68  Training Loss:  0.7418795502998612  Training Accuracy:  0.758214\n",
      "Epoch:  69  Training Loss:  0.7353367390957746  Training Accuracy:  0.7663578\n",
      "Epoch:  70  Training Loss:  0.7238018087365411  Training Accuracy:  0.7694468\n",
      "Epoch:  71  Training Loss:  0.707583723962307  Training Accuracy:  0.76046056\n",
      "Epoch:  72  Training Loss:  0.6974070608615875  Training Accuracy:  0.77309746\n",
      "Epoch:  73  Training Loss:  0.6837199437347325  Training Accuracy:  0.7756248\n",
      "Epoch:  74  Training Loss:  0.6642213293097236  Training Accuracy:  0.7773097\n",
      "Epoch:  75  Training Loss:  0.667899125949903  Training Accuracy:  0.7834878\n",
      "Epoch:  76  Training Loss:  0.6510730530050668  Training Accuracy:  0.7927548\n",
      "Epoch:  77  Training Loss:  0.6436119049787521  Training Accuracy:  0.7975288\n",
      "Epoch:  78  Training Loss:  0.6318113684654236  Training Accuracy:  0.7913507\n",
      "Epoch:  79  Training Loss:  0.6262967773459175  Training Accuracy:  0.7989329\n",
      "Epoch:  80  Training Loss:  0.6169986701147123  Training Accuracy:  0.7992137\n",
      "Epoch:  81  Training Loss:  0.5974662880328568  Training Accuracy:  0.80174106\n",
      "Epoch:  82  Training Loss:  0.5893788169730794  Training Accuracy:  0.8042685\n",
      "Epoch:  83  Training Loss:  0.5835278309881687  Training Accuracy:  0.80651504\n",
      "Epoch:  84  Training Loss:  0.5755239964886145  Training Accuracy:  0.8090424\n",
      "Epoch:  85  Training Loss:  0.5668860323049806  Training Accuracy:  0.8163437\n",
      "Epoch:  86  Training Loss:  0.5688667451116172  Training Accuracy:  0.81297386\n",
      "Epoch:  87  Training Loss:  0.5558914319358089  Training Accuracy:  0.81409717\n",
      "Epoch:  88  Training Loss:  0.5483242297714407  Training Accuracy:  0.8202752\n",
      "Epoch:  89  Training Loss:  0.5386333145878531  Training Accuracy:  0.8118506\n",
      "Epoch:  90  Training Loss:  0.5326914287087592  Training Accuracy:  0.8292614\n",
      "Epoch:  91  Training Loss:  0.5250191468406807  Training Accuracy:  0.8301039\n",
      "Epoch:  92  Training Loss:  0.5235902185467156  Training Accuracy:  0.83038473\n",
      "Epoch:  93  Training Loss:  0.5055751277641817  Training Accuracy:  0.8281382\n",
      "Epoch:  94  Training Loss:  0.4930573365227743  Training Accuracy:  0.82673407\n",
      "Epoch:  95  Training Loss:  0.4864905515177683  Training Accuracy:  0.8286998\n",
      "Epoch:  96  Training Loss:  0.4865201411599463  Training Accuracy:  0.8309464\n",
      "Epoch:  97  Training Loss:  0.4867678930813616  Training Accuracy:  0.8404942\n",
      "Epoch:  98  Training Loss:  0.4861003634604541  Training Accuracy:  0.83347374\n",
      "Epoch:  99  Training Loss:  0.47016500739211387  Training Accuracy:  0.83628196\n",
      "INFO:tensorflow:Restoring parameters from pa2\n",
      "Testing Accuracy: 0.84713376\n",
      "validation accuracy: 0.84713376\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_experiments):\n",
    "    model.W_conv2_weight = model3.W_conv2_weight\n",
    "    model.b_conv2_weight = model3.b_conv2_weight\n",
    "    model.build_model(self_training=False, load_weights=True)\n",
    "    model.run_model(training_epochs=100, learning_rate=0.0001)\n",
    "    test_accuracy, val_accuracy, y_pred, y_true = model.test()\n",
    "    stats3.add(test_accuracy, val_accuracy, y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy. Mean (std) = 0.852 (0.020)\n",
      "Val accuracy. Mean (std) = 0.852 (0.020)\n",
      "f1 score weighted. Mean (std) = 0.847 (0.021)\n",
      "f1 score mean. Mean (std) = 0.833 (0.023)\n"
     ]
    }
   ],
   "source": [
    "stats3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusions\n",
    "1. Self-training facilitates faster convergence for (num_epochs = 50)\n",
    "2. No visible improvements for binary or multi-task self-training\n",
    "3. Possible reason: the tested network is too small\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}