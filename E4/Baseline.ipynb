{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline for datasets\n",
    "Insert train.json, test.json under the folder data to get data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/anaconda3/envs/psdaub4/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from CNN.config import Config\n",
    "from CNN.utils import WordEmbeddingLoader, RelationLoader, SemEvalDataLoader\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import torch\n",
    "import numpy as np\n",
    "config = Config()\n",
    "config.batch_size = 1\n",
    "config.embedding_path = \"./CNN/embedding/hlbl-embeddings-scaled.EMBEDDING_SIZE=50.txt\"\n",
    "config.data_dir = \"./CNN/data/\"\n",
    "word2id, word_vec = WordEmbeddingLoader(config).load_embedding()\n",
    "rel2id, id2rel, class_num = RelationLoader(config).get_relation()\n",
    "loader = SemEvalDataLoader(rel2id, word2id, config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get X and y vectors from dataset\n",
    "NB: X is already a feature vector got from the word embedding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_x_y_from_loader(loader):\n",
    "    # upload train and test from dataloader\n",
    "    min_v, max_v = float('inf'), -float('inf')\n",
    "    X = []\n",
    "    y = []\n",
    "    for step, (data, label) in enumerate(loader):\n",
    "        x = data.detach().numpy().flatten()\n",
    "        x.astype(int)\n",
    "        X.append(x)\n",
    "        y.append(label.detach().numpy()[0])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = get_x_y_from_loader(loader.get_train())\n",
    "X_test, y_test = get_x_y_from_loader(loader.get_test())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics\n",
    "According to the [survey](https://link.springer.com/content/pdf/10.1007/s10115-022-01665-w.pdf), the main metrics are Accuracy, Precision, Recall and F1 Score. However, they may generate overoptimistic, misleading results on\n",
    "imbalanced datasets, as they failed to consider the ratio between positive and negative classes. To mitigate this, Matthews Correlation Coefficient (It is high only when the classifier is doing well in both positive and negative\n",
    "classes) and G-Mean-Score (a poor performance in positive examples prediction will lead to a low G-mean\n",
    "value, even if negative instances are correctly classified by the classifier) are used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_stats(prediction, y_test):\n",
    "    print(\"Accuracy Score -> \", accuracy_score(y_test, prediction))\n",
    "    print(\"Precision Score -> \", precision_score(y_test, prediction, average='weighted'))\n",
    "    print(\"Recall Score -> \", recall_score(y_test, prediction, average='weighted'))\n",
    "    print(\"F1 Score -> \", f1_score(y_test, prediction, average='weighted'))\n",
    "    print(\"Matthews Correlation Coefficient -> \", matthews_corrcoef(y_test, prediction))\n",
    "    print(\"G Mean Score -> \", geometric_mean_score(y_test, prediction))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline: Bayessian Classifier\n",
    "According to the [survey](https://link.springer.com/content/pdf/10.1007/s10115-022-01665-w.pdf), different baselines are possible. For instance, Logistic Regression, Decision Trees, SVM. [Sorgente et al.](http://ceur-ws.org/Vol-1109/paper4.pdf) used Naive Bayes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.5384615384615384\n",
      "Precision Score ->  0.5448504620165983\n",
      "Recall Score ->  0.5384615384615384\n",
      "F1 Score ->  0.5403048664902214\n",
      "Matthews Correlation Coefficient ->  0.07386140404851196\n",
      "G Mean Score ->  0.5371427867762878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions_nb = nb.predict(X_test)\n",
    "get_stats(predictions_nb, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Other possible baselines\n",
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.6502564102564102\n",
      "Precision Score ->  0.647079810159557\n",
      "Recall Score ->  0.6502564102564102\n",
      "F1 Score ->  0.640937446579709\n",
      "Matthews Correlation Coefficient ->  0.27505205602044247\n",
      "G Mean Score ->  0.6110827849119087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/anaconda3/envs/psdaub4/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='lbfgs', random_state=42, multi_class='multinomial', max_iter=1000, n_jobs=16)\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions_logreg = logreg.predict(X_test)\n",
    "get_stats(predictions_logreg, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM\n",
    "NB: for large datasets can have a long training period"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.5651282051282052\n",
      "Precision Score ->  0.7543387141334806\n",
      "Recall Score ->  0.5651282051282052\n",
      "F1 Score ->  0.40865823010162455\n",
      "Matthews Correlation Coefficient ->  0.02579490274625982\n",
      "G Mean Score ->  0.034319911152729005\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto')\n",
    "SVM.fit(X_train, y_train)\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "get_stats(predictions_SVM, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.7558974358974359\n",
      "Precision Score ->  0.7561043881216917\n",
      "Recall Score ->  0.7558974358974359\n",
      "F1 Score ->  0.7559937204846002\n",
      "Matthews Correlation Coefficient ->  0.5039141609561323\n",
      "G Mean Score ->  0.7515985032826582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "rfc = DecisionTreeClassifier(random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "predictions_rfc = rfc.predict(X_test)\n",
    "get_stats(predictions_rfc, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.7687179487179487\n",
      "Precision Score ->  0.7687494035376388\n",
      "Recall Score ->  0.7687179487179487\n",
      "F1 Score ->  0.7687334726677805\n",
      "Matthews Correlation Coefficient ->  0.5296432884430681\n",
      "G Mean Score ->  0.7642735270782253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "predictions_rfc = rfc.predict(X_test)\n",
    "get_stats(predictions_rfc, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}