{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline for datasets\n",
    "Insert train.json, test.json under the folder data to get data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/anaconda3/envs/psdaub4/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from CNN.config import Config\n",
    "from CNN.utils import WordEmbeddingLoader, RelationLoader, SemEvalDataLoader\n",
    "import numpy as np\n",
    "config = Config()\n",
    "config.batch_size = 1\n",
    "config.embedding_path = \"./CNN/embedding/hlbl-embeddings-scaled.EMBEDDING_SIZE=50.txt\"\n",
    "config.data_dir = \"./CNN/data/\"\n",
    "word2id, word_vec = WordEmbeddingLoader(config).load_embedding()\n",
    "rel2id, id2rel, class_num = RelationLoader(config).get_relation()\n",
    "loader = SemEvalDataLoader(rel2id, word2id, config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get X and y vectors from dataset\n",
    "NB: X is already a feature vector got from the word embedding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_x_y_from_loader(loader):\n",
    "    # upload train and test from dataloader\n",
    "    X = []\n",
    "    y = []\n",
    "    for step, (data, label) in enumerate(loader):\n",
    "        x = data.detach().numpy().flatten()\n",
    "        x.astype(int)\n",
    "        X.append(x)\n",
    "        y.append(label.detach().numpy()[0])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = get_x_y_from_loader(loader.get_train())\n",
    "X_test, y_test = get_x_y_from_loader(loader.get_test())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics\n",
    "According to the [survey](https://link.springer.com/content/pdf/10.1007/s10115-022-01665-w.pdf), the main metrics are Accuracy, Precision, Recall and F1 Score. However, they may generate overoptimistic, misleading results on\n",
    "imbalanced datasets, as they failed to consider the ratio between positive and negative classes. To mitigate this, Matthews Correlation Coefficient (It is high only when the classifier is doing well in both positive and negative\n",
    "classes) and G-Mean-Score (a poor performance in positive examples prediction will lead to a low G-mean\n",
    "value, even if negative instances are correctly classified by the classifier) are used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from custom_statistics import Statistics\n",
    "stats = Statistics()\n",
    "random_states = [0, 1, 42, 100, 5782]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline: Bayessian Classifier\n",
    "According to the [survey](https://link.springer.com/content/pdf/10.1007/s10115-022-01665-w.pdf), different baselines are possible. For instance, Logistic Regression, Decision Trees, SVM. [Sorgente et al.](http://ceur-ws.org/Vol-1109/paper4.pdf) used Naive Bayes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.5384615384615384\n",
      "Precision Score ->  0.5448504620165983\n",
      "Recall Score ->  0.5384615384615384\n",
      "F1 Score ->  0.5403048664902214\n",
      "Matthews Correlation Coefficient ->  0.07386140404851196\n",
      "G Mean Score ->  0.5371427867762878\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.5384615384615384,\n 0.5448504620165983,\n 0.5384615384615384,\n 0.5403048664902214,\n 0.07386140404851196,\n 0.5371427867762878)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions_nb = nb.predict(X_test)\n",
    "stats.get_metrics(predictions_nb, y_test, show=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Other possible baselines\n",
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/anaconda3/envs/psdaub4/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dmitrii/anaconda3/envs/psdaub4/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dmitrii/anaconda3/envs/psdaub4/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dmitrii/anaconda3/envs/psdaub4/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  (0.5764102564102564, 0.0)\n",
      "Precision Score ->  (0.5629600107159805, 0.0)\n",
      "Recall Score ->  (0.5764102564102564, 0.0)\n",
      "F1 Score ->  (0.5253168971310564, 0.0)\n",
      "Matthews Correlation Coefficient ->  (0.09116874220469899, 0.0)\n",
      "G Mean Score ->  (0.4273144992890848, 5.551115123125783e-17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/anaconda3/envs/psdaub4/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "stats.clean()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for random_state in random_states:\n",
    "    logreg = LogisticRegression(solver='lbfgs', random_state=random_state, multi_class='multinomial', max_iter=100, n_jobs=16)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    predictions_logreg = logreg.predict(X_test)\n",
    "    stats.add(predictions_logreg, y_test)\n",
    "stats.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM\n",
    "NB: for large datasets can have a long training period"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  (0.5856410256410256, 0.0)\n",
      "Precision Score ->  (0.5808380194670032, 0.0)\n",
      "Recall Score ->  (0.5856410256410256, 0.0)\n",
      "F1 Score ->  (0.5252710362139439, 0.0)\n",
      "Matthews Correlation Coefficient ->  (0.11398853783652776, 0.0)\n",
      "G Mean Score ->  (0.41423219181172594, 5.551115123125783e-17)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "stats.clean()\n",
    "for random_state in random_states:\n",
    "    SVM = svm.SVC(random_state=random_state)\n",
    "    SVM.fit(X_train, y_train)\n",
    "    predictions_SVM = SVM.predict(X_test)\n",
    "    stats.add(predictions_SVM, y_test)\n",
    "stats.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  (0.7548717948717949, 0.00438753838691436)\n",
      "Precision Score ->  (0.755012479837909, 0.004526298723414325)\n",
      "Recall Score ->  (0.7548717948717949, 0.00438753838691436)\n",
      "F1 Score ->  (0.7549340336119036, 0.004448417805382231)\n",
      "Matthews Correlation Coefficient ->  (0.5016919039680318, 0.009194867614786688)\n",
      "G Mean Score ->  (0.7503664849522422, 0.0048408545106849955)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "stats.clean()\n",
    "for random_state in random_states:\n",
    "    rfc = DecisionTreeClassifier(random_state=random_state)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    predictions_rfc = rfc.predict(X_test)\n",
    "    stats.add(predictions_rfc, y_test)\n",
    "stats.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  (0.7675897435897434, 0.005283793588673321)\n",
      "Precision Score ->  (0.767525885951278, 0.005481712255094081)\n",
      "Recall Score ->  (0.7675897435897434, 0.005283793588673321)\n",
      "F1 Score ->  (0.7675367877432328, 0.0053925790854735265)\n",
      "Matthews Correlation Coefficient ->  (0.5271254921220063, 0.011164864902839966)\n",
      "G Mean Score ->  (0.762760531951507, 0.006034538734085988)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "stats.clean()\n",
    "for random_state in random_states:\n",
    "    rfc = RandomForestClassifier(random_state=random_state)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    predictions_rfc = rfc.predict(X_test)\n",
    "    stats.add(predictions_rfc, y_test)\n",
    "stats.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}